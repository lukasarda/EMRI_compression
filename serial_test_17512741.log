****************************************************************
*                      SLURM Batch System                      *
*           IN2P3 Computing Centre, Villeurbanne FR            *
****************************************************************
* Date:                 Sun Jun 30 13:35:13 CEST 2024
* Job name:             5000
* Job id:               17512741
* User:                 lkarda
* Account:              lisaf
* Submit host:          ccahm001
* Partition:            gpu
* Quality of service:   gpu
* Nodelist:             ccwgslurm0102
****************************************************************
no change     /sps/lisaf/lkarda/miniconda3/condabin/conda
no change     /sps/lisaf/lkarda/miniconda3/bin/conda
no change     /sps/lisaf/lkarda/miniconda3/bin/conda-env
no change     /sps/lisaf/lkarda/miniconda3/bin/activate
no change     /sps/lisaf/lkarda/miniconda3/bin/deactivate
no change     /sps/lisaf/lkarda/miniconda3/etc/profile.d/conda.sh
no change     /sps/lisaf/lkarda/miniconda3/etc/fish/conf.d/conda.fish
no change     /sps/lisaf/lkarda/miniconda3/shell/condabin/Conda.psm1
no change     /sps/lisaf/lkarda/miniconda3/shell/condabin/conda-hook.ps1
no change     /sps/lisaf/lkarda/miniconda3/lib/python3.12/site-packages/xontrib/conda.xsh
no change     /sps/lisaf/lkarda/miniconda3/etc/profile.d/conda.csh
no change     /pbs/home/l/lkarda/.bashrc
No action taken.
AE_net
# of epochs: 100
# of samples: 24000
Batchsize: 100
# of batches: 240
# of nodes in bottleneck 5000
20240630_133536
Epoch 1:
batch 5 loss: 0.017326806858181953
batch 10 loss: 0.004034911375492811
batch 15 loss: 0.0026278650388121606
batch 20 loss: 0.0020419739885255694
batch 25 loss: 0.0017811072058975697
batch 30 loss: 0.001542509999126196
batch 35 loss: 0.0014003844698891044
batch 40 loss: 0.0012574539752677083
batch 45 loss: 0.0011515133548527956
batch 50 loss: 0.0010565570089966058
batch 55 loss: 0.0009461172157898545
batch 60 loss: 0.0009626568877138198
batch 65 loss: 0.0008476490853354335
batch 70 loss: 0.000763540726620704
batch 75 loss: 0.0007396285072900355
batch 80 loss: 0.0007057544658891857
batch 85 loss: 0.0006925081135705114
batch 90 loss: 0.0006802237592637538
batch 95 loss: 0.0006653457181528211
batch 100 loss: 0.0006434431415982544
batch 105 loss: 0.00063218935392797
batch 110 loss: 0.0006325537338852883
batch 115 loss: 0.0007404636358842254
batch 120 loss: 0.0007093283580616117
batch 125 loss: 0.0006342342006973922
batch 130 loss: 0.0006327082985080779
batch 135 loss: 0.000631634017918259
batch 140 loss: 0.0006295230588875711
batch 145 loss: 0.0006262246402911842
batch 150 loss: 0.0006233089021407068
batch 155 loss: 0.0006201676093041897
batch 160 loss: 0.0008799572009593248
batch 165 loss: 0.000841727724764496
batch 170 loss: 0.0006409021094441414
batch 175 loss: 0.0006390448659658432
batch 180 loss: 0.0006369941984303296
batch 185 loss: 0.0006354450597427785
batch 190 loss: 0.0006331358337774873
batch 195 loss: 0.000629916787147522
batch 200 loss: 0.0006259839865379035
batch 205 loss: 0.0006221997435204684
batch 210 loss: 0.0006188006955198944
batch 215 loss: 0.0006153294933028519
batch 220 loss: 0.000612468330655247
batch 225 loss: 0.0006099476246163249
batch 230 loss: 0.0006079501588828861
batch 235 loss: 0.0006062401458621025
batch 240 loss: 0.0006047669798135757
Training Loss: 0.0012508562009315937
Validation Loss: 0.0005943878175457939
Epoch 2:
batch 5 loss: 0.0006035761907696724
batch 10 loss: 0.0006022186717018485
batch 15 loss: 0.0006011664634570479
batch 20 loss: 0.0006000474095344543
batch 25 loss: 0.0005990841193124652
batch 30 loss: 0.0005981037393212318
batch 35 loss: 0.0005972260609269142
batch 40 loss: 0.0005964821786619723
batch 45 loss: 0.0005953959655016661
batch 50 loss: 0.0005945254815742373
batch 55 loss: 0.0005936289788223803
batch 60 loss: 0.0005927307531237603
batch 65 loss: 0.0005917309666983783
batch 70 loss: 0.0005906514124944806
batch 75 loss: 0.0005896512069739401
batch 80 loss: 0.000588638533372432
batch 85 loss: 0.0005875128787010908
batch 90 loss: 0.0005864078528247773
batch 95 loss: 0.000585187366232276
batch 100 loss: 0.0005840675556100905
batch 105 loss: 0.000583194277714938
batch 110 loss: 0.0005823494400829076
batch 115 loss: 0.0005816271295771003
batch 120 loss: 0.00058110726531595
batch 125 loss: 0.0005807462497614324
batch 130 loss: 0.0005803092499263585
batch 135 loss: 0.0005799368023872376
batch 140 loss: 0.0005794156808406114
batch 145 loss: 0.0005793590913526714
batch 150 loss: 0.0005790132330730557
batch 155 loss: 0.0005786802736110985
batch 160 loss: 0.0005783158354461193
batch 165 loss: 0.0005779714207164943
batch 170 loss: 0.00057765954406932
batch 175 loss: 0.000577343674376607
batch 180 loss: 0.0005769259762018919
batch 185 loss: 0.0005765739479102194
batch 190 loss: 0.0005765947164036334
batch 195 loss: 0.0005771176191046834
batch 200 loss: 0.0005765037145465613
batch 205 loss: 0.0005759060150012374
batch 210 loss: 0.0005755734397098422
batch 215 loss: 0.0005751075106672943
batch 220 loss: 0.0005748686380684376
batch 225 loss: 0.0005746102076955139
batch 230 loss: 0.000574322568718344
batch 235 loss: 0.0005916389171034097
batch 240 loss: 0.0005814042990095914
Training Loss: 0.0005850460525834933
Validation Loss: 0.0006254983668137963
Epoch 3:
batch 5 loss: 0.0005791158997453749
batch 10 loss: 0.0005784529610536992
batch 15 loss: 0.0005775200319476425
batch 20 loss: 0.0005766981979832053
batch 25 loss: 0.0005760463769547641
batch 30 loss: 0.0005754925194196403
batch 35 loss: 0.0005752049619331956
batch 40 loss: 0.0005749719333834946
batch 45 loss: 0.0005747164832428098
batch 50 loss: 0.0005743276211433113
batch 55 loss: 0.0005742819630540907
batch 60 loss: 0.0005741087137721479
batch 65 loss: 0.0005738568725064397
batch 70 loss: 0.0005735664977692068
batch 75 loss: 0.0005734958336688578
batch 80 loss: 0.0005731865414418281
batch 85 loss: 0.0005730251199565828
batch 90 loss: 0.0005729815224185586
batch 95 loss: 0.0005726810544729233
batch 100 loss: 0.0005724637769162655
batch 105 loss: 0.0005722531699575484
batch 110 loss: 0.0005722302827052772
batch 115 loss: 0.0005720803281292319
batch 120 loss: 0.0005717976484447718
batch 125 loss: 0.0005716905230656266
batch 130 loss: 0.0005714743747375906
batch 135 loss: 0.0005712961195968091
batch 140 loss: 0.0005710880737751723
batch 145 loss: 0.0005709096672944725
batch 150 loss: 0.0005708347423933446
batch 155 loss: 0.0005706290481612087
batch 160 loss: 0.000573166913818568
batch 165 loss: 0.00057051966432482
batch 170 loss: 0.0005704146111384034
batch 175 loss: 0.0005700575886294246
batch 180 loss: 0.000569947191979736
batch 185 loss: 0.000569623860064894
batch 190 loss: 0.0005694811698049307
batch 195 loss: 0.00056933086598292
batch 200 loss: 0.000569242041092366
batch 205 loss: 0.0005689001292921603
batch 210 loss: 0.0005689599318429827
batch 215 loss: 0.0005686945980414749
batch 220 loss: 0.0005685580428689719
batch 225 loss: 0.0005686071119271219
batch 230 loss: 0.0005684261675924062
batch 235 loss: 0.0005683730123564601
batch 240 loss: 0.0005682561080902815
Training Loss: 0.0005721466222894378
Validation Loss: 0.0005669140121123443
Epoch 4:
batch 5 loss: 0.0005681374925188721
batch 10 loss: 0.0005680136382579803
batch 15 loss: 0.0005681148497387767
batch 20 loss: 0.0005678239860571921
batch 25 loss: 0.0005678108427673578
batch 30 loss: 0.0005676714703440666
batch 35 loss: 0.0005676587345078588
batch 40 loss: 0.0005675619002431631
batch 45 loss: 0.0005674174288287758
batch 50 loss: 0.0005674654035829008
batch 55 loss: 0.0005673890584148467
batch 60 loss: 0.0005672158673405647
batch 65 loss: 0.0005672182305715978
batch 70 loss: 0.0005671488819643855
batch 75 loss: 0.0005670926999300719
batch 80 loss: 0.0005670295795425773
batch 85 loss: 0.0005669872276484966
batch 90 loss: 0.000566876761149615
batch 95 loss: 0.0005668362835422158
batch 100 loss: 0.0005669730482622982
batch 105 loss: 0.0005667945253662765
batch 110 loss: 0.0005667689838446677
batch 115 loss: 0.0005665668519213796
batch 120 loss: 0.0005665886681526899
batch 125 loss: 0.0005664741154760122
batch 130 loss: 0.0005665303091518581
batch 135 loss: 0.0005663803545758128
batch 140 loss: 0.000566321425139904
batch 145 loss: 0.000566278281621635
batch 150 loss: 0.0005661184317432344
batch 155 loss: 0.0005661533796228468
batch 160 loss: 0.000566225335933268
batch 165 loss: 0.0005662648123688996
batch 170 loss: 0.0005661602248437702
batch 175 loss: 0.0005663741147145628
batch 180 loss: 0.0005663391551934182
batch 185 loss: 0.0005668122204951942
batch 190 loss: 0.0005667130229994654
batch 195 loss: 0.0005665807286277414
batch 200 loss: 0.0005661801085807383
batch 205 loss: 0.0005661626229993999
batch 210 loss: 0.0005659522954374552
batch 215 loss: 0.0005658203503116965
batch 220 loss: 0.0005655452841892838
batch 225 loss: 0.0005653147702105344
batch 230 loss: 0.0005654930952005089
batch 235 loss: 0.0005652475752867758
batch 240 loss: 0.0005653415108099579
Training Loss: 0.0005667072070840125
Validation Loss: 0.0005650357479074349
Epoch 5:
batch 5 loss: 0.0005652162595652044
batch 10 loss: 0.0005651816027238965
batch 15 loss: 0.000565101148094982
batch 20 loss: 0.0005651101353578269
batch 25 loss: 0.0005650567822158336
batch 30 loss: 0.0005649733589962125
batch 35 loss: 0.0005650043021887541
batch 40 loss: 0.0005647230660542846
batch 45 loss: 0.0005649366998113692
batch 50 loss: 0.0005648300750181079
batch 55 loss: 0.0005647658719681204
batch 60 loss: 0.0005646721343509853
batch 65 loss: 0.0005647285492159426
batch 70 loss: 0.000564613554161042
batch 75 loss: 0.0005646265810355545
batch 80 loss: 0.0005647676764056087
batch 85 loss: 0.0005646029370836913
batch 90 loss: 0.0005645832978188991
batch 95 loss: 0.0005644841236062348
batch 100 loss: 0.0005644687218591571
batch 105 loss: 0.0005646327161230146
batch 110 loss: 0.0005645658122375608
batch 115 loss: 0.0005644798278808594
batch 120 loss: 0.0005642685806378722
batch 125 loss: 0.0005644350661896169
batch 130 loss: 0.0005643751472234726
batch 135 loss: 0.0005643530515953898
batch 140 loss: 0.0005644025630317628
batch 145 loss: 0.0005642007919959724
batch 150 loss: 0.00056429342366755
batch 155 loss: 0.0005645756144076585
batch 160 loss: 0.0005647073034197092
batch 165 loss: 0.0005647630081512034
batch 170 loss: 0.0005644467775709928
batch 175 loss: 0.0005643372191116214
batch 180 loss: 0.0005640764022246004
batch 185 loss: 0.0005640620249323547
batch 190 loss: 0.0005640650168061256
batch 195 loss: 0.0005640396964736282
batch 200 loss: 0.0005640188814140856
batch 205 loss: 0.0005642009433358908
batch 210 loss: 0.0005641402560286224
batch 215 loss: 0.000563903886359185
batch 220 loss: 0.0005640982650220394
batch 225 loss: 0.0005639473791234195
batch 230 loss: 0.00056405981304124
batch 235 loss: 0.0005643131327815354
batch 240 loss: 0.0005639061913825571
Training Loss: 0.0005645024097854427
Validation Loss: 0.000563751716981642
Epoch 6:
batch 5 loss: 0.0005637739785015583
batch 10 loss: 0.0005635886802338064
batch 15 loss: 0.0005637486814521253
batch 20 loss: 0.0005638377508148551
batch 25 loss: 0.000563752488233149
batch 30 loss: 0.0005639041657559574
batch 35 loss: 0.0005637526279315353
batch 40 loss: 0.0005636586342006922
batch 45 loss: 0.0005633935565128922
batch 50 loss: 0.0005635202513076365
batch 55 loss: 0.0005633017863146961
batch 60 loss: 0.0005632639164105058
batch 65 loss: 0.0005631839274428784
batch 70 loss: 0.0005632175831124187
batch 75 loss: 0.0005631648004055023
batch 80 loss: 0.0005631813197396696
batch 85 loss: 0.0005633471067994833
batch 90 loss: 0.0005631141248159111
batch 95 loss: 0.0005631005507893861
batch 100 loss: 0.0005630030645988882
batch 105 loss: 0.0005631657317280769
batch 110 loss: 0.0005631392588838935
batch 115 loss: 0.0005631077685393393
batch 120 loss: 0.0005631620995700359
batch 125 loss: 0.0005631502252072095
batch 130 loss: 0.0005629603401757777
batch 135 loss: 0.0005629586870782077
batch 140 loss: 0.0005630195140838623
batch 145 loss: 0.0005628656013868749
batch 150 loss: 0.0005632677581161261
batch 155 loss: 0.0005631631356664002
batch 160 loss: 0.0005631216568872333
batch 165 loss: 0.0005633619264699518
batch 170 loss: 0.0005633927998133003
batch 175 loss: 0.0005631658947095275
batch 180 loss: 0.0005630363477393985
batch 185 loss: 0.0005628256709314883
batch 190 loss: 0.0005628196522593498
batch 195 loss: 0.0005628420854918659
batch 200 loss: 0.0005627406877465546
batch 205 loss: 0.0005626780795864761
batch 210 loss: 0.000562754925340414
batch 215 loss: 0.0005628011887893081
batch 220 loss: 0.0005628444370813668
batch 225 loss: 0.0005627601873129606
batch 230 loss: 0.0005626438767649233
batch 235 loss: 0.0005626399302855134
batch 240 loss: 0.0005625650286674499
Training Loss: 0.000563161739410134
Validation Loss: 0.0005623701018824552
Epoch 7:
batch 5 loss: 0.0005624949000775814
batch 10 loss: 0.0005624371697194874
batch 15 loss: 0.0005625563673675061
batch 20 loss: 0.0005623321980237961
batch 25 loss: 0.0005625160643830896
batch 30 loss: 0.0005624417099170387
batch 35 loss: 0.0005623422097414732
batch 40 loss: 0.0005624200566671789
batch 45 loss: 0.0005625197780318558
batch 50 loss: 0.000562583317514509
batch 55 loss: 0.000562460592482239
batch 60 loss: 0.0005623531411401928
batch 65 loss: 0.0005622585886158049
batch 70 loss: 0.000562351441476494
batch 75 loss: 0.0005625364370644093
batch 80 loss: 0.000562535400968045
batch 85 loss: 0.0005622370634227991
batch 90 loss: 0.0005623047007247805
batch 95 loss: 0.0005622906144708395
batch 100 loss: 0.0005623177625238895
batch 105 loss: 0.0005623871111311018
batch 110 loss: 0.0005623921053484083
batch 115 loss: 0.0005623490666039288
batch 120 loss: 0.0005622793454676866
batch 125 loss: 0.0005623435718007386
batch 130 loss: 0.000562241836450994
batch 135 loss: 0.000562219601124525
batch 140 loss: 0.0005621359217911958
batch 145 loss: 0.0005621564690954983
batch 150 loss: 0.0005623380886390806
batch 155 loss: 0.0005622524069622159
batch 160 loss: 0.000562099099624902
batch 165 loss: 0.0005622574128210545
batch 170 loss: 0.000562139367684722
batch 175 loss: 0.0005620886571705341
batch 180 loss: 0.000562337995506823
batch 185 loss: 0.0005622771219350398
batch 190 loss: 0.0005623427918180823
batch 195 loss: 0.0005620792275294661
batch 200 loss: 0.0005622943979687988
batch 205 loss: 0.0005622244905680418
batch 210 loss: 0.0005620673997327686
batch 215 loss: 0.0005621751537546515
batch 220 loss: 0.0005620064097456634
batch 225 loss: 0.0005620617070235312
batch 230 loss: 0.0005620644660666585
batch 235 loss: 0.0005621287971735
batch 240 loss: 0.0005623754695989192
Training Loss: 0.0005623001042598237
Validation Loss: 0.0005626433955815931
Epoch 8:
batch 5 loss: 0.0005621705087833107
batch 10 loss: 0.0005622303113341331
batch 15 loss: 0.0005623688572086394
batch 20 loss: 0.0005623166216537356
batch 25 loss: 0.0005623754230327904
batch 30 loss: 0.0005621901946142316
batch 35 loss: 0.0005622720345854759
batch 40 loss: 0.000562259554862976
batch 45 loss: 0.0005625144694931805
batch 50 loss: 0.0005624865763820708
batch 55 loss: 0.0005623764591291547
batch 60 loss: 0.0005620088195428252
batch 65 loss: 0.0005622019758448005
batch 70 loss: 0.0005620233481749892
batch 75 loss: 0.0005621380754746496
batch 80 loss: 0.0005621812772005797
batch 85 loss: 0.000562311743851751
batch 90 loss: 0.0005620890180580318
batch 95 loss: 0.0005621528252959251
batch 100 loss: 0.000562032510060817
batch 105 loss: 0.0005622608470730484
batch 110 loss: 0.000561949412804097
batch 115 loss: 0.0005619428469799459
batch 120 loss: 0.0005620037904009223
batch 125 loss: 0.000562120892573148
batch 130 loss: 0.0005619965842925013
batch 135 loss: 0.0005618858034722507
batch 140 loss: 0.0005619946285150945
batch 145 loss: 0.0005620878306217492
batch 150 loss: 0.0005621561664156616
batch 155 loss: 0.0005620937561616301
batch 160 loss: 0.0005619716248475015
batch 165 loss: 0.0005619582487270236
batch 170 loss: 0.0005620240583084524
batch 175 loss: 0.0005625326535664499
batch 180 loss: 0.0005624838406220079
batch 185 loss: 0.0005622298805974424
batch 190 loss: 0.000562158680986613
batch 195 loss: 0.0005621069576591253
batch 200 loss: 0.0005622142925858498
batch 205 loss: 0.0005619596806354821
batch 210 loss: 0.0005620979121886194
batch 215 loss: 0.0005620377371087671
batch 220 loss: 0.0005620741285383701
batch 225 loss: 0.0005619524978101254
batch 230 loss: 0.0005619199713692069
batch 235 loss: 0.0005618235445581377
batch 240 loss: 0.0005619287723675371
Training Loss: 0.0005621389092993923
Validation Loss: 0.0005614595371298492
Epoch 9:
batch 5 loss: 0.0005617978167720139
batch 10 loss: 0.000562085083220154
batch 15 loss: 0.0005621132324449718
batch 20 loss: 0.0005622336990199983
batch 25 loss: 0.0005620900075882674
batch 30 loss: 0.0005620239768177271
batch 35 loss: 0.0005619144765660166
batch 40 loss: 0.0005617387592792511
batch 45 loss: 0.0005619622068479657
batch 50 loss: 0.000561911822296679
batch 55 loss: 0.0005618058261461556
batch 60 loss: 0.0005621624994091689
batch 65 loss: 0.0005622373544611036
batch 70 loss: 0.0005620735348202289
batch 75 loss: 0.000561996956821531
batch 80 loss: 0.0005618532537482679
batch 85 loss: 0.0005618639872409404
batch 90 loss: 0.0005618387716822326
batch 95 loss: 0.0005618550232611597
batch 100 loss: 0.0005619864212349057
batch 105 loss: 0.0005619670846499503
batch 110 loss: 0.0005618838360533119
batch 115 loss: 0.0005621081800200045
batch 120 loss: 0.0005622387863695622
batch 125 loss: 0.0005621270858682692
batch 130 loss: 0.0005619779461994767
batch 135 loss: 0.0005619441973976791
batch 140 loss: 0.0005620048963464796
batch 145 loss: 0.0005618608905933797
batch 150 loss: 0.0005618262453936041
batch 155 loss: 0.000561984465457499
batch 160 loss: 0.0005620380863547326
batch 165 loss: 0.0005621922900900245
batch 170 loss: 0.0005620307521894575
batch 175 loss: 0.0005616922862827778
batch 180 loss: 0.0005615666508674621
batch 185 loss: 0.0005617122165858746
batch 190 loss: 0.000562189903575927
batch 195 loss: 0.0005619281553663313
batch 200 loss: 0.0005617632297798992
batch 205 loss: 0.000561769469641149
batch 210 loss: 0.0005617251619696618
batch 215 loss: 0.0005617816932499409
batch 220 loss: 0.0005618105875328183
batch 225 loss: 0.0005618804134428501
batch 230 loss: 0.0005615359637886286
batch 235 loss: 0.0005616734968498349
batch 240 loss: 0.0005617455579340457
Training Loss: 0.0005619271716568619
Validation Loss: 0.0005615776530855025
Epoch 10:
batch 5 loss: 0.0005618638126179576
batch 10 loss: 0.0005618771887384355
batch 15 loss: 0.0005618527182377874
batch 20 loss: 0.0005616997601464391
batch 25 loss: 0.0005615054280497134
batch 30 loss: 0.0005617010989226401
batch 35 loss: 0.0005619257921352982
batch 40 loss: 0.0005619740579277277
batch 45 loss: 0.0005620631040073931
batch 50 loss: 0.0005620114621706307
batch 55 loss: 0.0005618723575025797
batch 60 loss: 0.0005616627284325659
batch 65 loss: 0.0005618230672553182
batch 70 loss: 0.0005618391674943269
batch 75 loss: 0.0005614797468297183
batch 80 loss: 0.0005615609465166926
batch 85 loss: 0.0005615489673800767
batch 90 loss: 0.0005616824491880834
batch 95 loss: 0.0005617767223156988
batch 100 loss: 0.0005619501695036888
batch 105 loss: 0.000562051055021584
batch 110 loss: 0.0005620603449642658
batch 115 loss: 0.0005618256749585271
batch 120 loss: 0.0005617295508272945
batch 125 loss: 0.0005617220769636333
batch 130 loss: 0.000561584800016135
batch 135 loss: 0.0005615919246338308
batch 140 loss: 0.0005618853378109634
batch 145 loss: 0.0005617291782982648
batch 150 loss: 0.0005620203912258149
batch 155 loss: 0.0005617654765956104
batch 160 loss: 0.0005617280839942396
batch 165 loss: 0.0005616053938865661
batch 170 loss: 0.0005617781076580286
batch 175 loss: 0.0005616518435999751
batch 180 loss: 0.000561539432965219
batch 185 loss: 0.0005616419482976198
batch 190 loss: 0.0005618301103822887
batch 195 loss: 0.000562052009627223
batch 200 loss: 0.000561901752371341
batch 205 loss: 0.000561853963881731
batch 210 loss: 0.0005617497256025672
batch 215 loss: 0.0005618407973088324
batch 220 loss: 0.0005621111835353076
batch 225 loss: 0.0005619245115667581
batch 230 loss: 0.0006592998164705932
batch 235 loss: 0.0006580808665603399
batch 240 loss: 0.0006327395793050527
Training Loss: 0.0005673117850771329
Validation Loss: 0.0006598986306926236
Epoch 11:
batch 5 loss: 0.0006172758177854121
batch 10 loss: 0.0005968278390355408
batch 15 loss: 0.0005822344799526035
batch 20 loss: 0.0005751997116021812
batch 25 loss: 0.0005721363355405629
batch 30 loss: 0.0005694738705642521
batch 35 loss: 0.0005677055683918298
batch 40 loss: 0.0005663144402205944
batch 45 loss: 0.0005655050161294639
batch 50 loss: 0.0005648383288644254
batch 55 loss: 0.0005641959491185844
batch 60 loss: 0.0005639671115204691
batch 65 loss: 0.0005637726746499539
batch 70 loss: 0.0005636276910081506
batch 75 loss: 0.00056322863092646
batch 80 loss: 0.0005630519590340555
batch 85 loss: 0.0005631343112327159
batch 90 loss: 0.0005630669533275068
batch 95 loss: 0.0005632151034660638
batch 100 loss: 0.0005630045430734754
batch 105 loss: 0.0005628518178127706
batch 110 loss: 0.0005628082668408752
batch 115 loss: 0.0005626650061458349
batch 120 loss: 0.0005627056234516203
batch 125 loss: 0.0005631331587210298
batch 130 loss: 0.0005624965648166836
batch 135 loss: 0.0005624009179882705
batch 140 loss: 0.000562360673211515
batch 145 loss: 0.0005621175281703472
batch 150 loss: 0.000562295620329678
batch 155 loss: 0.0005625214893370867
batch 160 loss: 0.000562602817080915
batch 165 loss: 0.000562393618747592
batch 170 loss: 0.000562610023189336
batch 175 loss: 0.0005630405503325164
batch 180 loss: 0.0005626052618026734
batch 185 loss: 0.0005622111377306283
batch 190 loss: 0.0005622811382636428
batch 195 loss: 0.0005620422307401896
batch 200 loss: 0.0005623089149594307
batch 205 loss: 0.0005625106627121568
batch 210 loss: 0.0005627039587125182
batch 215 loss: 0.0005623529781587422
batch 220 loss: 0.0005621156422421336
batch 225 loss: 0.0005619962234050035
batch 230 loss: 0.000562014279421419
batch 235 loss: 0.0005622281227260828
batch 240 loss: 0.0005620259558781982
Training Loss: 0.0005658370107994414
Validation Loss: 0.0005623032106086612
Epoch 12:
batch 5 loss: 0.0005623498349450528
batch 10 loss: 0.0005620286101475358
batch 15 loss: 0.0005617563845589757
batch 20 loss: 0.0005619383649900555
batch 25 loss: 0.0005617810762487352
batch 30 loss: 0.000561756466049701
batch 35 loss: 0.0005616997485049068
batch 40 loss: 0.0005620778887532651
batch 45 loss: 0.0005622253287583589
batch 50 loss: 0.000562061055097729
batch 55 loss: 0.0005618485156446695
batch 60 loss: 0.0005622490542009472
batch 65 loss: 0.0005622293916530907
batch 70 loss: 0.0005619864561595023
batch 75 loss: 0.0005618669209070503
batch 80 loss: 0.0005616943002678454
batch 85 loss: 0.0005615633097477257
batch 90 loss: 0.0005620999028906227
batch 95 loss: 0.0005617024144157767
batch 100 loss: 0.000561471190303564
batch 105 loss: 0.0005619510309770703
batch 110 loss: 0.0005617827759124338
batch 115 loss: 0.0005619183415547013
batch 120 loss: 0.0005618169670924544
batch 125 loss: 0.000561691471375525
batch 130 loss: 0.0005620084004476667
batch 135 loss: 0.0005614988040179014
batch 140 loss: 0.0005617642891593277
batch 145 loss: 0.0005616291076876223
batch 150 loss: 0.0005618576309643686
batch 155 loss: 0.0005618522642180324
batch 160 loss: 0.0005618892144411802
batch 165 loss: 0.0005624753423035145
batch 170 loss: 0.0005621969816274941
batch 175 loss: 0.0005621547228656709
batch 180 loss: 0.0005618528346531093
batch 185 loss: 0.0005619770148769021
batch 190 loss: 0.0005619803443551064
batch 195 loss: 0.0005617495742626488
batch 200 loss: 0.0005617871996946633
batch 205 loss: 0.0005615197704173624
batch 210 loss: 0.0005614182096906007
batch 215 loss: 0.0005613179178908468
batch 220 loss: 0.0005617628106847405
batch 225 loss: 0.0005618163500912488
batch 230 loss: 0.0005617039278149605
batch 235 loss: 0.0005613550310954452
batch 240 loss: 0.0005619131959974765
Training Loss: 0.000561854744591983
Validation Loss: 0.0005613668637427812
Epoch 13:
batch 5 loss: 0.0005618901806883514
batch 10 loss: 0.0005617044516839087
batch 15 loss: 0.000561942474450916
batch 20 loss: 0.0005617381189949811
batch 25 loss: 0.0005614508292637766
batch 30 loss: 0.0005616537528112531
batch 35 loss: 0.000561551854480058
batch 40 loss: 0.0005615720641799271
batch 45 loss: 0.000561795593239367
batch 50 loss: 0.0005618394119665026
batch 55 loss: 0.0005621373769827187
batch 60 loss: 0.00056204047286883
batch 65 loss: 0.0005619717645458877
batch 70 loss: 0.0005617208778858184
batch 75 loss: 0.0005613220622763037
batch 80 loss: 0.0005617927410639823
batch 85 loss: 0.0005618529161438346
batch 90 loss: 0.0005615799454972148
batch 95 loss: 0.0005615820293314755
batch 100 loss: 0.0005615513655357063
batch 105 loss: 0.0005617984337732196
batch 110 loss: 0.0005615476169623434
batch 115 loss: 0.0005617546499706805
batch 120 loss: 0.0005616451962850988
batch 125 loss: 0.0005616063135676086
batch 130 loss: 0.0005617546616122126
batch 135 loss: 0.0005615679314360022
batch 140 loss: 0.0005614029709249735
batch 145 loss: 0.0005614840774796903
batch 150 loss: 0.0005616697017103434
batch 155 loss: 0.0005615721456706524
batch 160 loss: 0.0005612917011603713
batch 165 loss: 0.0005615679081529378
batch 170 loss: 0.0005615700385533274
batch 175 loss: 0.000561585498508066
batch 180 loss: 0.0005615151603706181
batch 185 loss: 0.0005612218752503395
batch 190 loss: 0.000561362225562334
batch 195 loss: 0.0005615683272480965
batch 200 loss: 0.0005612862412817776
batch 205 loss: 0.0005613363580778241
batch 210 loss: 0.0005612305831164122
batch 215 loss: 0.0005614636000245809
batch 220 loss: 0.0005615836358629167
batch 225 loss: 0.0005588978645391762
batch 230 loss: 0.0005576850846409798
batch 235 loss: 0.0005577658070251345
batch 240 loss: 0.0005575865507125854
Training Loss: 0.0005613127592368983
Validation Loss: 0.0005576952341167877
Epoch 14:
batch 5 loss: 0.0005576671566814185
batch 10 loss: 0.000557787180878222
batch 15 loss: 0.0005577740841545165
batch 20 loss: 0.0005576984491199255
batch 25 loss: 0.0005576746189035475
batch 30 loss: 0.0005577223142609
batch 35 loss: 0.0005576847353950143
batch 40 loss: 0.0005577225820161402
batch 45 loss: 0.0005576498806476593
batch 50 loss: 0.0005576375871896744
batch 55 loss: 0.0005575984367169439
batch 60 loss: 0.000557670637499541
batch 65 loss: 0.0005577185307629407
batch 70 loss: 0.0005576800904236734
batch 75 loss: 0.0005576868075877428
batch 80 loss: 0.0005576048395596444
batch 85 loss: 0.0005576872965320945
batch 90 loss: 0.0005577037925831973
batch 95 loss: 0.0005576426978223026
batch 100 loss: 0.0005575137096457183
batch 105 loss: 0.000557656935416162
batch 110 loss: 0.000557697843760252
batch 115 loss: 0.0005577436531893909
batch 120 loss: 0.0005575808696448803
batch 125 loss: 0.0005577134317718447
batch 130 loss: 0.0005577346310019493
batch 135 loss: 0.0005577459698542953
batch 140 loss: 0.0005577407428063452
batch 145 loss: 0.0005576821393333375
batch 150 loss: 0.0005577209638431668
batch 155 loss: 0.0005575589137151837
batch 160 loss: 0.0005576828494668007
batch 165 loss: 0.0005576752591878176
batch 170 loss: 0.0005575853865593672
batch 175 loss: 0.0005576296243816614
batch 180 loss: 0.0005576340947300196
batch 185 loss: 0.0005576521158218384
batch 190 loss: 0.0005578061332926154
batch 195 loss: 0.0005577435833401978
batch 200 loss: 0.000557674653828144
batch 205 loss: 0.0005577034666202962
batch 210 loss: 0.0005578021635301411
batch 215 loss: 0.0005576907307840884
batch 220 loss: 0.0005576151073910296
batch 225 loss: 0.0005576909170486033
batch 230 loss: 0.0005576953757554292
batch 235 loss: 0.0005577097297646105
batch 240 loss: 0.0005577277741394937
Training Loss: 0.000557683760174162
Validation Loss: 0.0005576933996053413
Epoch 15:
batch 5 loss: 0.0005576749448664486
batch 10 loss: 0.0005577290779910981
batch 15 loss: 0.0005576645489782095
batch 20 loss: 0.0005576679133810103
batch 25 loss: 0.0005577145959250629
batch 30 loss: 0.0005577522912062705
batch 35 loss: 0.0005576988914981484
batch 40 loss: 0.0005576794967055321
batch 45 loss: 0.0005576051422394812
batch 50 loss: 0.0005576451192609965
batch 55 loss: 0.0005577576230280101
batch 60 loss: 0.0005576307419687509
batch 65 loss: 0.0005576847237534821
batch 70 loss: 0.0005577850271947682
batch 75 loss: 0.0005576363415457309
batch 80 loss: 0.0005576876224949956
batch 85 loss: 0.0005576123367063701
batch 90 loss: 0.0005576532101258635
batch 95 loss: 0.0005577334435656667
batch 100 loss: 0.0005576776922680438
batch 105 loss: 0.000557563896290958
batch 110 loss: 0.000557749334257096
batch 115 loss: 0.0005576234892942011
batch 120 loss: 0.0005576600902713835
batch 125 loss: 0.0005576798925176263
batch 130 loss: 0.0005576431285589933
batch 135 loss: 0.0005577029893174768
batch 140 loss: 0.0005576287163421512
batch 145 loss: 0.0005576512659899891
batch 150 loss: 0.0005576391238719224
batch 155 loss: 0.0005577706033363938
batch 160 loss: 0.0005576662253588438
batch 165 loss: 0.0005577187403105199
batch 170 loss: 0.0005576441064476967
batch 175 loss: 0.000557705934625119
batch 180 loss: 0.0005576494499109685
batch 185 loss: 0.0005576053750701249
batch 190 loss: 0.0005577281001023949
batch 195 loss: 0.0005577265517786145
batch 200 loss: 0.0005577234318479895
batch 205 loss: 0.0005578057374805212
batch 210 loss: 0.0005577307427302002
batch 215 loss: 0.000557578878942877
batch 220 loss: 0.0005576182506047189
batch 225 loss: 0.0005577727453783155
batch 230 loss: 0.0005576711148023606
batch 235 loss: 0.00055767617886886
batch 240 loss: 0.0005577776348218322
Training Loss: 0.0005576833857048769
Validation Loss: 0.0005576934083364904
Epoch 16:
batch 5 loss: 0.0005577107775025069
batch 10 loss: 0.0005576080875471234
batch 15 loss: 0.0005577554809860885
batch 20 loss: 0.0005576689844019711
batch 25 loss: 0.0005577316274866462
batch 30 loss: 0.0005576601601205766
batch 35 loss: 0.0005576174589805305
batch 40 loss: 0.0005576433730311691
batch 45 loss: 0.0005575912655331194
batch 50 loss: 0.0005577804055064917
batch 55 loss: 0.0005576997064054012
batch 60 loss: 0.0005576529540121556
batch 65 loss: 0.0005576676339842379
batch 70 loss: 0.000557764363475144
batch 75 loss: 0.0005577155039645732
batch 80 loss: 0.0005576235009357334
batch 85 loss: 0.0005576718365773558
batch 90 loss: 0.0005576976342126727
batch 95 loss: 0.0005577521864324808
batch 100 loss: 0.000557653815485537
batch 105 loss: 0.000557721487712115
batch 110 loss: 0.0005577243748120964
batch 115 loss: 0.0005576464463956654
batch 120 loss: 0.0005576979368925094
batch 125 loss: 0.0005576200666837395
batch 130 loss: 0.0005576828145422042
batch 135 loss: 0.0005577353993430733
batch 140 loss: 0.0005576382973231375
batch 145 loss: 0.000557692814618349
batch 150 loss: 0.0005577041767537594
batch 155 loss: 0.0005576006602495909
batch 160 loss: 0.0005577190080657601
batch 165 loss: 0.0005577556323260069
batch 170 loss: 0.0005577777745202183
batch 175 loss: 0.0005575569113716484
batch 180 loss: 0.0005577155272476376
batch 185 loss: 0.0005577414645813406
batch 190 loss: 0.0005578534095548093
batch 195 loss: 0.0005576572963036597
batch 200 loss: 0.0005577079486101866
batch 205 loss: 0.0005575879593379795
batch 210 loss: 0.0005577626288868487
batch 215 loss: 0.0005576739902608096
batch 220 loss: 0.0005576106137596071
batch 225 loss: 0.0005576346884481609
batch 230 loss: 0.0005576841766014695
batch 235 loss: 0.0005575566552579403
batch 240 loss: 0.000557675352320075
Training Loss: 0.0005576833806117065
Validation Loss: 0.0005576934025157243
Epoch 17:
batch 5 loss: 0.0005577329779043793
batch 10 loss: 0.0005577088217251003
batch 15 loss: 0.0005577025818638504
batch 20 loss: 0.0005576406023465097
batch 25 loss: 0.000557692744769156
batch 30 loss: 0.0005576741648837924
batch 35 loss: 0.0005577425239607692
batch 40 loss: 0.0005576772848144174
batch 45 loss: 0.0005575967603363097
batch 50 loss: 0.0005576481693424284
batch 55 loss: 0.0005577409057877958
batch 60 loss: 0.0005577286123298108
batch 65 loss: 0.0005577003350481391
batch 70 loss: 0.0005576415685936808
batch 75 loss: 0.0005577065167017281
batch 80 loss: 0.000557653175201267
batch 85 loss: 0.0005576718831434846
batch 90 loss: 0.0005576818017289043
batch 95 loss: 0.0005577330011874437
batch 100 loss: 0.0005576835596002638
batch 105 loss: 0.0005576511961407959
batch 110 loss: 0.0005577048636041581
batch 115 loss: 0.0005576355033554137
batch 120 loss: 0.0005576461786404252
batch 125 loss: 0.0005576783092692495
batch 130 loss: 0.0005575740011408925
batch 135 loss: 0.0005576273309998214
batch 140 loss: 0.0005576682975515723
batch 145 loss: 0.0005576641648076475
batch 150 loss: 0.0005576880415901541
batch 155 loss: 0.0005577190779149533
batch 160 loss: 0.0005577623611316085
batch 165 loss: 0.0005576328025199473
batch 170 loss: 0.0005577886942774058
batch 175 loss: 0.0005577034549787641
batch 180 loss: 0.0005576024064794183
batch 185 loss: 0.0005577225121669472
batch 190 loss: 0.0005577039904892444
batch 195 loss: 0.000557680951897055
batch 200 loss: 0.000557645398657769
batch 205 loss: 0.000557673501316458
batch 210 loss: 0.0005576892057433724
batch 215 loss: 0.0005576965631917119
batch 220 loss: 0.0005576805793680251
batch 225 loss: 0.0005577695555984974
batch 230 loss: 0.0005576150259003043
batch 235 loss: 0.0005577603122219443
batch 240 loss: 0.0005576601368375122
Training Loss: 0.0005576833835220895
Validation Loss: 0.0005576934015455966
Epoch 18:
batch 5 loss: 0.0005577196250669658
batch 10 loss: 0.0005576958297751844
batch 15 loss: 0.0005577474134042859
batch 20 loss: 0.0005575684946961701
batch 25 loss: 0.0005576235940679908
batch 30 loss: 0.0005577583913691341
batch 35 loss: 0.000557704665698111
batch 40 loss: 0.0005576090421527624
batch 45 loss: 0.0005576841300353408
batch 50 loss: 0.0005576385068707168
batch 55 loss: 0.0005577797302976251
batch 60 loss: 0.0005576852476224303
batch 65 loss: 0.0005576659692451358
batch 70 loss: 0.0005577228497713804
batch 75 loss: 0.0005576938739977777
batch 80 loss: 0.0005576225579716265
batch 85 loss: 0.0005577517091296613
batch 90 loss: 0.0005577308358624578
batch 95 loss: 0.0005576539202593267
batch 100 loss: 0.0005575995892286301
batch 105 loss: 0.0005577047704719007
batch 110 loss: 0.0005577473202720284
batch 115 loss: 0.0005577481351792812
batch 120 loss: 0.0005576968658715486
batch 125 loss: 0.000557654513977468
batch 130 loss: 0.0005576992291025818
batch 135 loss: 0.0005576393334195018
batch 140 loss: 0.000557550648227334
batch 145 loss: 0.0005576485302299262
batch 150 loss: 0.0005576762137934566
batch 155 loss: 0.0005576772149652242
batch 160 loss: 0.0005575520452111959
batch 165 loss: 0.00055753025226295
batch 170 loss: 0.0005576479248702526
batch 175 loss: 0.0005577292991802097
batch 180 loss: 0.0005576528841629624
batch 185 loss: 0.0005576006369665265
batch 190 loss: 0.0005576224415563047
batch 195 loss: 0.0005577411269769072
batch 200 loss: 0.0005577124888077378
batch 205 loss: 0.0005577453412115574
batch 210 loss: 0.0005576310912147164
batch 215 loss: 0.0005577064934186637
batch 220 loss: 0.0005578191252425313
batch 225 loss: 0.0005577210919000209
batch 230 loss: 0.0005577465635724366
batch 235 loss: 0.0005577953648753464
batch 240 loss: 0.0005577497999183833
Training Loss: 0.0005576833900704514
Validation Loss: 0.0005576934044559796
Epoch 19:
batch 5 loss: 0.0005576928262598813
batch 10 loss: 0.0005576650029979647
batch 15 loss: 0.0005576572963036597
batch 20 loss: 0.0005576654104515911
batch 25 loss: 0.0005576758063398302
batch 30 loss: 0.0005577117204666138
batch 35 loss: 0.000557756400667131
batch 40 loss: 0.0005578137701377272
batch 45 loss: 0.0005576275056228041
batch 50 loss: 0.000557698542252183
batch 55 loss: 0.0005576482624746859
batch 60 loss: 0.0005577791132964193
batch 65 loss: 0.0005576957715675235
batch 70 loss: 0.0005576693103648723
batch 75 loss: 0.0005576919298619032
batch 80 loss: 0.000557677005417645
batch 85 loss: 0.0005577135598286986
batch 90 loss: 0.0005576999275945127
batch 95 loss: 0.0005577130825258792
batch 100 loss: 0.0005576852126978338
batch 105 loss: 0.0005576727911829948
batch 110 loss: 0.0005577122676186264
batch 115 loss: 0.0005576682393439114
batch 120 loss: 0.0005577446660026908
batch 125 loss: 0.0005577405099757016
batch 130 loss: 0.00055764215067029
batch 135 loss: 0.0005576642113737762
batch 140 loss: 0.0005576038849540055
batch 145 loss: 0.0005576719646342099
batch 150 loss: 0.0005576540133915842
batch 155 loss: 0.0005576347350142897
batch 160 loss: 0.0005577411386184395
batch 165 loss: 0.0005576944327913225
batch 170 loss: 0.0005576614523306489
batch 175 loss: 0.0005576592986471951
batch 180 loss: 0.0005576650029979647
batch 185 loss: 0.0005576182971708477
batch 190 loss: 0.0005577164702117443
batch 195 loss: 0.0005576630006544292
batch 200 loss: 0.0005577101837843657
batch 205 loss: 0.0005576410796493292
batch 210 loss: 0.0005576119059696793
batch 215 loss: 0.0005576084600761533
batch 220 loss: 0.0005577145842835307
batch 225 loss: 0.0005576778086833656
batch 230 loss: 0.0005576782976277172
batch 235 loss: 0.00055772167397663
batch 240 loss: 0.000557672674767673
Training Loss: 0.0005576833886152599
Validation Loss: 0.0005576933947547028
Epoch 20:
batch 5 loss: 0.0005577076459303498
batch 10 loss: 0.0005576235358603299
batch 15 loss: 0.0005577465635724366
batch 20 loss: 0.0005577647942118346
batch 25 loss: 0.0005577730131335557
batch 30 loss: 0.000557696574833244
batch 35 loss: 0.0005575690767727793
batch 40 loss: 0.0005577308940701187
batch 45 loss: 0.0005576259456574917
batch 50 loss: 0.0005576435010880232
batch 55 loss: 0.0005576342809945345
batch 60 loss: 0.0005576777854003012
batch 65 loss: 0.0005577177042141556
batch 70 loss: 0.0005576932453550398
batch 75 loss: 0.0005576431402005255
batch 80 loss: 0.0005575680290348828
batch 85 loss: 0.0005577332805842162
batch 90 loss: 0.0005576714640483261
batch 95 loss: 0.0005576712777838111
batch 100 loss: 0.0005576790077611804
batch 105 loss: 0.0005576444091275334
batch 110 loss: 0.000557703129015863
batch 115 loss: 0.0005576684605330228
batch 120 loss: 0.0005576301133260131
batch 125 loss: 0.0005577753181569278
batch 130 loss: 0.0005577345960773528
batch 135 loss: 0.0005577570176683366
batch 140 loss: 0.0005576729192398489
batch 145 loss: 0.0005577583448030055
batch 150 loss: 0.0005576260155066848
batch 155 loss: 0.0005577168078161776
batch 160 loss: 0.0005578100448474288
batch 165 loss: 0.0005576508701778948
batch 170 loss: 0.0005576866446062922
batch 175 loss: 0.0005576740833930672
batch 180 loss: 0.0005578023032285273
batch 185 loss: 0.0005576435127295553
batch 190 loss: 0.0005577318137511611
batch 195 loss: 0.0005575883551500738
batch 200 loss: 0.0005575931747443974
batch 205 loss: 0.0005576143274083733
batch 210 loss: 0.0005576626164838672
batch 215 loss: 0.0005576729541644454
batch 220 loss: 0.0005577352130785584
batch 225 loss: 0.0005576824187301099
batch 230 loss: 0.0005577287171036005
batch 235 loss: 0.000557662162464112
batch 240 loss: 0.0005576056777499616
Training Loss: 0.0005576833912831111
Validation Loss: 0.0005576934054261073
Epoch 21:
batch 5 loss: 0.000557587156072259
batch 10 loss: 0.000557698612101376
batch 15 loss: 0.0005575976683758199
batch 20 loss: 0.0005575974704697728
batch 25 loss: 0.0005576348397880792
batch 30 loss: 0.0005577011033892632
batch 35 loss: 0.0005575538380071521
batch 40 loss: 0.0005577566917054355
batch 45 loss: 0.0005577449803240598
batch 50 loss: 0.0005576760740950704
batch 55 loss: 0.0005575735936872661
batch 60 loss: 0.0005576919764280319
batch 65 loss: 0.0005577550735324621
batch 70 loss: 0.0005577148171141743
batch 75 loss: 0.0005575706833042205
batch 80 loss: 0.000557712372392416
batch 85 loss: 0.0005577804287895561
batch 90 loss: 0.0005576804047450423
batch 95 loss: 0.0005576472729444503
batch 100 loss: 0.0005576746654696763
batch 105 loss: 0.0005577828036621213
batch 110 loss: 0.000557768892031163
batch 115 loss: 0.0005577063770033419
batch 120 loss: 0.0005577519652433694
batch 125 loss: 0.0005575937684625387
batch 130 loss: 0.0005576685070991516
batch 135 loss: 0.0005577093455940485
batch 140 loss: 0.0005577080533839762
batch 145 loss: 0.0005575967021286488
batch 150 loss: 0.000557661207858473
batch 155 loss: 0.0005577352829277515
batch 160 loss: 0.0005577225005254149
batch 165 loss: 0.0005576729075983166
batch 170 loss: 0.0005576368654146791
batch 175 loss: 0.0005576405208557844
batch 180 loss: 0.000557781127281487
batch 185 loss: 0.0005578041658736765
batch 190 loss: 0.00055769057944417
batch 195 loss: 0.0005577091593295336
batch 200 loss: 0.0005575614748522639
batch 205 loss: 0.0005576540715992451
batch 210 loss: 0.000557676050812006
batch 215 loss: 0.0005577032687142491
batch 220 loss: 0.0005577646079473197
batch 225 loss: 0.0005576825817115605
batch 230 loss: 0.0005577040603384376
batch 235 loss: 0.0005577670061029493
batch 240 loss: 0.0005575995775870979
Training Loss: 0.0005576833990441325
Validation Loss: 0.0005576934005754689
Epoch 22:
batch 5 loss: 0.000557673629373312
batch 10 loss: 0.0005576972267590463
batch 15 loss: 0.0005576302180998027
batch 20 loss: 0.0005576509865932167
batch 25 loss: 0.000557765131816268
batch 30 loss: 0.000557750032749027
batch 35 loss: 0.0005577258998528123
batch 40 loss: 0.0005577052128501236
batch 45 loss: 0.0005576111259870231
batch 50 loss: 0.0005577176343649626
batch 55 loss: 0.0005577801610343158
batch 60 loss: 0.0005576533148996532
batch 65 loss: 0.0005576849449425936
batch 70 loss: 0.0005576818366535008
batch 75 loss: 0.0005575303686782718
batch 80 loss: 0.0005577240139245987
batch 85 loss: 0.0005576472845859826
batch 90 loss: 0.0005576818599365652
batch 95 loss: 0.0005577392876148224
batch 100 loss: 0.000557694083545357
batch 105 loss: 0.0005577433155849576
batch 110 loss: 0.0005576417315751314
batch 115 loss: 0.000557694397866726
batch 120 loss: 0.0005577019182965159
batch 125 loss: 0.0005576759460382164
batch 130 loss: 0.0005576136405579746
batch 135 loss: 0.0005576569936238229
batch 140 loss: 0.0005576963536441326
batch 145 loss: 0.0005575601011514663
batch 150 loss: 0.0005577045492827892
batch 155 loss: 0.0005576310679316521
batch 160 loss: 0.0005576574243605137
batch 165 loss: 0.000557656493037939
batch 170 loss: 0.0005576557945460081
batch 175 loss: 0.0005577619536779821
batch 180 loss: 0.0005577536183409392
batch 185 loss: 0.0005576340481638908
batch 190 loss: 0.0005577538860961795
batch 195 loss: 0.0005577348405495286
batch 200 loss: 0.0005576379713602364
batch 205 loss: 0.0005575379822403192
batch 210 loss: 0.0005576976109296083
batch 215 loss: 0.0005577596719376742
batch 220 loss: 0.0005576772033236921
batch 225 loss: 0.0005576926516368986
batch 230 loss: 0.000557684269733727
batch 235 loss: 0.000557731359731406
batch 240 loss: 0.0005577119183726609
Training Loss: 0.0005576833951636218
Validation Loss: 0.0005576933928144475
Epoch 23:
batch 5 loss: 0.0005577149568125606
batch 10 loss: 0.0005576851428486407
batch 15 loss: 0.0005576678086072206
batch 20 loss: 0.0005577437928877771
batch 25 loss: 0.0005575428949669003
batch 30 loss: 0.0005576910451054573
batch 35 loss: 0.0005577441304922103
batch 40 loss: 0.0005576592171564698
batch 45 loss: 0.0005576801602728664
batch 50 loss: 0.000557676691096276
batch 55 loss: 0.0005576602416113019
batch 60 loss: 0.0005575768183916808
batch 65 loss: 0.0005576807423494756
batch 70 loss: 0.0005577385891228914
batch 75 loss: 0.0005578100448474288
batch 80 loss: 0.000557645398657769
batch 85 loss: 0.0005576955969445408
batch 90 loss: 0.0005576361669227481
batch 95 loss: 0.0005577905452810228
batch 100 loss: 0.0005577207310125231
batch 105 loss: 0.000557721487712115
batch 110 loss: 0.0005576500436291099
batch 115 loss: 0.0005577149917371571
batch 120 loss: 0.0005576985073275864
batch 125 loss: 0.0005577290547080338
batch 130 loss: 0.0005576820229180157
batch 135 loss: 0.0005575890652835369
batch 140 loss: 0.0005577516392804682
batch 145 loss: 0.000557668216060847
batch 150 loss: 0.0005576321738772095
batch 155 loss: 0.0005576314171776176
batch 160 loss: 0.0005576656083576381
batch 165 loss: 0.0005577092990279198
batch 170 loss: 0.0005576745257712901
batch 175 loss: 0.0005577611038461328
batch 180 loss: 0.0005577514180913568
batch 185 loss: 0.0005576523952186107
batch 190 loss: 0.0005575644900090992
batch 195 loss: 0.0005576475174166262
batch 200 loss: 0.0005576677736826241
batch 205 loss: 0.0005577552015893162
batch 210 loss: 0.00055774130159989
batch 215 loss: 0.0005576458293944597
batch 220 loss: 0.0005575604503974318
batch 225 loss: 0.000557803432457149
batch 230 loss: 0.0005576510913670063
batch 235 loss: 0.0005576935480348765
batch 240 loss: 0.0005576285999268294
Training Loss: 0.000557683394193494
Validation Loss: 0.0005576934209481503
Epoch 24:
batch 5 loss: 0.0005576896597631276
batch 10 loss: 0.000557804200798273
batch 15 loss: 0.0005577089614234865
batch 20 loss: 0.0005577001720666885
batch 25 loss: 0.0005576953524723649
batch 30 loss: 0.0005577732808887959
batch 35 loss: 0.0005576475639827549
batch 40 loss: 0.0005577897536568344
batch 45 loss: 0.000557580403983593
batch 50 loss: 0.0005576657014898956
batch 55 loss: 0.0005576731171458959
batch 60 loss: 0.0005576678435318172
batch 65 loss: 0.0005577461677603423
batch 70 loss: 0.0005575563409365714
batch 75 loss: 0.0005575792049057782
batch 80 loss: 0.0005575985764153301
batch 85 loss: 0.0005576799274422228
batch 90 loss: 0.0005576758761890232
batch 95 loss: 0.0005577225238084793
batch 100 loss: 0.0005577949690632522
batch 105 loss: 0.0005577035481110215
batch 110 loss: 0.0005576741532422602
batch 115 loss: 0.000557765201665461
batch 120 loss: 0.0005576617550104856
batch 125 loss: 0.0005577262956649065
batch 130 loss: 0.0005576588562689721
batch 135 loss: 0.0005576164112426341
batch 140 loss: 0.0005576891941018403
batch 145 loss: 0.000557813630439341
batch 150 loss: 0.0005576872848905623
batch 155 loss: 0.0005576657364144922
batch 160 loss: 0.0005576377501711249
batch 165 loss: 0.0005575509974732995
batch 170 loss: 0.0005577530711889267
batch 175 loss: 0.000557737413328141
batch 180 loss: 0.0005578151089139282
batch 185 loss: 0.0005577902542427182
batch 190 loss: 0.0005577124888077378
batch 195 loss: 0.0005576425348408521
batch 200 loss: 0.0005575761082582176
batch 205 loss: 0.0005576642579399049
batch 210 loss: 0.0005576660623773932
batch 215 loss: 0.0005576549563556909
batch 220 loss: 0.0005576665978878736
batch 225 loss: 0.0005576515453867614
batch 230 loss: 0.00055760876275599
batch 235 loss: 0.0005576081923209131
batch 240 loss: 0.0005576552473939955
Training Loss: 0.0005576833961337494
Validation Loss: 0.0005576934840064496
Epoch 25:
batch 5 loss: 0.0005576639086939394
batch 10 loss: 0.0005577327916398645
batch 15 loss: 0.000557802664116025
batch 20 loss: 0.000557768577709794
batch 25 loss: 0.0005576326861046254
batch 30 loss: 0.0005575741175562144
batch 35 loss: 0.000557554210536182
batch 40 loss: 0.0005576969007961452
batch 45 loss: 0.0005576202413067222
batch 50 loss: 0.0005577528732828796
batch 55 loss: 0.0005576439551077783
batch 60 loss: 0.0005576475406996906
batch 65 loss: 0.0005577151780016721
batch 70 loss: 0.0005575786693952977
batch 75 loss: 0.0005577105330303311
batch 80 loss: 0.000557633547578007
batch 85 loss: 0.0005577692645601928
batch 90 loss: 0.0005576569237746298
batch 95 loss: 0.0005577138043008744
batch 100 loss: 0.0005576761090196669
batch 105 loss: 0.0005577563541010022
batch 110 loss: 0.0005577223375439644
batch 115 loss: 0.0005576088093221188
batch 120 loss: 0.0005576882511377334
batch 125 loss: 0.0005577875766903162
batch 130 loss: 0.0005576833616942167
batch 135 loss: 0.0005577464471571147
batch 140 loss: 0.0005576017429120839
batch 145 loss: 0.0005576970521360636
batch 150 loss: 0.0005576447118073701
batch 155 loss: 0.0005576974130235612
batch 160 loss: 0.0005576376104727387
batch 165 loss: 0.0005576220923103392
batch 170 loss: 0.0005576064344495535
batch 175 loss: 0.0005576520110480487
batch 180 loss: 0.0005576896597631276
batch 185 loss: 0.0005576349562034011
batch 190 loss: 0.0005576947238296271
batch 195 loss: 0.0005576913594268262
batch 200 loss: 0.0005576743162237108
batch 205 loss: 0.0005576878786087037
batch 210 loss: 0.0005576508585363627
batch 215 loss: 0.0005576519411988557
batch 220 loss: 0.0005577957956120372
batch 225 loss: 0.0005577432923018933
batch 230 loss: 0.0005577626056037843
batch 235 loss: 0.0005576698458753526
batch 240 loss: 0.0005577605683356523
Training Loss: 0.0005576834271778352
Validation Loss: 0.0005576934510221084
Epoch 26:
batch 5 loss: 0.0005577117553912103
batch 10 loss: 0.0005576560157351196
batch 15 loss: 0.0005576142924837768
batch 20 loss: 0.0005578607087954879
batch 25 loss: 0.0005577150848694145
batch 30 loss: 0.0005577698000706732
batch 35 loss: 0.0005576546769589186
batch 40 loss: 0.00055758518865332
batch 45 loss: 0.0005576758063398302
batch 50 loss: 0.0005576197057962417
batch 55 loss: 0.000557682360522449
batch 60 loss: 0.0005576630122959614
batch 65 loss: 0.000557688158005476
batch 70 loss: 0.0005577787407673896
batch 75 loss: 0.0005576310213655233
batch 80 loss: 0.0005577408126555383
batch 85 loss: 0.0005576574592851102
batch 90 loss: 0.0005576447234489024
batch 95 loss: 0.0005578126641921699
batch 100 loss: 0.0005576613359153271
batch 105 loss: 0.0005576357711106539
batch 110 loss: 0.0005577801493927836
batch 115 loss: 0.0005576962255872786
batch 120 loss: 0.0005576720461249352
batch 125 loss: 0.0005576918949373067
batch 130 loss: 0.000557625899091363
batch 135 loss: 0.0005576004623435438
batch 140 loss: 0.0005576870520599186
batch 145 loss: 0.0005577485309913755
batch 150 loss: 0.0005577294854447245
batch 155 loss: 0.0005576364463195204
batch 160 loss: 0.0005577395553700626
batch 165 loss: 0.0005577329313382507
batch 170 loss: 0.0005576091702096164
batch 175 loss: 0.000557624502107501
batch 180 loss: 0.0005576110794208944
batch 185 loss: 0.0005576496245339513
batch 190 loss: 0.0005576975760050118
batch 195 loss: 0.0005576337687671184
batch 200 loss: 0.0005576538620516658
batch 205 loss: 0.0005576333729550243
batch 210 loss: 0.0005577185424044728
batch 215 loss: 0.0005575774819590151
batch 220 loss: 0.0005577521864324808
batch 225 loss: 0.0005577509291470051
batch 230 loss: 0.0005576746421866119
batch 235 loss: 0.000557702430523932
batch 240 loss: 0.0005577149335294962
Training Loss: 0.0005576834140811115
Validation Loss: 0.0005576935654971749
Epoch 27:
batch 5 loss: 0.0005576692521572113
batch 10 loss: 0.0005577356205321848
batch 15 loss: 0.0005576312658376991
batch 20 loss: 0.0005576792405918241
batch 25 loss: 0.0005577391711995006
batch 30 loss: 0.0005576545372605324
batch 35 loss: 0.0005575816496275366
batch 40 loss: 0.0005576982162892819
batch 45 loss: 0.0005577606963925064
batch 50 loss: 0.0005577328614890575
batch 55 loss: 0.0005577437113970518
batch 60 loss: 0.0005576119176112116
batch 65 loss: 0.0005577027332037687
batch 70 loss: 0.0005576882045716048
batch 75 loss: 0.0005576953059062362
batch 80 loss: 0.0005577307776547969
batch 85 loss: 0.0005577826057560741
batch 90 loss: 0.0005577242467552423
batch 95 loss: 0.0005577148403972387
batch 100 loss: 0.0005576907307840884
batch 105 loss: 0.0005576528725214303
batch 110 loss: 0.0005575898685492575
batch 115 loss: 0.0005577253294177353
batch 120 loss: 0.0005577149335294962
batch 125 loss: 0.0005576371448114514
batch 130 loss: 0.0005576228490099311
batch 135 loss: 0.0005577457370236516
batch 140 loss: 0.0005576874129474163
batch 145 loss: 0.0005577411153353751
batch 150 loss: 0.0005576716503128409
batch 155 loss: 0.0005575792863965034
batch 160 loss: 0.0005577095435000956
batch 165 loss: 0.0005576354567892849
batch 170 loss: 0.0005578042240813374
batch 175 loss: 0.0005576780764386058
batch 180 loss: 0.0005576943745836616
batch 185 loss: 0.000557675096206367
batch 190 loss: 0.0005576475639827549
batch 195 loss: 0.0005576319992542267
batch 200 loss: 0.0005576732801273465
batch 205 loss: 0.0005576420808210969
batch 210 loss: 0.0005576619412750005
batch 215 loss: 0.0005577448406256736
batch 220 loss: 0.000557685864623636
batch 225 loss: 0.000557701219804585
batch 230 loss: 0.0005576481344178319
batch 235 loss: 0.0005576511612161994
batch 240 loss: 0.0005575836170464754
Training Loss: 0.000557683422084665
Validation Loss: 0.0005576935082596417
Epoch 28:
batch 5 loss: 0.000557674653828144
batch 10 loss: 0.00055760646937415
batch 15 loss: 0.0005575645831413567
batch 20 loss: 0.0005575801129452884
batch 25 loss: 0.0005576418363489211
batch 30 loss: 0.000557693385053426
batch 35 loss: 0.0005578063894063235
batch 40 loss: 0.0005577388568781316
batch 45 loss: 0.0005576920695602894
batch 50 loss: 0.0005575330229476094
batch 55 loss: 0.0005577696952968836
batch 60 loss: 0.0005576603813096881
batch 65 loss: 0.0005576828494668007
batch 70 loss: 0.0005577100091613829
batch 75 loss: 0.0005578104755841196
batch 80 loss: 0.0005577534437179565
batch 85 loss: 0.0005577484727837146
batch 90 loss: 0.0005576469236984849
batch 95 loss: 0.0005577538977377117
batch 100 loss: 0.0005577314412221312
batch 105 loss: 0.0005576816853135824
batch 110 loss: 0.000557661592029035
batch 115 loss: 0.0005577602074481547
batch 120 loss: 0.0005576345603913069
batch 125 loss: 0.000557672360446304
batch 130 loss: 0.0005577854812145233
batch 135 loss: 0.0005576525232754648
batch 140 loss: 0.0005576991010457277
batch 145 loss: 0.0005576116382144392
batch 150 loss: 0.0005576126161031425
batch 155 loss: 0.0005576635361649096
batch 160 loss: 0.0005576460738666355
batch 165 loss: 0.0005576846306212246
batch 170 loss: 0.0005577388103120029
batch 175 loss: 0.0005577245261520148
batch 180 loss: 0.0005576391005888582
batch 185 loss: 0.0005576493102125823
batch 190 loss: 0.000557686435058713
batch 195 loss: 0.0005576942581683398
batch 200 loss: 0.0005576852941885591
batch 205 loss: 0.0005577437113970518
batch 210 loss: 0.000557687459513545
batch 215 loss: 0.000557668844703585
batch 220 loss: 0.000557567982468754
batch 225 loss: 0.0005576646653935313
batch 230 loss: 0.0005577354691922665
batch 235 loss: 0.0005576583207584918
batch 240 loss: 0.0005576959112659097
Training Loss: 0.0005576834390618994
Validation Loss: 0.0005576934015455966
Epoch 29:
batch 5 loss: 0.0005576837807893753
batch 10 loss: 0.0005576584138907492
batch 15 loss: 0.0005576252820901573
batch 20 loss: 0.000557576003484428
batch 25 loss: 0.0005575776682235301
batch 30 loss: 0.0005576634430326521
batch 35 loss: 0.000557673629373312
batch 40 loss: 0.0005577067262493074
batch 45 loss: 0.0005577021278440952
batch 50 loss: 0.000557682290673256
batch 55 loss: 0.0005577719886787236
batch 60 loss: 0.0005578221869654953
batch 65 loss: 0.0005577310104854405
batch 70 loss: 0.000557800056412816
batch 75 loss: 0.0005576845956966281
batch 80 loss: 0.0005576792522333562
batch 85 loss: 0.0005576568539254368
batch 90 loss: 0.0005577070289291442
batch 95 loss: 0.0005577076459303498
batch 100 loss: 0.0005576790543273091
batch 105 loss: 0.0005575239541940391
batch 110 loss: 0.0005577066214755178
batch 115 loss: 0.0005577012663707138
batch 120 loss: 0.0005576633731834591
batch 125 loss: 0.0005575787858106196
batch 130 loss: 0.0005578462383709848
batch 135 loss: 0.0005576168652623892
batch 140 loss: 0.0005576812196522951
batch 145 loss: 0.0005576499970629811
batch 150 loss: 0.0005577749572694302
batch 155 loss: 0.0005576661904342472
batch 160 loss: 0.0005576881929300725
batch 165 loss: 0.0005576065508648753
batch 170 loss: 0.0005576793570071459
batch 175 loss: 0.0005576450843364
batch 180 loss: 0.0005578011041507125
batch 185 loss: 0.0005577353644184768
batch 190 loss: 0.0005578003940172494
batch 195 loss: 0.0005577543051913381
batch 200 loss: 0.0005577066331170499
batch 205 loss: 0.0005575550021603703
batch 210 loss: 0.0005577580421231687
batch 215 loss: 0.0005576216033659875
batch 220 loss: 0.0005577075062319636
batch 225 loss: 0.0005576784024015069
batch 230 loss: 0.0005575226503424346
batch 235 loss: 0.0005576167022809386
batch 240 loss: 0.0005577306728810072
Training Loss: 0.0005576834599196445
Validation Loss: 0.0005576934442312146
Epoch 30:
batch 5 loss: 0.0005577741540037096
batch 10 loss: 0.0005576511262916029
batch 15 loss: 0.0005578070529736578
batch 20 loss: 0.0005577413248829544
batch 25 loss: 0.0005577607546001673
batch 30 loss: 0.0005576869705691933
batch 35 loss: 0.0005576070630922914
batch 40 loss: 0.0005575978779233992
batch 45 loss: 0.0005577559233643115
batch 50 loss: 0.0005576135707087814
batch 55 loss: 0.0005576550960540771
batch 60 loss: 0.0005577663308940828
batch 65 loss: 0.0005576952709816397
batch 70 loss: 0.0005576312309131026
batch 75 loss: 0.0005576382391154766
batch 80 loss: 0.0005576162133365869
batch 85 loss: 0.000557610287796706
batch 90 loss: 0.0005577747826464475
batch 95 loss: 0.0005575874354690313
batch 100 loss: 0.0005576695781201124
batch 105 loss: 0.0005576393683440984
batch 110 loss: 0.0005576859461143613
batch 115 loss: 0.0005577220348641276
batch 120 loss: 0.0005575819290243089
batch 125 loss: 0.0005577944335527718
batch 130 loss: 0.00055772919440642
batch 135 loss: 0.000557768892031163
batch 140 loss: 0.0005577067146077752
batch 145 loss: 0.0005578150623477996
batch 150 loss: 0.0005576582974754274
batch 155 loss: 0.0005576731637120247
batch 160 loss: 0.0005576482624746859
batch 165 loss: 0.0005576910101808607
batch 170 loss: 0.0005577254109084606
batch 175 loss: 0.0005576865863986313
batch 180 loss: 0.0005577292875386774
batch 185 loss: 0.0005576311377808452
batch 190 loss: 0.0005577086587436498
batch 195 loss: 0.0005576276336796582
batch 200 loss: 0.0005576331983320415
batch 205 loss: 0.000557766854763031
batch 210 loss: 0.0005576879368163646
batch 215 loss: 0.0005576075636781752
batch 220 loss: 0.0005577139090746641
batch 225 loss: 0.0005576232098974288
batch 230 loss: 0.0005577281001023949
batch 235 loss: 0.0005575743271037936
batch 240 loss: 0.0005576065275818109
Training Loss: 0.0005576834361515163
Validation Loss: 0.0005576934151273841
Epoch 31:
batch 5 loss: 0.0005575704271905124
batch 10 loss: 0.0005575439310632647
batch 15 loss: 0.0005577382282353938
batch 20 loss: 0.0005575187969952822
batch 25 loss: 0.0005576059804297984
batch 30 loss: 0.0005577475647442042
batch 35 loss: 0.0005576377385295928
batch 40 loss: 0.0005576719180680811
batch 45 loss: 0.0005577101488597691
batch 50 loss: 0.0005577199277468026
batch 55 loss: 0.0005577710689976811
batch 60 loss: 0.0005576674710027873
batch 65 loss: 0.000557671976275742
batch 70 loss: 0.000557637878227979
batch 75 loss: 0.0005576077266596258
batch 80 loss: 0.0005577758071012795
batch 85 loss: 0.0005577548639848828
batch 90 loss: 0.0005577297182753682
batch 95 loss: 0.0005577001953497529
batch 100 loss: 0.0005576400901190937
batch 105 loss: 0.0005576264811679721
batch 110 loss: 0.0005575857008807361
batch 115 loss: 0.000557606341317296
batch 120 loss: 0.0005577251547947526
batch 125 loss: 0.0005577472969889641
batch 130 loss: 0.0005576954456046224
batch 135 loss: 0.0005577272735536098
batch 140 loss: 0.0005576793919317424
batch 145 loss: 0.0005576759809628129
batch 150 loss: 0.0005576527095399797
batch 155 loss: 0.0005576759809628129
batch 160 loss: 0.0005576371215283871
batch 165 loss: 0.000557666493114084
batch 170 loss: 0.0005576713825576008
batch 175 loss: 0.000557812163606286
batch 180 loss: 0.0005576104973442853
batch 185 loss: 0.0005576305789873004
batch 190 loss: 0.0005576998926699161
batch 195 loss: 0.0005577602307312191
batch 200 loss: 0.0005577167612500489
batch 205 loss: 0.0005577803240157664
batch 210 loss: 0.0005576642462983728
batch 215 loss: 0.0005576619878411293
batch 220 loss: 0.0005576904397457838
batch 225 loss: 0.0005578574258834123
batch 230 loss: 0.0005576694733463228
batch 235 loss: 0.0005577333155088127
batch 240 loss: 0.0005577230243943631
Training Loss: 0.0005576834286330268
Validation Loss: 0.0005576934772155558
Epoch 32:
batch 5 loss: 0.000557722372468561
batch 10 loss: 0.0005576819530688226
batch 15 loss: 0.0005576036171987652
batch 20 loss: 0.0005575663759373129
batch 25 loss: 0.0005577049683779478
batch 30 loss: 0.0005577202304266393
batch 35 loss: 0.0005577060277573764
batch 40 loss: 0.0005576183903031051
batch 45 loss: 0.0005578425712883473
batch 50 loss: 0.0005578067153692246
batch 55 loss: 0.000557584036141634
batch 60 loss: 0.000557761057280004
batch 65 loss: 0.0005577218136750162
batch 70 loss: 0.0005576674127951264
batch 75 loss: 0.0005577594856731594
batch 80 loss: 0.0005577347124926746
batch 85 loss: 0.0005576546536758542
batch 90 loss: 0.0005576531868427992
batch 95 loss: 0.0005577741540037096
batch 100 loss: 0.0005577050498686731
batch 105 loss: 0.0005576177267357707
batch 110 loss: 0.0005577857722528279
batch 115 loss: 0.0005576473893597722
batch 120 loss: 0.0005576558643952012
batch 125 loss: 0.0005576725583523512
batch 130 loss: 0.0005576837109401822
batch 135 loss: 0.0005576747236773372
batch 140 loss: 0.0005576341063715518
batch 145 loss: 0.000557672861032188
batch 150 loss: 0.0005576915689744055
batch 155 loss: 0.0005576576339080929
batch 160 loss: 0.0005575493560172617
batch 165 loss: 0.0005576854455284774
batch 170 loss: 0.000557630939874798
batch 175 loss: 0.0005576487514190376
batch 180 loss: 0.0005577349918894469
batch 185 loss: 0.0005576653289608658
batch 190 loss: 0.000557739136274904
batch 195 loss: 0.0005578066455200314
batch 200 loss: 0.0005576364696025848
batch 205 loss: 0.0005577962961979211
batch 210 loss: 0.0005575774470344186
batch 215 loss: 0.0005577641655690968
batch 220 loss: 0.0005576585070230066
batch 225 loss: 0.0005576417664997279
batch 230 loss: 0.0005576553172431886
batch 235 loss: 0.0005576669587753713
batch 240 loss: 0.0005575648974627256
Training Loss: 0.000557683440032027
Validation Loss: 0.0005576935781088347
Epoch 33:
batch 5 loss: 0.0005575644085183739
batch 10 loss: 0.000557553325779736
batch 15 loss: 0.0005576521740294993
batch 20 loss: 0.0005576382507570087
batch 25 loss: 0.0005576057126745581
batch 30 loss: 0.0005576779483817517
batch 35 loss: 0.0005577126168645919
batch 40 loss: 0.0005576646071858704
batch 45 loss: 0.0005577256320975721
batch 50 loss: 0.0005576836876571179
batch 55 loss: 0.0005577595438808203
batch 60 loss: 0.0005575991352088749
batch 65 loss: 0.0005577500909566879
batch 70 loss: 0.000557608378585428
batch 75 loss: 0.0005576022667810321
batch 80 loss: 0.0005577749572694302
batch 85 loss: 0.0005576861323788763
batch 90 loss: 0.0005576750263571739
batch 95 loss: 0.0005577212315984071
batch 100 loss: 0.000557651708368212
batch 105 loss: 0.0005576491821557283
batch 110 loss: 0.0005576875293627382
batch 115 loss: 0.000557757169008255
batch 120 loss: 0.0005576043506152928
batch 125 loss: 0.000557672674767673
batch 130 loss: 0.0005575804156251251
batch 135 loss: 0.0005577184492722154
batch 140 loss: 0.0005576922791078687
batch 145 loss: 0.0005577599164098501
batch 150 loss: 0.0005577196017839015
batch 155 loss: 0.0005576292402110994
batch 160 loss: 0.0005576926399953663
batch 165 loss: 0.0005576494964770973
batch 170 loss: 0.0005576609983108938
batch 175 loss: 0.0005577409290708601
batch 180 loss: 0.0005577354924753309
batch 185 loss: 0.0005576938390731811
batch 190 loss: 0.0005576489609666168
batch 195 loss: 0.0005576599389314652
batch 200 loss: 0.0005576930241659283
batch 205 loss: 0.000557659869082272
batch 210 loss: 0.0005577336298301816
batch 215 loss: 0.0005577550269663334
batch 220 loss: 0.0005576679715886713
batch 225 loss: 0.0005577984848059714
batch 230 loss: 0.0005577682750299573
batch 235 loss: 0.0005577893578447401
batch 240 loss: 0.0005576810450293124
Training Loss: 0.0005576834713186448
Validation Loss: 0.0005576934684844067
Epoch 34:
batch 5 loss: 0.0005576442228630186
batch 10 loss: 0.0005578077863901854
batch 15 loss: 0.0005577078671194613
batch 20 loss: 0.0005577668896876275
batch 25 loss: 0.0005576340248808265
batch 30 loss: 0.0005576830124482512
batch 35 loss: 0.0005576898925937712
batch 40 loss: 0.0005575663992203773
batch 45 loss: 0.0005576446419581771
batch 50 loss: 0.0005576608120463789
batch 55 loss: 0.0005577107658609748
batch 60 loss: 0.0005577730014920234
batch 65 loss: 0.0005577039555646479
batch 70 loss: 0.0005577867617830634
batch 75 loss: 0.0005577816860750318
batch 80 loss: 0.0005577435833401978
batch 85 loss: 0.0005576578667387366
batch 90 loss: 0.0005577618372626603
batch 95 loss: 0.0005576608120463789
batch 100 loss: 0.0005577265750616789
batch 105 loss: 0.0005577031639404595
batch 110 loss: 0.0005577043630182743
batch 115 loss: 0.0005575378541834653
batch 120 loss: 0.0005577171570621431
batch 125 loss: 0.0005577306961640716
batch 130 loss: 0.0005577007541432977
batch 135 loss: 0.0005575840710662306
batch 140 loss: 0.0005577419884502888
batch 145 loss: 0.0005577018950134516
batch 150 loss: 0.0005576768191531301
batch 155 loss: 0.0005576191702857614
batch 160 loss: 0.0005577242467552423
batch 165 loss: 0.0005577343632467091
batch 170 loss: 0.0005576231051236391
batch 175 loss: 0.0005576286930590868
batch 180 loss: 0.0005577292875386774
batch 185 loss: 0.0005574608803726733
batch 190 loss: 0.0005576277268119157
batch 195 loss: 0.0005576792522333562
batch 200 loss: 0.0005575953284278512
batch 205 loss: 0.0005575446877628565
batch 210 loss: 0.000557607295922935
batch 215 loss: 0.0005577903939411044
batch 220 loss: 0.0005576793919317424
batch 225 loss: 0.0005578502197749913
batch 230 loss: 0.0005577678908593953
batch 235 loss: 0.0005576348979957402
batch 240 loss: 0.0005575970164500177
Training Loss: 0.0005576834376067078
Validation Loss: 0.0005576935790789624
Epoch 35:
batch 5 loss: 0.0005577524425461888
batch 10 loss: 0.0005575841874815524
batch 15 loss: 0.0005577004980295896
batch 20 loss: 0.0005577399977482855
batch 25 loss: 0.0005576824187301099
batch 30 loss: 0.0005575762945227325
batch 35 loss: 0.0005576223251409828
batch 40 loss: 0.0005576100666075945
batch 45 loss: 0.0005577332573011518
batch 50 loss: 0.0005577028612606227
batch 55 loss: 0.000557688984554261
batch 60 loss: 0.0005576205323450268
batch 65 loss: 0.0005576306954026222
batch 70 loss: 0.0005577485542744398
batch 75 loss: 0.00055773212807253
batch 80 loss: 0.0005576689261943101
batch 85 loss: 0.000557640683837235
batch 90 loss: 0.0005576762254349887
batch 95 loss: 0.000557654513977468
batch 100 loss: 0.0005577398929744959
batch 105 loss: 0.0005576654337346553
batch 110 loss: 0.0005576491239480674
batch 115 loss: 0.0005576446885243059
batch 120 loss: 0.0005576648749411106
batch 125 loss: 0.0005576361552812159
batch 130 loss: 0.000557676691096276
batch 135 loss: 0.0005575862363912165
batch 140 loss: 0.0005576989380642772
batch 145 loss: 0.0005577999399974942
batch 150 loss: 0.0005576774710789323
batch 155 loss: 0.0005577246542088687
batch 160 loss: 0.0005576725350692868
batch 165 loss: 0.000557685480453074
batch 170 loss: 0.000557738495990634
batch 175 loss: 0.0005576104274950921
batch 180 loss: 0.0005577435833401978
batch 185 loss: 0.0005577531177550554
batch 190 loss: 0.0005576941068284214
batch 195 loss: 0.0005576600204221904
batch 200 loss: 0.0005577580421231687
batch 205 loss: 0.0005577025702223181
batch 210 loss: 0.0005575701361522079
batch 215 loss: 0.0005577575648203492
batch 220 loss: 0.0005576853873208165
batch 225 loss: 0.0005577859003096819
batch 230 loss: 0.000557641254272312
batch 235 loss: 0.0005576094263233244
batch 240 loss: 0.0005578108015470207
Training Loss: 0.0005576835113364117
Validation Loss: 0.0005576934190078948
Epoch 36:
batch 5 loss: 0.0005576706957072019
batch 10 loss: 0.0005577446427196264
batch 15 loss: 0.0005575828487053514
batch 20 loss: 0.0005576602066867054
batch 25 loss: 0.0005577233270742
batch 30 loss: 0.0005577329662628472
batch 35 loss: 0.0005576363299041986
batch 40 loss: 0.0005576111725531518
batch 45 loss: 0.0005577004631049931
batch 50 loss: 0.0005577359232120215
batch 55 loss: 0.0005576162599027157
batch 60 loss: 0.000557694851886481
batch 65 loss: 0.0005576405907049775
batch 70 loss: 0.0005576575640588999
batch 75 loss: 0.0005577570991590619
batch 80 loss: 0.0005578366573899985
batch 85 loss: 0.0005577808129601181
batch 90 loss: 0.000557568809017539
batch 95 loss: 0.0005577132222242653
batch 100 loss: 0.0005576247815042735
batch 105 loss: 0.0005577007075771689
batch 110 loss: 0.0005576698575168848
batch 115 loss: 0.000557705108076334
batch 120 loss: 0.0005577463656663894
batch 125 loss: 0.0005576222902163863
batch 130 loss: 0.0005577294854447245
batch 135 loss: 0.0005576310330070555
batch 140 loss: 0.0005577469477429986
batch 145 loss: 0.0005577138741500676
batch 150 loss: 0.0005576915107667446
batch 155 loss: 0.0005576616036705673
batch 160 loss: 0.0005576035240665078
batch 165 loss: 0.0005575621267780662
batch 170 loss: 0.000557685736566782
batch 175 loss: 0.0005577097996138036
batch 180 loss: 0.0005577139090746641
batch 185 loss: 0.0005576310330070555
batch 190 loss: 0.0005575993214733899
batch 195 loss: 0.0005576682277023792
batch 200 loss: 0.0005576126859523356
batch 205 loss: 0.0005577411619015038
batch 210 loss: 0.0005577751784585416
batch 215 loss: 0.0005576926399953663
batch 220 loss: 0.0005576946656219661
batch 225 loss: 0.0005576669471338391
batch 230 loss: 0.0005577218369580805
batch 235 loss: 0.0005576764466241002
batch 240 loss: 0.0005577428615652025
Training Loss: 0.0005576834606472403
Validation Loss: 0.0005576933996053413
Epoch 37:
batch 5 loss: 0.0005576575524173677
batch 10 loss: 0.0005576540715992451
batch 15 loss: 0.0005575854098424316
batch 20 loss: 0.0005577862961217761
batch 25 loss: 0.0005577119998633861
batch 30 loss: 0.0005576254683546722
batch 35 loss: 0.0005577018251642585
batch 40 loss: 0.0005575517308898271
batch 45 loss: 0.0005576704163104296
batch 50 loss: 0.000557691475842148
batch 55 loss: 0.0005576931755058468
batch 60 loss: 0.0005576314870268106
batch 65 loss: 0.0005577426753006875
batch 70 loss: 0.0005576303112320602
batch 75 loss: 0.0005576465977355838
batch 80 loss: 0.0005576268187724054
batch 85 loss: 0.0005577561794780194
batch 90 loss: 0.0005576954456046224
batch 95 loss: 0.000557639729231596
batch 100 loss: 0.0005576502648182213
batch 105 loss: 0.0005576120805926621
batch 110 loss: 0.0005575968883931637
batch 115 loss: 0.00055767975281924
batch 120 loss: 0.0005577830364927649
batch 125 loss: 0.0005577933392487466
batch 130 loss: 0.0005576601368375122
batch 135 loss: 0.0005577189498580992
batch 140 loss: 0.0005576620460487902
batch 145 loss: 0.0005575806135311723
batch 150 loss: 0.000557631126139313
batch 155 loss: 0.0005577623378485441
batch 160 loss: 0.0005578374373726546
batch 165 loss: 0.0005576572031714023
batch 170 loss: 0.0005577947478741408
batch 175 loss: 0.0005575896590016783
batch 180 loss: 0.0005576319759711623
batch 185 loss: 0.0005576529074460268
batch 190 loss: 0.0005576802417635917
batch 195 loss: 0.0005575919523835183
batch 200 loss: 0.0005578449345193803
batch 205 loss: 0.0005577594507485628
batch 210 loss: 0.000557693059090525
batch 215 loss: 0.0005577133852057159
batch 220 loss: 0.000557737669441849
batch 225 loss: 0.000557672861032188
batch 230 loss: 0.0005576087860390544
batch 235 loss: 0.0005577941075898707
batch 240 loss: 0.0005577180767431855
Training Loss: 0.0005576834936315815
Validation Loss: 0.0005576934199780226
Epoch 38:
batch 5 loss: 0.0005577160976827144
batch 10 loss: 0.0005576790543273091
batch 15 loss: 0.0005577593925409019
batch 20 loss: 0.0005575362360104918
batch 25 loss: 0.0005577305215410888
batch 30 loss: 0.0005577049916610122
batch 35 loss: 0.0005577230243943631
batch 40 loss: 0.0005576368537731468
batch 45 loss: 0.0005576208815909923
batch 50 loss: 0.0005575445829890668
batch 55 loss: 0.0005576594616286456
batch 60 loss: 0.000557694782037288
batch 65 loss: 0.0005577009287662804
batch 70 loss: 0.000557734863832593
batch 75 loss: 0.000557694851886481
batch 80 loss: 0.0005577081814408302
batch 85 loss: 0.0005575726041570306
batch 90 loss: 0.000557811779435724
batch 95 loss: 0.0005576361319981516
batch 100 loss: 0.0005576379015110433
batch 105 loss: 0.0005575562245212495
batch 110 loss: 0.0005576952127739788
batch 115 loss: 0.0005577021394856275
batch 120 loss: 0.0005576763534918428
batch 125 loss: 0.000557759718503803
batch 130 loss: 0.0005577918374910951
batch 135 loss: 0.0005577092757448554
batch 140 loss: 0.0005575871444307267
batch 145 loss: 0.0005576963885687292
batch 150 loss: 0.0005575949908234179
batch 155 loss: 0.0005576726864092052
batch 160 loss: 0.0005576044437475503
batch 165 loss: 0.0005576875177212059
batch 170 loss: 0.0005576007417403162
batch 175 loss: 0.0005576459574513137
batch 180 loss: 0.0005577350850217045
batch 185 loss: 0.0005578126874752343
batch 190 loss: 0.0005577666801400482
batch 195 loss: 0.0005578444921411574
batch 200 loss: 0.0005577300325967371
batch 205 loss: 0.0005577378324232996
batch 210 loss: 0.0005577339441515505
batch 215 loss: 0.0005576539435423911
batch 220 loss: 0.0005576781695708632
batch 225 loss: 0.0005575764924287796
batch 230 loss: 0.0005576881347224116
batch 235 loss: 0.0005577728501521051
batch 240 loss: 0.000557593663688749
Training Loss: 0.000557683495086773
Validation Loss: 0.0005576934063962351
Epoch 39:
batch 5 loss: 0.0005576038733124733
batch 10 loss: 0.0005577596370130777
batch 15 loss: 0.000557697075419128
batch 20 loss: 0.0005577686475589872
batch 25 loss: 0.000557755131740123
batch 30 loss: 0.000557602965272963
batch 35 loss: 0.0005576854338869453
batch 40 loss: 0.0005576599389314652
batch 45 loss: 0.0005575350020080805
batch 50 loss: 0.0005576358176767826
batch 55 loss: 0.0005575868184678256
batch 60 loss: 0.0005577015108428895
batch 65 loss: 0.0005576896714046597
batch 70 loss: 0.0005575987976044417
batch 75 loss: 0.000557744677644223
batch 80 loss: 0.00055766279110685
batch 85 loss: 0.0005577146308496595
batch 90 loss: 0.0005577029194682836
batch 95 loss: 0.0005576939089223743
batch 100 loss: 0.0005577301722951234
batch 105 loss: 0.0005576392286457121
batch 110 loss: 0.0005577785545028746
batch 115 loss: 0.0005576417781412602
batch 120 loss: 0.0005576281109824777
batch 125 loss: 0.0005577095551416277
batch 130 loss: 0.0005575908697210252
batch 135 loss: 0.0005576339899562299
batch 140 loss: 0.0005576124647632241
batch 145 loss: 0.0005576254217885435
batch 150 loss: 0.0005577337578870356
batch 155 loss: 0.0005577433970756829
batch 160 loss: 0.000557730533182621
batch 165 loss: 0.000557739136274904
batch 170 loss: 0.0005576969240792095
batch 175 loss: 0.0005576319410465658
batch 180 loss: 0.0005576125578954816
batch 185 loss: 0.0005575781571678818
batch 190 loss: 0.0005577719653956592
batch 195 loss: 0.000557749264407903
batch 200 loss: 0.0005576891591772438
batch 205 loss: 0.0005577549571171402
batch 210 loss: 0.0005577506846748293
batch 215 loss: 0.0005577312549576163
batch 220 loss: 0.0005576817668043077
batch 225 loss: 0.0005577226169407367
batch 230 loss: 0.0005577381001785397
batch 235 loss: 0.0005576513125561178
batch 240 loss: 0.0005577096599154174
Training Loss: 0.0005576834696209214
Validation Loss: 0.0005576935878101115
Epoch 40:
batch 5 loss: 0.0005576976691372693
batch 10 loss: 0.000557746912818402
batch 15 loss: 0.0005576204042881727
batch 20 loss: 0.0005576640367507934
batch 25 loss: 0.0005576713825576008
batch 30 loss: 0.0005576382158324122
batch 35 loss: 0.0005578383803367615
batch 40 loss: 0.0005576480412855745
batch 45 loss: 0.000557628262322396
batch 50 loss: 0.0005576848867349327
batch 55 loss: 0.000557733851019293
batch 60 loss: 0.0005576628376729786
batch 65 loss: 0.0005576987867243588
batch 70 loss: 0.000557576771825552
batch 75 loss: 0.0005576855852268636
batch 80 loss: 0.0005576657596975565
batch 85 loss: 0.0005576844792813063
batch 90 loss: 0.0005577538744546473
batch 95 loss: 0.0005576909636147321
batch 100 loss: 0.0005576141527853906
batch 105 loss: 0.0005576549097895622
batch 110 loss: 0.0005577124771662057
batch 115 loss: 0.0005576839786954225
batch 120 loss: 0.0005577330943197012
batch 125 loss: 0.00055763985728845
batch 130 loss: 0.0005576343042775989
batch 135 loss: 0.0005576389376074076
batch 140 loss: 0.0005576960626058281
batch 145 loss: 0.0005576192867010832
batch 150 loss: 0.0005576930940151215
batch 155 loss: 0.0005577466450631619
batch 160 loss: 0.0005577233852818609
batch 165 loss: 0.000557722756639123
batch 170 loss: 0.0005577040603384376
batch 175 loss: 0.0005576732568442821
batch 180 loss: 0.000557755003683269
batch 185 loss: 0.000557696889154613
batch 190 loss: 0.0005576794617809355
batch 195 loss: 0.0005576295545324684
batch 200 loss: 0.0005576974246650935
batch 205 loss: 0.0005578206735663116
batch 210 loss: 0.0005576545489020645
batch 215 loss: 0.0005576170631684362
batch 220 loss: 0.0005575982271693647
batch 225 loss: 0.0005576365045271813
batch 230 loss: 0.0005576692172326147
batch 235 loss: 0.0005578255280852318
batch 240 loss: 0.0005576474475674331
Training Loss: 0.0005576835188549012
Validation Loss: 0.0005576934704246621
Epoch 41:
batch 5 loss: 0.0005576769472099841
batch 10 loss: 0.0005575920571573078
batch 15 loss: 0.0005576973315328359
batch 20 loss: 0.0005577719304710627
batch 25 loss: 0.0005575731047429144
batch 30 loss: 0.0005576636409386993
batch 35 loss: 0.0005576065159402788
batch 40 loss: 0.0005577016621828079
batch 45 loss: 0.000557754363398999
batch 50 loss: 0.000557645340450108
batch 55 loss: 0.0005575826624408364
batch 60 loss: 0.0005576437339186669
batch 65 loss: 0.0005576395429670811
batch 70 loss: 0.00055774359498173
batch 75 loss: 0.0005577857722528279
batch 80 loss: 0.0005576930474489927
batch 85 loss: 0.0005577536532655359
batch 90 loss: 0.0005577873438596725
batch 95 loss: 0.0005577226169407367
batch 100 loss: 0.0005576668656431139
batch 105 loss: 0.0005577170988544822
batch 110 loss: 0.0005576650029979647
batch 115 loss: 0.0005577686359174549
batch 120 loss: 0.0005575910327024758
batch 125 loss: 0.0005575530696660281
batch 130 loss: 0.0005577094736509026
batch 135 loss: 0.000557825667783618
batch 140 loss: 0.0005576624535024166
batch 145 loss: 0.0005576862022280693
batch 150 loss: 0.0005577535717748106
batch 155 loss: 0.0005576996947638691
batch 160 loss: 0.0005576820345595479
batch 165 loss: 0.0005576541647315025
batch 170 loss: 0.0005577173200435936
batch 175 loss: 0.0005576441995799542
batch 180 loss: 0.0005576611030846835
batch 185 loss: 0.0005577554809860885
batch 190 loss: 0.0005576896248385311
batch 195 loss: 0.0005576937808655202
batch 200 loss: 0.0005576569237746298
batch 205 loss: 0.0005577227799221874
batch 210 loss: 0.0005576369469054044
batch 215 loss: 0.0005576114519499243
batch 220 loss: 0.0005576912546530366
batch 225 loss: 0.0005576330353505909
batch 230 loss: 0.0005576917785219849
batch 235 loss: 0.0005577186006121337
batch 240 loss: 0.000557614432182163
Training Loss: 0.0005576835113364117
Validation Loss: 0.0005576935761685794
Epoch 42:
batch 5 loss: 0.0005576465162448585
batch 10 loss: 0.0005577012314461171
batch 15 loss: 0.0005575912538915873
batch 20 loss: 0.0005576952942647039
batch 25 loss: 0.000557588110677898
batch 30 loss: 0.0005577793810516596
batch 35 loss: 0.0005577766103670001
batch 40 loss: 0.0005577302770689129
batch 45 loss: 0.0005577248055487871
batch 50 loss: 0.0005577035713940859
batch 55 loss: 0.0005576730123721063
batch 60 loss: 0.0005577053176239133
batch 65 loss: 0.0005576527677476406
batch 70 loss: 0.0005577204748988152
batch 75 loss: 0.0005577076342888176
batch 80 loss: 0.0005577023723162711
batch 85 loss: 0.0005575814051553607
batch 90 loss: 0.0005577416042797268
batch 95 loss: 0.0005576038500294089
batch 100 loss: 0.0005576876923441887
batch 105 loss: 0.0005575990304350853
batch 110 loss: 0.0005577197298407555
batch 115 loss: 0.0005577555974014103
batch 120 loss: 0.0005575871211476624
batch 125 loss: 0.0005577764357440173
batch 130 loss: 0.0005576842115260661
batch 135 loss: 0.0005576535244472325
batch 140 loss: 0.0005577555508352816
batch 145 loss: 0.0005577685427851975
batch 150 loss: 0.0005576501018367708
batch 155 loss: 0.0005576314171776176
batch 160 loss: 0.0005575745366513729
batch 165 loss: 0.0005576176685281098
batch 170 loss: 0.0005576232564635575
batch 175 loss: 0.0005576428608037532
batch 180 loss: 0.0005577087053097784
batch 185 loss: 0.0005576921626925469
batch 190 loss: 0.0005576791823841632
batch 195 loss: 0.000557715364266187
batch 200 loss: 0.0005576546536758542
batch 205 loss: 0.0005577840376645327
batch 210 loss: 0.0005577413132414222
batch 215 loss: 0.0005576395196840167
batch 220 loss: 0.0005576862837187946
batch 225 loss: 0.0005576700787059963
batch 230 loss: 0.0005577765055932105
batch 235 loss: 0.0005576219875365496
batch 240 loss: 0.0005576869356445968
Training Loss: 0.0005576835312240292
Validation Loss: 0.0005576934267689164
Epoch 43:
batch 5 loss: 0.0005577381001785397
batch 10 loss: 0.000557733466848731
batch 15 loss: 0.0005576365045271813
batch 20 loss: 0.0005576754920184612
batch 25 loss: 0.0005577067611739039
batch 30 loss: 0.0005578046082518994
batch 35 loss: 0.0005577010218985379
batch 40 loss: 0.0005577721516601741
batch 45 loss: 0.0005577389616519213
batch 50 loss: 0.0005577196017839015
batch 55 loss: 0.0005575660266913474
batch 60 loss: 0.000557599263265729
batch 65 loss: 0.0005575924646109342
batch 70 loss: 0.0005576484254561365
batch 75 loss: 0.0005577048286795616
batch 80 loss: 0.0005577742820605635
batch 85 loss: 0.0005576235707849264
batch 90 loss: 0.0005577013944275677
batch 95 loss: 0.0005576848401688039
batch 100 loss: 0.0005576404393650592
batch 105 loss: 0.0005577779258601368
batch 110 loss: 0.0005577034200541676
batch 115 loss: 0.0005576045485213398
batch 120 loss: 0.0005576782976277172
batch 125 loss: 0.0005576462135650218
batch 130 loss: 0.0005576501018367708
batch 135 loss: 0.0005576987401582301
batch 140 loss: 0.0005577370524406433
batch 145 loss: 0.0005576426046900451
batch 150 loss: 0.0005577577510848641
batch 155 loss: 0.0005577281583100558
batch 160 loss: 0.0005577115342020988
batch 165 loss: 0.0005576484138146043
batch 170 loss: 0.0005576646188274025
batch 175 loss: 0.0005576571566052735
batch 180 loss: 0.0005576347932219506
batch 185 loss: 0.0005575704970397055
batch 190 loss: 0.0005577568197622895
batch 195 loss: 0.0005577727453783155
batch 200 loss: 0.0005576549330726266
batch 205 loss: 0.0005576766096055507
batch 210 loss: 0.0005576398340053857
batch 215 loss: 0.0005577343399636447
batch 220 loss: 0.0005575925461016595
batch 225 loss: 0.0005577532458119095
batch 230 loss: 0.000557620415929705
batch 235 loss: 0.0005576207768172026
batch 240 loss: 0.0005577092990279198
Training Loss: 0.0005576834499758358
Validation Loss: 0.0005576934694545343
Epoch 44:
batch 5 loss: 0.0005576645489782095
batch 10 loss: 0.0005576702184043825
batch 15 loss: 0.0005577302770689129
batch 20 loss: 0.0005576380994170904
batch 25 loss: 0.0005576849100179971
batch 30 loss: 0.0005575805436819792
batch 35 loss: 0.0005576946423389018
batch 40 loss: 0.0005576847703196109
batch 45 loss: 0.0005575783434323967
batch 50 loss: 0.0005576539202593267
batch 55 loss: 0.0005576642695814371
batch 60 loss: 0.0005577149917371571
batch 65 loss: 0.0005576761905103922
batch 70 loss: 0.0005576872848905623
batch 75 loss: 0.0005577702191658318
batch 80 loss: 0.0005576712777838111
batch 85 loss: 0.0005577275995165109
batch 90 loss: 0.0005576974130235612
batch 95 loss: 0.0005577575066126883
batch 100 loss: 0.0005575807997956872
batch 105 loss: 0.0005576551426202059
batch 110 loss: 0.0005577447125688195
batch 115 loss: 0.000557697843760252
batch 120 loss: 0.0005578049924224616
batch 125 loss: 0.0005577428499236702
batch 130 loss: 0.0005576877505518496
batch 135 loss: 0.0005576631403528154
batch 140 loss: 0.0005576645489782095
batch 145 loss: 0.0005576659343205393
batch 150 loss: 0.0005577068775892257
batch 155 loss: 0.0005576525931246578
batch 160 loss: 0.0005577108124271036
batch 165 loss: 0.0005575363175012171
batch 170 loss: 0.0005577705334872008
batch 175 loss: 0.000557727797422558
batch 180 loss: 0.0005575945251621306
batch 185 loss: 0.0005577520933002234
batch 190 loss: 0.0005575773888267576
batch 195 loss: 0.0005578564247116447
batch 200 loss: 0.0005575284361839294
batch 205 loss: 0.0005576307419687509
batch 210 loss: 0.00055763985728845
batch 215 loss: 0.0005576765979640186
batch 220 loss: 0.0005577469011768699
batch 225 loss: 0.0005578119191341103
batch 230 loss: 0.0005575623596087098
batch 235 loss: 0.0005577369360253215
batch 240 loss: 0.0005577347707003355
Training Loss: 0.0005576835130341351
Validation Loss: 0.000557693531542706
Epoch 45:
batch 5 loss: 0.0005577726755291223
batch 10 loss: 0.0005576789029873907
batch 15 loss: 0.0005576445953920483
batch 20 loss: 0.0005576924770139158
batch 25 loss: 0.0005576350493356585
batch 30 loss: 0.000557798717636615
batch 35 loss: 0.0005576757714152337
batch 40 loss: 0.0005576557014137506
batch 45 loss: 0.0005577268777415157
batch 50 loss: 0.0005576804047450423
batch 55 loss: 0.0005577407311648131
batch 60 loss: 0.0005576044903136789
batch 65 loss: 0.0005576304509304463
batch 70 loss: 0.0005577420000918209
batch 75 loss: 0.0005578795680776238
batch 80 loss: 0.0005576208583079279
batch 85 loss: 0.0005577641422860324
batch 90 loss: 0.0005577115807682276
batch 95 loss: 0.0005576608469709754
batch 100 loss: 0.0005576400784775615
batch 105 loss: 0.0005577196017839015
batch 110 loss: 0.0005577529431320727
batch 115 loss: 0.000557625270448625
batch 120 loss: 0.0005576324765570462
batch 125 loss: 0.0005576961673796176
batch 130 loss: 0.0005577424890361726
batch 135 loss: 0.0005576967494562268
batch 140 loss: 0.0005576150142587721
batch 145 loss: 0.0005577610456384719
batch 150 loss: 0.0005577053292654454
batch 155 loss: 0.0005577596602961421
batch 160 loss: 0.0005576790776103735
batch 165 loss: 0.0005576226860284806
batch 170 loss: 0.000557590217795223
batch 175 loss: 0.0005578097072429955
batch 180 loss: 0.0005575978895649314
batch 185 loss: 0.0005577355157583952
batch 190 loss: 0.0005575641756877303
batch 195 loss: 0.0005576701485551893
batch 200 loss: 0.0005577541189268232
batch 205 loss: 0.0005576574127189815
batch 210 loss: 0.0005577655858360231
batch 215 loss: 0.0005575735121965408
batch 220 loss: 0.0005575251299887896
batch 225 loss: 0.00055766343139112
batch 230 loss: 0.0005575341405346989
batch 235 loss: 0.0005577693809755147
batch 240 loss: 0.000557632022537291
Training Loss: 0.0005576834754416874
Validation Loss: 0.0005576935878101115
Epoch 46:
batch 5 loss: 0.0005576423718594015
batch 10 loss: 0.0005577006842941046
batch 15 loss: 0.0005576158058829605
batch 20 loss: 0.0005576759576797485
batch 25 loss: 0.0005576124414801598
batch 30 loss: 0.0005575947114266455
batch 35 loss: 0.0005577345960773528
batch 40 loss: 0.0005577492062002421
batch 45 loss: 0.0005576607887633145
batch 50 loss: 0.0005576945026405155
batch 55 loss: 0.0005577667383477092
batch 60 loss: 0.0005575885297730565
batch 65 loss: 0.0005577230360358954
batch 70 loss: 0.0005575843621045351
batch 75 loss: 0.0005575985298492015
batch 80 loss: 0.0005576872499659657
batch 85 loss: 0.0005577667732723057
batch 90 loss: 0.0005576724768616259
batch 95 loss: 0.0005576709168963135
batch 100 loss: 0.0005575796822085977
batch 105 loss: 0.000557713711168617
batch 110 loss: 0.0005577727686613798
batch 115 loss: 0.00055782605195418
batch 120 loss: 0.0005576277850195766
batch 125 loss: 0.0005576498457230628
batch 130 loss: 0.0005576570518314838
batch 135 loss: 0.0005576583440415561
batch 140 loss: 0.0005577318836003542
batch 145 loss: 0.000557726004626602
batch 150 loss: 0.0005577355972491205
batch 155 loss: 0.0005577000905759632
batch 160 loss: 0.000557731103617698
batch 165 loss: 0.0005575525807216764
batch 170 loss: 0.0005576474359259009
batch 175 loss: 0.0005576500319875777
batch 180 loss: 0.0005576918134465814
batch 185 loss: 0.0005576585885137319
batch 190 loss: 0.000557734165340662
batch 195 loss: 0.0005576657131314278
batch 200 loss: 0.0005576537107117475
batch 205 loss: 0.0005577666102908552
batch 210 loss: 0.0005576498806476593
batch 215 loss: 0.0005577364121563732
batch 220 loss: 0.0005576738272793591
batch 225 loss: 0.0005578113603405654
batch 230 loss: 0.0005577625008299947
batch 235 loss: 0.0005576651310548186
batch 240 loss: 0.0005576391005888582
Training Loss: 0.0005576835096386882
Validation Loss: 0.0005576934684844067
Epoch 47:
batch 5 loss: 0.0005577012314461171
batch 10 loss: 0.0005577087169513107
batch 15 loss: 0.0005577007890678942
batch 20 loss: 0.0005576736177317799
batch 25 loss: 0.0005577409407123924
batch 30 loss: 0.0005577579606324435
batch 35 loss: 0.0005577059113420546
batch 40 loss: 0.0005576893454417586
batch 45 loss: 0.0005575403687544167
batch 50 loss: 0.0005577198928222061
batch 55 loss: 0.000557703827507794
batch 60 loss: 0.0005576855619437993
batch 65 loss: 0.0005577693111263216
batch 70 loss: 0.0005576177034527063
batch 75 loss: 0.0005576430819928646
batch 80 loss: 0.0005578355048783123
batch 85 loss: 0.0005576219409704208
batch 90 loss: 0.0005576485418714583
batch 95 loss: 0.000557836052030325
batch 100 loss: 0.0005577341886237264
batch 105 loss: 0.0005576216499321163
batch 110 loss: 0.0005577157367952168
batch 115 loss: 0.0005576829425990582
batch 120 loss: 0.000557665282394737
batch 125 loss: 0.0005576220573857427
batch 130 loss: 0.0005576576921157538
batch 135 loss: 0.0005577189265750348
batch 140 loss: 0.0005576648400165141
batch 145 loss: 0.0005576069583185017
batch 150 loss: 0.0005575916497036814
batch 155 loss: 0.0005576740484684705
batch 160 loss: 0.0005577724776230752
batch 165 loss: 0.0005576135008595884
batch 170 loss: 0.0005575760267674923
batch 175 loss: 0.0005576246883720159
batch 180 loss: 0.0005577248055487871
batch 185 loss: 0.0005577053059823811
batch 190 loss: 0.0005576533148996532
batch 195 loss: 0.000557748565915972
batch 200 loss: 0.0005576774594374001
batch 205 loss: 0.0005576965981163084
batch 210 loss: 0.0005576797062531114
batch 215 loss: 0.0005576444789767265
batch 220 loss: 0.0005577135016210377
batch 225 loss: 0.0005577857722528279
batch 230 loss: 0.0005575402756221592
batch 235 loss: 0.0005576726282015443
batch 240 loss: 0.0005577226052992046
Training Loss: 0.0005576834996948794
Validation Loss: 0.0005576934345299378
Epoch 48:
batch 5 loss: 0.0005577059928327799
batch 10 loss: 0.0005576315918006003
batch 15 loss: 0.0005576591356657445
batch 20 loss: 0.0005577389616519213
batch 25 loss: 0.0005576727795414627
batch 30 loss: 0.0005576266208663583
batch 35 loss: 0.0005577549221925437
batch 40 loss: 0.0005576760857366025
batch 45 loss: 0.0005577273550443351
batch 50 loss: 0.0005576939438469708
batch 55 loss: 0.000557531020604074
batch 60 loss: 0.0005575927789323032
batch 65 loss: 0.0005575533141382039
batch 70 loss: 0.0005577229079790413
batch 75 loss: 0.0005577011033892632
batch 80 loss: 0.0005576614756137132
batch 85 loss: 0.0005576516734436155
batch 90 loss: 0.0005577556672506035
batch 95 loss: 0.0005576454102993011
batch 100 loss: 0.0005575850140303373
batch 105 loss: 0.0005576348514296115
batch 110 loss: 0.0005577373085543513
batch 115 loss: 0.0005577094736509026
batch 120 loss: 0.0005575295421294868
batch 125 loss: 0.0005577651085332036
batch 130 loss: 0.0005576363764703274
batch 135 loss: 0.0005577640607953071
batch 140 loss: 0.0005577801144681871
batch 145 loss: 0.0005577767267823219
batch 150 loss: 0.0005577373318374157
batch 155 loss: 0.0005576850264333189
batch 160 loss: 0.0005576825118623674
batch 165 loss: 0.0005577260395511985
batch 170 loss: 0.0005576750030741095
batch 175 loss: 0.000557729578576982
batch 180 loss: 0.0005576775176450611
batch 185 loss: 0.0005576877156272531
batch 190 loss: 0.000557705806568265
batch 195 loss: 0.0005576670169830322
batch 200 loss: 0.0005576017312705517
batch 205 loss: 0.0005577336647547782
batch 210 loss: 0.000557697075419128
batch 215 loss: 0.0005577431293204427
batch 220 loss: 0.0005577312665991485
batch 225 loss: 0.0005576937575824559
batch 230 loss: 0.0005576167488470674
batch 235 loss: 0.0005577209056355059
batch 240 loss: 0.0005576750612817704
Training Loss: 0.000557683504302986
Validation Loss: 0.0005576934927375987
Epoch 49:
batch 5 loss: 0.000557630171533674
batch 10 loss: 0.0005577606032602489
batch 15 loss: 0.0005577418021857738
batch 20 loss: 0.0005576943163760007
batch 25 loss: 0.0005577016388997435
batch 30 loss: 0.0005577740725129843
batch 35 loss: 0.0005577220232225955
batch 40 loss: 0.0005576554918661714
batch 45 loss: 0.0005576515570282937
batch 50 loss: 0.0005577174131758511
batch 55 loss: 0.000557708297856152
batch 60 loss: 0.0005576340714469552
batch 65 loss: 0.0005576056893914938
batch 70 loss: 0.0005576501018367708
batch 75 loss: 0.000557703897356987
batch 80 loss: 0.0005576512659899891
batch 85 loss: 0.0005576445139013231
batch 90 loss: 0.0005578030017204582
batch 95 loss: 0.0005576655152253806
batch 100 loss: 0.0005576506722718477
batch 105 loss: 0.0005576941068284214
batch 110 loss: 0.0005577150965109468
batch 115 loss: 0.0005577823845669627
batch 120 loss: 0.0005575989605858922
batch 125 loss: 0.0005576997878961265
batch 130 loss: 0.0005576638854108751
batch 135 loss: 0.0005576958763413131
batch 140 loss: 0.0005575923365540803
batch 145 loss: 0.000557662162464112
batch 150 loss: 0.0005576872965320945
batch 155 loss: 0.0005577066214755178
batch 160 loss: 0.0005577292875386774
batch 165 loss: 0.0005577775766141713
batch 170 loss: 0.0005576584488153457
batch 175 loss: 0.0005576350493356585
batch 180 loss: 0.0005576094728894532
batch 185 loss: 0.0005576160969212651
batch 190 loss: 0.0005576487863436341
batch 195 loss: 0.0005577443051151931
batch 200 loss: 0.0005576816038228571
batch 205 loss: 0.0005577916861511766
batch 210 loss: 0.0005576055380515754
batch 215 loss: 0.0005576845607720316
batch 220 loss: 0.0005576803465373814
batch 225 loss: 0.0005577105795964599
batch 230 loss: 0.0005576534778811038
batch 235 loss: 0.0005576858180575073
batch 240 loss: 0.0005576301016844809
Training Loss: 0.0005576834868406877
Validation Loss: 0.000557693574228324
Epoch 50:
batch 5 loss: 0.0005576031748205423
batch 10 loss: 0.00055765068391338
batch 15 loss: 0.0005577003699727357
batch 20 loss: 0.000557669228874147
batch 25 loss: 0.0005577479139901697
batch 30 loss: 0.0005576666677370668
batch 35 loss: 0.0005575599265284836
batch 40 loss: 0.0005577442701905966
batch 45 loss: 0.0005576319643296301
batch 50 loss: 0.0005576273426413537
batch 55 loss: 0.0005576029303483665
batch 60 loss: 0.0005575567483901978
batch 65 loss: 0.0005576855386607349
batch 70 loss: 0.0005577743519097567
batch 75 loss: 0.0005578005220741034
batch 80 loss: 0.000557848543394357
batch 85 loss: 0.0005577094736509026
batch 90 loss: 0.0005577094736509026
batch 95 loss: 0.0005576638854108751
batch 100 loss: 0.0005578071693889796
batch 105 loss: 0.0005576442461460828
batch 110 loss: 0.0005576939089223743
batch 115 loss: 0.0005576144903898239
batch 120 loss: 0.0005576421623118222
batch 125 loss: 0.0005577501025982202
batch 130 loss: 0.0005575655493885278
batch 135 loss: 0.0005577539443038404
batch 140 loss: 0.0005576712777838111
batch 145 loss: 0.0005576822557486593
batch 150 loss: 0.0005577467149123549
batch 155 loss: 0.0005577175063081086
batch 160 loss: 0.0005577455507591367
batch 165 loss: 0.0005577090429142118
batch 170 loss: 0.0005576914991252124
batch 175 loss: 0.0005575480754487216
batch 180 loss: 0.0005576536990702152
batch 185 loss: 0.0005577617906965315
batch 190 loss: 0.000557689182460308
batch 195 loss: 0.0005576268653385341
batch 200 loss: 0.0005576129886321723
batch 205 loss: 0.0005576497409492731
batch 210 loss: 0.0005577113013714551
batch 215 loss: 0.0005576894385740161
batch 220 loss: 0.0005576609051786363
batch 225 loss: 0.0005576811381615698
batch 230 loss: 0.0005577058764174581
batch 235 loss: 0.0005577106960117817
batch 240 loss: 0.000557717343326658
Training Loss: 0.0005576834890234749
Validation Loss: 0.0005576935451244936
Epoch 51:
batch 5 loss: 0.0005576939671300352
batch 10 loss: 0.0005576584138907492
batch 15 loss: 0.0005576326046139001
batch 20 loss: 0.0005577044445089996
batch 25 loss: 0.0005577094852924347
batch 30 loss: 0.000557686435058713
batch 35 loss: 0.0005576758529059588
batch 40 loss: 0.0005576811614446342
batch 45 loss: 0.0005576597875915467
batch 50 loss: 0.0005576255265623331
batch 55 loss: 0.0005576973082497716
batch 60 loss: 0.0005577224073931575
batch 65 loss: 0.0005576807190664113
batch 70 loss: 0.0005576698225922882
batch 75 loss: 0.0005577450385317207
batch 80 loss: 0.0005576762603595852
batch 85 loss: 0.0005577219417318702
batch 90 loss: 0.0005576890427619219
batch 95 loss: 0.000557639030739665
batch 100 loss: 0.0005576292751356959
batch 105 loss: 0.0005576671566814185
batch 110 loss: 0.0005576281691901386
batch 115 loss: 0.0005576125695370138
batch 120 loss: 0.0005575879593379795
batch 125 loss: 0.0005577205098234117
batch 130 loss: 0.0005577265401370823
batch 135 loss: 0.0005576575174927711
batch 140 loss: 0.0005577188567258418
batch 145 loss: 0.0005576007766649127
batch 150 loss: 0.0005577137577347458
batch 155 loss: 0.0005576423252932727
batch 160 loss: 0.0005577893112786114
batch 165 loss: 0.0005577537231147289
batch 170 loss: 0.0005576619412750005
batch 175 loss: 0.0005576923373155296
batch 180 loss: 0.000557670823764056
batch 185 loss: 0.0005576741648837924
batch 190 loss: 0.0005576649447903038
batch 195 loss: 0.0005577162024565041
batch 200 loss: 0.0005577078904025256
batch 205 loss: 0.0005577030824497342
batch 210 loss: 0.0005578335491009057
batch 215 loss: 0.0005576756200753152
batch 220 loss: 0.0005576787865720689
batch 225 loss: 0.0005576796480454505
batch 230 loss: 0.0005576276686042547
batch 235 loss: 0.0005577566218562425
batch 240 loss: 0.0005576450028456747
Training Loss: 0.0005576834579793891
Validation Loss: 0.0005576934345299378
Epoch 52:
batch 5 loss: 0.0005577929550781846
batch 10 loss: 0.0005575968767516315
batch 15 loss: 0.0005577426636591554
batch 20 loss: 0.0005576833500526845
batch 25 loss: 0.0005577223957516253
batch 30 loss: 0.000557837204542011
batch 35 loss: 0.0005576886469498277
batch 40 loss: 0.0005577165167778731
batch 45 loss: 0.0005575882154516876
batch 50 loss: 0.0005576648632995784
batch 55 loss: 0.0005575969931669533
batch 60 loss: 0.000557745061814785
batch 65 loss: 0.0005577297182753682
batch 70 loss: 0.0005576696246862411
batch 75 loss: 0.0005578532232902944
batch 80 loss: 0.0005576815805397928
batch 85 loss: 0.0005575736868195236
batch 90 loss: 0.0005577098694629967
batch 95 loss: 0.0005576826515607536
batch 100 loss: 0.0005575844319537282
batch 105 loss: 0.0005576194496825337
batch 110 loss: 0.0005576372612267732
batch 115 loss: 0.0005576554569415749
batch 120 loss: 0.0005577167263254523
batch 125 loss: 0.0005576536292210222
batch 130 loss: 0.0005576630705036223
batch 135 loss: 0.0005576451658271253
batch 140 loss: 0.0005575248273089528
batch 145 loss: 0.0005577044794335961
batch 150 loss: 0.0005577054340392351
batch 155 loss: 0.0005576561205089092
batch 160 loss: 0.0005577186006121337
batch 165 loss: 0.0005577195435762406
batch 170 loss: 0.0005576357361860573
batch 175 loss: 0.0005577498348429799
batch 180 loss: 0.0005577499512583017
batch 185 loss: 0.0005577827570959926
batch 190 loss: 0.0005577578325755894
batch 195 loss: 0.0005576825700700283
batch 200 loss: 0.0005577121395617723
batch 205 loss: 0.0005577231757342815
batch 210 loss: 0.0005576274008490146
batch 215 loss: 0.0005577116971835494
batch 220 loss: 0.0005576020921580493
batch 225 loss: 0.0005575151182711125
batch 230 loss: 0.0005576736410148441
batch 235 loss: 0.0005576718365773558
batch 240 loss: 0.0005577292526140809
Training Loss: 0.0005576834443976016
Validation Loss: 0.0005576933986352135
Epoch 53:
batch 5 loss: 0.0005578585900366306
batch 10 loss: 0.0005576747586019337
batch 15 loss: 0.0005576695315539837
batch 20 loss: 0.0005577989504672587
batch 25 loss: 0.0005577000905759632
batch 30 loss: 0.0005575953051447869
batch 35 loss: 0.0005576560040935874
batch 40 loss: 0.0005576857714913785
batch 45 loss: 0.0005576566094532609
batch 50 loss: 0.0005576886469498277
batch 55 loss: 0.0005577294155955315
batch 60 loss: 0.0005575990653596818
batch 65 loss: 0.0005577023490332067
batch 70 loss: 0.0005577232223004103
batch 75 loss: 0.0005576616851612926
batch 80 loss: 0.0005575376795604825
batch 85 loss: 0.0005577875184826553
batch 90 loss: 0.0005577477160841227
batch 95 loss: 0.0005577171803452074
batch 100 loss: 0.0005576137453317642
batch 105 loss: 0.0005577235016971827
batch 110 loss: 0.0005576597293838858
batch 115 loss: 0.0005577539210207761
batch 120 loss: 0.0005576728959567845
batch 125 loss: 0.0005577800679020583
batch 130 loss: 0.000557597540318966
batch 135 loss: 0.0005576381110586226
batch 140 loss: 0.000557699438650161
batch 145 loss: 0.0005577715230174363
batch 150 loss: 0.0005575952818617225
batch 155 loss: 0.0005577037460170686
batch 160 loss: 0.0005576383671723306
batch 165 loss: 0.0005577371804974974
batch 170 loss: 0.0005576559691689908
batch 175 loss: 0.0005576576222665608
batch 180 loss: 0.0005577072617597878
batch 185 loss: 0.0005575658637098968
batch 190 loss: 0.0005576516850851476
batch 195 loss: 0.0005576406954787671
batch 200 loss: 0.0005576074356213212
batch 205 loss: 0.0005577904288657009
batch 210 loss: 0.0005576975410804153
batch 215 loss: 0.0005576772266067565
batch 220 loss: 0.0005576778319664299
batch 225 loss: 0.0005576462717726827
batch 230 loss: 0.0005576693685725332
batch 235 loss: 0.0005577226402238011
batch 240 loss: 0.0005576641764491796
Training Loss: 0.0005576834824751131
Validation Loss: 0.0005576937643733496
Epoch 54:
batch 5 loss: 0.000557687459513545
batch 10 loss: 0.0005576677387580276
batch 15 loss: 0.0005577613250352442
batch 20 loss: 0.000557795655913651
batch 25 loss: 0.0005576706724241375
batch 30 loss: 0.000557658274192363
batch 35 loss: 0.0005576922907494008
batch 40 loss: 0.0005576752941124141
batch 45 loss: 0.0005576149793341756
batch 50 loss: 0.000557720148935914
batch 55 loss: 0.0005576899973675608
batch 60 loss: 0.0005577657953836024
batch 65 loss: 0.000557762396056205
batch 70 loss: 0.0005576528958044947
batch 75 loss: 0.000557610671967268
batch 80 loss: 0.0005577425356023014
batch 85 loss: 0.0005576798343099654
batch 90 loss: 0.0005574789945967495
batch 95 loss: 0.0005575927323661744
batch 100 loss: 0.0005575663293711841
batch 105 loss: 0.0005577065981924534
batch 110 loss: 0.000557677261531353
batch 115 loss: 0.0005576919415034354
batch 120 loss: 0.0005575985764153301
batch 125 loss: 0.0005577158997766673
batch 130 loss: 0.0005576589959673583
batch 135 loss: 0.0005577561794780194
batch 140 loss: 0.000557774817571044
batch 145 loss: 0.0005576561205089092
batch 150 loss: 0.000557803746778518
batch 155 loss: 0.0005576906842179596
batch 160 loss: 0.0005577709292992949
batch 165 loss: 0.0005576835013926029
batch 170 loss: 0.0005577358533628285
batch 175 loss: 0.0005576441879384219
batch 180 loss: 0.0005576531519182026
batch 185 loss: 0.0005576965515501798
batch 190 loss: 0.0005576715571805835
batch 195 loss: 0.0005577271338552236
batch 200 loss: 0.0005576125811785459
batch 205 loss: 0.0005576184135861695
batch 210 loss: 0.0005576822790317237
batch 215 loss: 0.0005576954572461545
batch 220 loss: 0.0005576397175900638
batch 225 loss: 0.0005576026509515941
batch 230 loss: 0.0005577416392043233
batch 235 loss: 0.0005577714066021145
batch 240 loss: 0.0005576441064476967
Training Loss: 0.0005576834992098156
Validation Loss: 0.0005576934713947897
Epoch 55:
batch 5 loss: 0.000557729066349566
batch 10 loss: 0.0005576435010880232
batch 15 loss: 0.0005577843519859016
batch 20 loss: 0.0005575966788455844
batch 25 loss: 0.0005577218253165483
batch 30 loss: 0.0005577171570621431
batch 35 loss: 0.0005576392053626478
batch 40 loss: 0.00055767553858459
batch 45 loss: 0.000557607610244304
batch 50 loss: 0.0005576296360231936
batch 55 loss: 0.0005575215094722807
batch 60 loss: 0.0005577252595685422
batch 65 loss: 0.0005576883791945875
batch 70 loss: 0.0005577183328568935
batch 75 loss: 0.0005576030584052205
batch 80 loss: 0.0005576987401582301
batch 85 loss: 0.0005577377742156386
batch 90 loss: 0.0005578244454227388
batch 95 loss: 0.0005577628850005567
batch 100 loss: 0.0005577066331170499
batch 105 loss: 0.0005577216972596944
batch 110 loss: 0.0005577793810516596
batch 115 loss: 0.0005577980075031519
batch 120 loss: 0.0005575435818172992
batch 125 loss: 0.000557607738301158
batch 130 loss: 0.0005576452356763184
batch 135 loss: 0.0005577017436735332
batch 140 loss: 0.0005577017203904688
batch 145 loss: 0.0005577443866059184
batch 150 loss: 0.0005577463074587285
batch 155 loss: 0.0005577565869316458
batch 160 loss: 0.0005575763410888612
batch 165 loss: 0.000557613221462816
batch 170 loss: 0.0005576948402449489
batch 175 loss: 0.0005577828153036535
batch 180 loss: 0.000557672546710819
batch 185 loss: 0.0005577175761573017
batch 190 loss: 0.0005576614639721811
batch 195 loss: 0.0005576382158324122
batch 200 loss: 0.0005576392286457121
batch 205 loss: 0.0005577165051363408
batch 210 loss: 0.0005576314637437463
batch 215 loss: 0.0005577443866059184
batch 220 loss: 0.0005576521041803062
batch 225 loss: 0.0005576509982347488
batch 230 loss: 0.0005576669238507748
batch 235 loss: 0.0005576316616497934
batch 240 loss: 0.0005576379364356399
Training Loss: 0.0005576834625874957
Validation Loss: 0.0005576934384104485
Epoch 56:
batch 5 loss: 0.0005577458301559091
batch 10 loss: 0.0005578203359618783
batch 15 loss: 0.0005577170173637569
batch 20 loss: 0.0005576634197495878
batch 25 loss: 0.0005576326628215611
batch 30 loss: 0.0005576835363171994
batch 35 loss: 0.0005576467257924378
batch 40 loss: 0.0005576316150836646
batch 45 loss: 0.0005577394040301442
batch 50 loss: 0.0005576873081736267
batch 55 loss: 0.0005576905678026378
batch 60 loss: 0.0005576830473728478
batch 65 loss: 0.0005577278789132833
batch 70 loss: 0.0005576986935921013
batch 75 loss: 0.0005576238385401666
batch 80 loss: 0.0005577520467340946
batch 85 loss: 0.0005577373085543513
batch 90 loss: 0.000557733466848731
batch 95 loss: 0.0005577410222031177
batch 100 loss: 0.0005575628136284649
batch 105 loss: 0.0005577087285928428
batch 110 loss: 0.0005576202063821256
batch 115 loss: 0.0005576065508648753
batch 120 loss: 0.0005576760973781347
batch 125 loss: 0.0005577093339525163
batch 130 loss: 0.0005577709176577628
batch 135 loss: 0.0005577771924436092
batch 140 loss: 0.0005576879717409611
batch 145 loss: 0.0005576711730100215
batch 150 loss: 0.0005575851304456591
batch 155 loss: 0.0005576037336140871
batch 160 loss: 0.0005577826290391385
batch 165 loss: 0.0005576343042775989
batch 170 loss: 0.0005576591356657445
batch 175 loss: 0.0005576550727710127
batch 180 loss: 0.0005576774710789323
batch 185 loss: 0.000557644059881568
batch 190 loss: 0.0005577160511165858
batch 195 loss: 0.0005576968542300165
batch 200 loss: 0.0005577137228101492
batch 205 loss: 0.0005577242700383067
batch 210 loss: 0.0005575719638727606
batch 215 loss: 0.0005576138850301504
batch 220 loss: 0.0005575921968556941
batch 225 loss: 0.0005576922092586755
batch 230 loss: 0.0005576835246756673
batch 235 loss: 0.000557684653904289
batch 240 loss: 0.0005577287287451327
Training Loss: 0.0005576834647702829
Validation Loss: 0.0005576934616935129
Epoch 57:
batch 5 loss: 0.0005576925934292376
batch 10 loss: 0.0005577467265538872
batch 15 loss: 0.0005576068768277764
batch 20 loss: 0.0005576766794547439
batch 25 loss: 0.0005576668307185173
batch 30 loss: 0.0005576949333772063
batch 35 loss: 0.0005576752475462854
batch 40 loss: 0.0005576467607170344
batch 45 loss: 0.0005576364696025848
batch 50 loss: 0.0005577165866270661
batch 55 loss: 0.0005576321389526128
batch 60 loss: 0.0005577792879194021
batch 65 loss: 0.0005576967261731625
batch 70 loss: 0.0005577319301664829
batch 75 loss: 0.0005576842348091304
batch 80 loss: 0.0005576313356868923
batch 85 loss: 0.0005577618023380638
batch 90 loss: 0.0005577097181230783
batch 95 loss: 0.0005576751194894314
batch 100 loss: 0.0005576316849328578
batch 105 loss: 0.0005576751194894314
batch 110 loss: 0.0005577167146839201
batch 115 loss: 0.000557468831539154
batch 120 loss: 0.0005576843395829201
batch 125 loss: 0.0005576669122092426
batch 130 loss: 0.0005577234434895218
batch 135 loss: 0.0005577063653618098
batch 140 loss: 0.0005577378207817674
batch 145 loss: 0.0005577886011451482
batch 150 loss: 0.0005576560506597161
batch 155 loss: 0.0005575870978645981
batch 160 loss: 0.0005577293457463383
batch 165 loss: 0.0005576468887738883
batch 170 loss: 0.0005576618830673396
batch 175 loss: 0.0005576770519837738
batch 180 loss: 0.0005576612893491983
batch 185 loss: 0.0005576408584602177
batch 190 loss: 0.0005577743286266923
batch 195 loss: 0.0005576314404606819
batch 200 loss: 0.0005577093921601773
batch 205 loss: 0.0005576198338530958
batch 210 loss: 0.0005578855983912945
batch 215 loss: 0.0005576616851612926
batch 220 loss: 0.0005576114286668599
batch 225 loss: 0.0005575935123488307
batch 230 loss: 0.0005577887175604701
batch 235 loss: 0.0005576984956860542
batch 240 loss: 0.0005577101605013013
Training Loss: 0.000557683476896879
Validation Loss: 0.0005576934403507039
Epoch 58:
batch 5 loss: 0.0005575761781074107
batch 10 loss: 0.0005577662726864218
batch 15 loss: 0.0005576880415901541
batch 20 loss: 0.0005576455150730908
batch 25 loss: 0.0005577129893936216
batch 30 loss: 0.0005576888099312783
batch 35 loss: 0.0005576407420448959
batch 40 loss: 0.0005576424766331912
batch 45 loss: 0.0005576583789661527
batch 50 loss: 0.0005576704163104296
batch 55 loss: 0.0005577629082836211
batch 60 loss: 0.000557699054479599
batch 65 loss: 0.00055773543426767
batch 70 loss: 0.0005577217671088874
batch 75 loss: 0.0005576687050051987
batch 80 loss: 0.0005577256204560399
batch 85 loss: 0.0005576974828727544
batch 90 loss: 0.0005577750504016876
batch 95 loss: 0.0005575991002842784
batch 100 loss: 0.0005577253876253962
batch 105 loss: 0.0005578105221502483
batch 110 loss: 0.0005576455499976873
batch 115 loss: 0.0005577870761044323
batch 120 loss: 0.0005576478550210595
batch 125 loss: 0.0005576317431405187
batch 130 loss: 0.0005576065974310041
batch 135 loss: 0.000557562557514757
batch 140 loss: 0.0005576350842602551
batch 145 loss: 0.0005576547235250473
batch 150 loss: 0.0005578097654506565
batch 155 loss: 0.0005576439201831817
batch 160 loss: 0.0005577154690399766
batch 165 loss: 0.0005576261202804745
batch 170 loss: 0.0005577673902735115
batch 175 loss: 0.0005576379830017686
batch 180 loss: 0.0005575890303589403
batch 185 loss: 0.0005576929077506065
batch 190 loss: 0.0005576584255322814
batch 195 loss: 0.0005576899740844965
batch 200 loss: 0.0005578369251452387
batch 205 loss: 0.0005575820687226951
batch 210 loss: 0.0005577772855758667
batch 215 loss: 0.0005576515453867614
batch 220 loss: 0.0005576327559538186
batch 225 loss: 0.0005576663766987622
batch 230 loss: 0.0005577363423071802
batch 235 loss: 0.0005576577386818826
batch 240 loss: 0.0005576518247835338
Training Loss: 0.0005576834560391338
Validation Loss: 0.0005576934083364904
Epoch 59:
batch 5 loss: 0.0005577150848694145
batch 10 loss: 0.0005577397649176418
batch 15 loss: 0.0005576349911279976
batch 20 loss: 0.0005576580297201872
batch 25 loss: 0.0005576646304689348
batch 30 loss: 0.0005576965166255831
batch 35 loss: 0.000557712942827493
batch 40 loss: 0.0005576687632128597
batch 45 loss: 0.0005577875534072518
batch 50 loss: 0.000557584292255342
batch 55 loss: 0.0005577516625635326
batch 60 loss: 0.0005576983909122646
batch 65 loss: 0.0005576998228207231
batch 70 loss: 0.0005576996132731438
batch 75 loss: 0.0005577231175266206
batch 80 loss: 0.0005577496020123362
batch 85 loss: 0.0005577937699854374
batch 90 loss: 0.0005576327675953507
batch 95 loss: 0.0005576818017289043
batch 100 loss: 0.0005576037685386837
batch 105 loss: 0.0005576006951741874
batch 110 loss: 0.0005577080184593797
batch 115 loss: 0.0005576390540227294
batch 120 loss: 0.0005576577852480114
batch 125 loss: 0.000557785015553236
batch 130 loss: 0.0005576382507570087
batch 135 loss: 0.0005577839910984039
batch 140 loss: 0.00055757078807801
batch 145 loss: 0.0005576246883720159
batch 150 loss: 0.0005576232215389609
batch 155 loss: 0.0005576587864197791
batch 160 loss: 0.0005577851436100901
batch 165 loss: 0.0005576415103860199
batch 170 loss: 0.0005576946772634983
batch 175 loss: 0.000557600986212492
batch 180 loss: 0.0005577555508352816
batch 185 loss: 0.0005576647585257888
batch 190 loss: 0.0005576689727604389
batch 195 loss: 0.0005577472038567066
batch 200 loss: 0.0005576793220825494
batch 205 loss: 0.0005576606490649283
batch 210 loss: 0.0005576917319558561
batch 215 loss: 0.0005577303469181061
batch 220 loss: 0.0005576571566052735
batch 225 loss: 0.0005576561205089092
batch 230 loss: 0.0005576312192715705
batch 235 loss: 0.0005577542819082737
batch 240 loss: 0.0005575996008701622
Training Loss: 0.0005576834669530702
Validation Loss: 0.0005576934665441513
Epoch 60:
batch 5 loss: 0.0005577104748226702
batch 10 loss: 0.0005577007890678942
batch 15 loss: 0.0005577019299380481
batch 20 loss: 0.0005575993680395186
batch 25 loss: 0.0005575658869929612
batch 30 loss: 0.0005577121861279011
batch 35 loss: 0.0005577283911406994
batch 40 loss: 0.0005576916388235986
batch 45 loss: 0.0005576584138907492
batch 50 loss: 0.0005576703581027687
batch 55 loss: 0.0005576581112109125
batch 60 loss: 0.0005576519179157913
batch 65 loss: 0.0005577714066021145
batch 70 loss: 0.0005576847353950143
batch 75 loss: 0.0005577493109740316
batch 80 loss: 0.0005577262723818422
batch 85 loss: 0.0005577299743890762
batch 90 loss: 0.0005577781470492482
batch 95 loss: 0.0005576408351771533
batch 100 loss: 0.0005576101830229163
batch 105 loss: 0.0005575761431828141
batch 110 loss: 0.000557690067216754
batch 115 loss: 0.0005576927913352847
batch 120 loss: 0.000557750032749027
batch 125 loss: 0.0005577107542194426
batch 130 loss: 0.000557756726630032
batch 135 loss: 0.0005576230818405747
batch 140 loss: 0.0005577033967711032
batch 145 loss: 0.0005577769712544978
batch 150 loss: 0.0005576645955443383
batch 155 loss: 0.0005576578201726079
batch 160 loss: 0.0005576331401243806
batch 165 loss: 0.0005578226526267826
batch 170 loss: 0.0005577055853791535
batch 175 loss: 0.0005577132687903941
batch 180 loss: 0.0005577043164521455
batch 185 loss: 0.0005575915798544884
batch 190 loss: 0.0005575931048952043
batch 195 loss: 0.0005577341420575976
batch 200 loss: 0.0005577237345278264
batch 205 loss: 0.0005576630122959614
batch 210 loss: 0.0005576529074460268
batch 215 loss: 0.00055762710981071
batch 220 loss: 0.0005577001138590276
batch 225 loss: 0.0005576243158429862
batch 230 loss: 0.0005576043971814215
batch 235 loss: 0.0005576965282671154
batch 240 loss: 0.0005576737923547626
Training Loss: 0.0005576834669530702
Validation Loss: 0.000557693427739044
Epoch 61:
batch 5 loss: 0.0005577911389991641
batch 10 loss: 0.0005576547933742404
batch 15 loss: 0.0005576676339842379
batch 20 loss: 0.0005576828494668007
batch 25 loss: 0.0005578051670454443
batch 30 loss: 0.0005576896597631276
batch 35 loss: 0.000557713012676686
batch 40 loss: 0.0005577001487836242
batch 45 loss: 0.0005576612195000053
batch 50 loss: 0.0005577178439125418
batch 55 loss: 0.000557651068083942
batch 60 loss: 0.0005577215342782438
batch 65 loss: 0.0005576775292865932
batch 70 loss: 0.000557727157138288
batch 75 loss: 0.0005578170297667384
batch 80 loss: 0.0005576469702646136
batch 85 loss: 0.000557729066349566
batch 90 loss: 0.000557708740234375
batch 95 loss: 0.0005576529074460268
batch 100 loss: 0.0005576912080869079
batch 105 loss: 0.0005576649447903038
batch 110 loss: 0.0005577290896326304
batch 115 loss: 0.0005576786701567471
batch 120 loss: 0.0005576122319325804
batch 125 loss: 0.0005577229429036378
batch 130 loss: 0.0005576880881562829
batch 135 loss: 0.0005576227325946092
batch 140 loss: 0.000557701219804585
batch 145 loss: 0.0005576520576141775
batch 150 loss: 0.0005576494731940329
batch 155 loss: 0.0005576790892519057
batch 160 loss: 0.0005577363539487123
batch 165 loss: 0.0005576295545324684
batch 170 loss: 0.0005576911731623113
batch 175 loss: 0.0005578616866841913
batch 180 loss: 0.0005576666677370668
batch 185 loss: 0.0005576323019340634
batch 190 loss: 0.0005576029187068343
batch 195 loss: 0.0005577416392043233
batch 200 loss: 0.0005576901836320758
batch 205 loss: 0.0005576253635808826
batch 210 loss: 0.0005576579133048654
batch 215 loss: 0.0005576254683546722
batch 220 loss: 0.0005575870163738728
batch 225 loss: 0.0005575813469476998
batch 230 loss: 0.000557661394122988
batch 235 loss: 0.0005576926749199628
batch 240 loss: 0.0005576148862019182
Training Loss: 0.0005576834533712827
Validation Loss: 0.0005576935121401524
Epoch 62:
batch 5 loss: 0.0005576484138146043
batch 10 loss: 0.0005576481926254928
batch 15 loss: 0.0005575669812969864
batch 20 loss: 0.0005577087169513107
batch 25 loss: 0.0005576204508543015
batch 30 loss: 0.0005577733740210533
batch 35 loss: 0.0005576780764386058
batch 40 loss: 0.0005576792871579527
batch 45 loss: 0.0005576634779572487
batch 50 loss: 0.0005576200084760786
batch 55 loss: 0.0005577123141847551
batch 60 loss: 0.000557661394122988
batch 65 loss: 0.0005576856667175889
batch 70 loss: 0.0005577085656113922
batch 75 loss: 0.0005575831281021237
batch 80 loss: 0.0005578003590926528
batch 85 loss: 0.0005576939554885029
batch 90 loss: 0.0005576422321610153
batch 95 loss: 0.000557605701033026
batch 100 loss: 0.0005577241303399205
batch 105 loss: 0.0005575995426625013
batch 110 loss: 0.0005576890893280506
batch 115 loss: 0.0005577823030762374
batch 120 loss: 0.0005578184849582612
batch 125 loss: 0.0005576955154538155
batch 130 loss: 0.0005577909061685205
batch 135 loss: 0.0005577293690294027
batch 140 loss: 0.0005577782867476344
batch 145 loss: 0.0005575553514063358
batch 150 loss: 0.0005576086579822004
batch 155 loss: 0.0005575990653596818
batch 160 loss: 0.000557649729307741
batch 165 loss: 0.0005575927090831101
batch 170 loss: 0.0005578443640843033
batch 175 loss: 0.000557721487712115
batch 180 loss: 0.0005576001829467713
batch 185 loss: 0.0005578095442615449
batch 190 loss: 0.0005575870978645981
batch 195 loss: 0.0005576570401899517
batch 200 loss: 0.000557646166998893
batch 205 loss: 0.0005575897987000645
batch 210 loss: 0.0005576850147917866
batch 215 loss: 0.000557741557713598
batch 220 loss: 0.000557679368648678
batch 225 loss: 0.0005577606498263776
batch 230 loss: 0.0005576620227657258
batch 235 loss: 0.0005577303003519773
batch 240 loss: 0.0005577766452915967
Training Loss: 0.000557683430815814
Validation Loss: 0.0005576934743051728
Epoch 63:
batch 5 loss: 0.0005576744209975004
batch 10 loss: 0.0005577136063948274
batch 15 loss: 0.000557711417786777
batch 20 loss: 0.0005576960742473602
batch 25 loss: 0.0005577546427957714
batch 30 loss: 0.0005576750379987061
batch 35 loss: 0.0005575729883275926
batch 40 loss: 0.000557670381385833
batch 45 loss: 0.0005576536408625543
batch 50 loss: 0.0005576422205194831
batch 55 loss: 0.0005576746072620154
batch 60 loss: 0.0005576962372288108
batch 65 loss: 0.0005576656782068312
batch 70 loss: 0.0005576506373472512
batch 75 loss: 0.000557667575776577
batch 80 loss: 0.0005575933028012514
batch 85 loss: 0.0005576168769039214
batch 90 loss: 0.0005576035473495722
batch 95 loss: 0.0005576865631155669
batch 100 loss: 0.0005576190655119717
batch 105 loss: 0.000557749648578465
batch 110 loss: 0.0005576879484578967
batch 115 loss: 0.0005576644674874842
batch 120 loss: 0.0005577523726969958
batch 125 loss: 0.000557803432457149
batch 130 loss: 0.0005576534429565072
batch 135 loss: 0.0005575661198236048
batch 140 loss: 0.000557712628506124
batch 145 loss: 0.0005577998817898333
batch 150 loss: 0.0005576961673796176
batch 155 loss: 0.0005576165742240847
batch 160 loss: 0.0005577948875725269
batch 165 loss: 0.0005575982038863003
batch 170 loss: 0.0005577127682045102
batch 175 loss: 0.0005576801369898022
batch 180 loss: 0.0005577671341598034
batch 185 loss: 0.0005577396834269166
batch 190 loss: 0.0005577193922363221
batch 195 loss: 0.0005576849565841257
batch 200 loss: 0.0005577090545557439
batch 205 loss: 0.0005576374591328203
batch 210 loss: 0.0005577148869633675
batch 215 loss: 0.0005576434195972979
batch 220 loss: 0.0005576789029873907
batch 225 loss: 0.0005576763884164393
batch 230 loss: 0.0005576276453211904
batch 235 loss: 0.000557691534049809
batch 240 loss: 0.0005577875999733806
Training Loss: 0.0005576834429424101
Validation Loss: 0.0005576936023620267
Epoch 64:
batch 5 loss: 0.0005577164003625513
batch 10 loss: 0.0005576480645686388
batch 15 loss: 0.0005576462368480861
batch 20 loss: 0.0005576551659032703
batch 25 loss: 0.0005576267489232123
batch 30 loss: 0.0005577897070907056
batch 35 loss: 0.0005576027440838515
batch 40 loss: 0.0005576995899900794
batch 45 loss: 0.000557745702099055
batch 50 loss: 0.0005575870745815337
batch 55 loss: 0.0005577126983553171
batch 60 loss: 0.0005577379371970892
batch 65 loss: 0.0005578522104769945
batch 70 loss: 0.0005576725699938834
batch 75 loss: 0.0005577092058956623
batch 80 loss: 0.0005576169234700501
batch 85 loss: 0.0005576762720011175
batch 90 loss: 0.0005576237221248448
batch 95 loss: 0.0005576208815909923
batch 100 loss: 0.0005577745847404003
batch 105 loss: 0.0005577685893513262
batch 110 loss: 0.000557744677644223
batch 115 loss: 0.0005576907773502171
batch 120 loss: 0.0005576812196522951
batch 125 loss: 0.0005575650953687728
batch 130 loss: 0.0005577938165515662
batch 135 loss: 0.0005575818940997124
batch 140 loss: 0.0005577446660026908
batch 145 loss: 0.0005576879600994288
batch 150 loss: 0.0005576567607931792
batch 155 loss: 0.000557609717361629
batch 160 loss: 0.0005577746080234647
batch 165 loss: 0.0005576578783802688
batch 170 loss: 0.0005576904397457838
batch 175 loss: 0.0005576232681050897
batch 180 loss: 0.0005577130941674113
batch 185 loss: 0.000557634315919131
batch 190 loss: 0.0005577489850111305
batch 195 loss: 0.0005576725932769477
batch 200 loss: 0.0005576061783358454
batch 205 loss: 0.0005576200783252716
batch 210 loss: 0.000557738950010389
batch 215 loss: 0.0005576799507252872
batch 220 loss: 0.0005576659925282002
batch 225 loss: 0.0005576850497163832
batch 230 loss: 0.0005575795541517437
batch 235 loss: 0.0005577636067755521
batch 240 loss: 0.000557710591237992
Training Loss: 0.0005576834322710056
Validation Loss: 0.0005576934878869603
Epoch 65:
batch 5 loss: 0.0005576803698204458
batch 10 loss: 0.0005576759576797485
batch 15 loss: 0.0005576954106800258
batch 20 loss: 0.0005576988216489554
batch 25 loss: 0.0005576936528086662
batch 30 loss: 0.0005575594026595354
batch 35 loss: 0.0005577370175160468
batch 40 loss: 0.0005576728493906557
batch 45 loss: 0.0005575645016506314
batch 50 loss: 0.0005577751551754772
batch 55 loss: 0.0005577756906859577
batch 60 loss: 0.000557728495914489
batch 65 loss: 0.0005577220697887241
batch 70 loss: 0.0005578403710387647
batch 75 loss: 0.00055762775009498
batch 80 loss: 0.000557737541384995
batch 85 loss: 0.0005576437921263278
batch 90 loss: 0.000557688728440553
batch 95 loss: 0.0005577221512794494
batch 100 loss: 0.0005576470750384033
batch 105 loss: 0.0005575773655436933
batch 110 loss: 0.0005575390183366835
batch 115 loss: 0.0005576141993515193
batch 120 loss: 0.00055767911253497
batch 125 loss: 0.000557738111820072
batch 130 loss: 0.0005576686933636665
batch 135 loss: 0.000557688344269991
batch 140 loss: 0.0005575730232521891
batch 145 loss: 0.0005576601601205766
batch 150 loss: 0.0005576956784352661
batch 155 loss: 0.0005576665396802127
batch 160 loss: 0.0005577842006459832
batch 165 loss: 0.0005576847004704177
batch 170 loss: 0.0005576502881012857
batch 175 loss: 0.0005576166789978742
batch 180 loss: 0.000557732512243092
batch 185 loss: 0.0005576958181336522
batch 190 loss: 0.0005577601958066225
batch 195 loss: 0.0005576386000029742
batch 200 loss: 0.0005576306371949613
batch 205 loss: 0.0005578013020567596
batch 210 loss: 0.000557821081019938
batch 215 loss: 0.0005577182048000396
batch 220 loss: 0.0005576033028773964
batch 225 loss: 0.0005575913935899734
batch 230 loss: 0.0005577513366006315
batch 235 loss: 0.0005576692870818079
batch 240 loss: 0.0005576697178184987
Training Loss: 0.0005576834647702829
Validation Loss: 0.0005576937071358164
Epoch 66:
batch 5 loss: 0.0005576122086495161
batch 10 loss: 0.0005577666452154517
batch 15 loss: 0.0005576673545874655
batch 20 loss: 0.0005577141186222434
batch 25 loss: 0.0005576748517341912
batch 30 loss: 0.0005577670992352069
batch 35 loss: 0.0005576452822424471
batch 40 loss: 0.0005577147821895778
batch 45 loss: 0.0005576533148996532
batch 50 loss: 0.0005576628143899142
batch 55 loss: 0.0005577563075348735
batch 60 loss: 0.0005576627445407212
batch 65 loss: 0.0005576438503339887
batch 70 loss: 0.000557740149088204
batch 75 loss: 0.0005575489485636353
batch 80 loss: 0.0005577004398219287
batch 85 loss: 0.0005576648865826428
batch 90 loss: 0.0005577131872996688
batch 95 loss: 0.0005577812320552766
batch 100 loss: 0.0005578188574872911
batch 105 loss: 0.0005575835471972823
batch 110 loss: 0.0005576571333222091
batch 115 loss: 0.0005576995201408864
batch 120 loss: 0.0005575992166996002
batch 125 loss: 0.0005575231276452542
batch 130 loss: 0.0005577136878855526
batch 135 loss: 0.0005576840019784867
batch 140 loss: 0.000557628960814327
batch 145 loss: 0.0005576642579399049
batch 150 loss: 0.0005576770170591771
batch 155 loss: 0.0005577704287134111
batch 160 loss: 0.0005577041651122272
batch 165 loss: 0.0005577675998210907
batch 170 loss: 0.0005576091818511486
batch 175 loss: 0.0005576301598921418
batch 180 loss: 0.000557668274268508
batch 185 loss: 0.0005576630006544292
batch 190 loss: 0.000557674013543874
batch 195 loss: 0.0005577921168878674
batch 200 loss: 0.0005576028255745768
batch 205 loss: 0.0005577275180257857
batch 210 loss: 0.0005577689968049526
batch 215 loss: 0.0005576739902608096
batch 220 loss: 0.0005576591938734055
batch 225 loss: 0.0005577592295594513
batch 230 loss: 0.0005576745490543545
batch 235 loss: 0.0005576112656854093
batch 240 loss: 0.0005577093572355807
Training Loss: 0.0005576834460953251
Validation Loss: 0.000557693622734708
Epoch 67:
batch 5 loss: 0.0005575536051765084
batch 10 loss: 0.0005576317198574543
batch 15 loss: 0.0005577299045398832
batch 20 loss: 0.0005576789262704551
batch 25 loss: 0.0005577513133175671
batch 30 loss: 0.0005576714989729226
batch 35 loss: 0.0005576497758738696
batch 40 loss: 0.0005576001945883036
batch 45 loss: 0.0005578139564022422
batch 50 loss: 0.000557563395705074
batch 55 loss: 0.0005579215358011425
batch 60 loss: 0.000557672290597111
batch 65 loss: 0.000557645270600915
batch 70 loss: 0.0005577007541432977
batch 75 loss: 0.0005577488336712122
batch 80 loss: 0.0005575485061854124
batch 85 loss: 0.0005577348289079964
batch 90 loss: 0.0005577506613917649
batch 95 loss: 0.0005576055846177042
batch 100 loss: 0.0005576329538598656
batch 105 loss: 0.0005577117321081459
batch 110 loss: 0.0005577229661867022
batch 115 loss: 0.0005577448522672057
batch 120 loss: 0.0005577078904025256
batch 125 loss: 0.0005577211733907462
batch 130 loss: 0.0005576531402766705
batch 135 loss: 0.0005577800679020583
batch 140 loss: 0.0005577252712100744
batch 145 loss: 0.0005577624309808016
batch 150 loss: 0.0005576515453867614
batch 155 loss: 0.0005577284377068281
batch 160 loss: 0.0005576072842814028
batch 165 loss: 0.0005575455958023668
batch 170 loss: 0.0005577634903602303
batch 175 loss: 0.0005576096009463072
batch 180 loss: 0.0005576969124376774
batch 185 loss: 0.0005575856659561396
batch 190 loss: 0.0005576725816354156
batch 195 loss: 0.0005577479721978306
batch 200 loss: 0.0005576391704380512
batch 205 loss: 0.0005576347350142897
batch 210 loss: 0.0005576474708504975
batch 215 loss: 0.0005576762137934566
batch 220 loss: 0.0005576524650678039
batch 225 loss: 0.0005576591473072767
batch 230 loss: 0.0005576739204116166
batch 235 loss: 0.0005577875999733806
batch 240 loss: 0.000557690067216754
Training Loss: 0.0005576834356664525
Validation Loss: 0.0005576934296792994
Epoch 68:
batch 5 loss: 0.0005576145718805492
batch 10 loss: 0.0005576843279413879
batch 15 loss: 0.0005577622796408832
batch 20 loss: 0.0005576190771535039
batch 25 loss: 0.0005576946423389018
batch 30 loss: 0.0005577531992457807
batch 35 loss: 0.0005576231982558965
batch 40 loss: 0.0005576633382588625
batch 45 loss: 0.0005577418371103704
batch 50 loss: 0.0005576618481427431
batch 55 loss: 0.0005576496827416122
batch 60 loss: 0.0005576582509092987
batch 65 loss: 0.000557618378661573
batch 70 loss: 0.0005577381467446685
batch 75 loss: 0.0005577148869633675
batch 80 loss: 0.0005576589843258262
batch 85 loss: 0.0005576884024776519
batch 90 loss: 0.0005576653522439301
batch 95 loss: 0.0005576874129474163
batch 100 loss: 0.0005576556548476219
batch 105 loss: 0.0005577478208579123
batch 110 loss: 0.0005577385774813593
batch 115 loss: 0.0005577018251642585
batch 120 loss: 0.0005576580530032516
batch 125 loss: 0.0005577134666964412
batch 130 loss: 0.0005576671566814185
batch 135 loss: 0.000557780486997217
batch 140 loss: 0.0005577422096394002
batch 145 loss: 0.0005576149444095791
batch 150 loss: 0.0005576183553785086
batch 155 loss: 0.0005576510564424097
batch 160 loss: 0.0005578673793934285
batch 165 loss: 0.0005576343857683242
batch 170 loss: 0.0005577007541432977
batch 175 loss: 0.0005577247706241905
batch 180 loss: 0.000557772780302912
batch 185 loss: 0.0005577055737376214
batch 190 loss: 0.0005577228730544448
batch 195 loss: 0.0005576784373261034
batch 200 loss: 0.0005575729301199317
batch 205 loss: 0.0005576303694397212
batch 210 loss: 0.0005576692754402756
batch 215 loss: 0.0005575662944465876
batch 220 loss: 0.0005576458759605884
batch 225 loss: 0.0005577370873652398
batch 230 loss: 0.000557710719294846
batch 235 loss: 0.0005576388677582145
batch 240 loss: 0.0005576388095505536
Training Loss: 0.0005576834293606226
Validation Loss: 0.0005576934287091717
Epoch 69:
batch 5 loss: 0.0005577322677709162
batch 10 loss: 0.0005576370866037905
batch 15 loss: 0.0005577521631494164
batch 20 loss: 0.0005577041418291628
batch 25 loss: 0.0005576362600550056
batch 30 loss: 0.000557648774702102
batch 35 loss: 0.0005576316150836646
batch 40 loss: 0.000557599717285484
batch 45 loss: 0.0005577373784035444
batch 50 loss: 0.000557736458722502
batch 55 loss: 0.000557655340526253
batch 60 loss: 0.0005577459349296987
batch 65 loss: 0.0005577375879511238
batch 70 loss: 0.0005576782277785242
batch 75 loss: 0.0005576076684519649
batch 80 loss: 0.0005577131872996688
batch 85 loss: 0.00055782082490623
batch 90 loss: 0.0005577768431976437
batch 95 loss: 0.0005576899624429643
batch 100 loss: 0.0005576155614107847
batch 105 loss: 0.0005577109986916184
batch 110 loss: 0.0005577193573117256
batch 115 loss: 0.0005577553762122989
batch 120 loss: 0.000557644315995276
batch 125 loss: 0.0005575987277552485
batch 130 loss: 0.0005577828851528466
batch 135 loss: 0.0005576101480983198
batch 140 loss: 0.0005577222560532391
batch 145 loss: 0.0005575889255851508
batch 150 loss: 0.0005576786119490862
batch 155 loss: 0.0005577209289185703
batch 160 loss: 0.0005576009978540241
batch 165 loss: 0.0005576653755269944
batch 170 loss: 0.0005576646537519992
batch 175 loss: 0.0005577100091613829
batch 180 loss: 0.0005576024181209504
batch 185 loss: 0.0005576066323556006
batch 190 loss: 0.0005576636525802314
batch 195 loss: 0.0005576969939284027
batch 200 loss: 0.0005577942007221282
batch 205 loss: 0.0005576457479037344
batch 210 loss: 0.0005576186929829418
batch 215 loss: 0.0005576029419898987
batch 220 loss: 0.0005577142233960331
batch 225 loss: 0.0005577324773184955
batch 230 loss: 0.0005577079718932509
batch 235 loss: 0.000557674327865243
batch 240 loss: 0.000557713396847248
Training Loss: 0.000557683421842133
Validation Loss: 0.0005576934296792994
Epoch 70:
batch 5 loss: 0.0005576907889917493
batch 10 loss: 0.0005577462841756641
batch 15 loss: 0.0005578286130912602
batch 20 loss: 0.0005575962830334901
batch 25 loss: 0.0005576924537308514
batch 30 loss: 0.0005577368661761284
batch 35 loss: 0.0005577370058745146
batch 40 loss: 0.0005576800322160125
batch 45 loss: 0.0005576478666625917
batch 50 loss: 0.0005577018018811941
batch 55 loss: 0.000557661836501211
batch 60 loss: 0.0005577059928327799
batch 65 loss: 0.0005576409050263465
batch 70 loss: 0.0005577254109084606
batch 75 loss: 0.0005577479721978306
batch 80 loss: 0.0005577365634962916
batch 85 loss: 0.0005577719071879983
batch 90 loss: 0.0005577406613156199
batch 95 loss: 0.0005575679708272219
batch 100 loss: 0.0005577655392698944
batch 105 loss: 0.0005577218369580805
batch 110 loss: 0.0005576534196734429
batch 115 loss: 0.0005577228032052517
batch 120 loss: 0.0005576010327786208
batch 125 loss: 0.0005576948635280133
batch 130 loss: 0.0005577758536674082
batch 135 loss: 0.0005575469462200999
batch 140 loss: 0.000557738309726119
batch 145 loss: 0.0005577335832640529
batch 150 loss: 0.0005575818242505193
batch 155 loss: 0.0005576492170803249
batch 160 loss: 0.0005576091585680843
batch 165 loss: 0.0005576599854975939
batch 170 loss: 0.0005576492403633893
batch 175 loss: 0.0005576718016527593
batch 180 loss: 0.0005576189607381821
batch 185 loss: 0.0005578127806074917
batch 190 loss: 0.0005576396943069994
batch 195 loss: 0.000557669484987855
batch 200 loss: 0.0005576805677264928
batch 205 loss: 0.0005577336531132459
batch 210 loss: 0.0005577394622378051
batch 215 loss: 0.0005576652707532048
batch 220 loss: 0.0005576038849540055
batch 225 loss: 0.0005576387629844248
batch 230 loss: 0.0005575739429332316
batch 235 loss: 0.0005576440715231001
batch 240 loss: 0.0005576508468948304
Training Loss: 0.0005576834169914946
Validation Loss: 0.0005576933986352135
Epoch 71:
batch 5 loss: 0.0005575483664870262
batch 10 loss: 0.0005577498232014477
batch 15 loss: 0.0005577099625952541
batch 20 loss: 0.0005576567491516471
batch 25 loss: 0.0005576489842496812
batch 30 loss: 0.0005576156196184457
batch 35 loss: 0.0005577251431532204
batch 40 loss: 0.0005575864692218601
batch 45 loss: 0.0005577142001129687
batch 50 loss: 0.0005576608120463789
batch 55 loss: 0.0005576782976277172
batch 60 loss: 0.0005577081581577658
batch 65 loss: 0.0005576853989623487
batch 70 loss: 0.0005576881463639438
batch 75 loss: 0.0005577188334427774
batch 80 loss: 0.0005576367722824216
batch 85 loss: 0.0005578126641921699
batch 90 loss: 0.0005576711962930858
batch 95 loss: 0.0005576550378464162
batch 100 loss: 0.0005575629533268511
batch 105 loss: 0.0005576100549660624
batch 110 loss: 0.0005576770170591771
batch 115 loss: 0.0005577797652222216
batch 120 loss: 0.0005576984491199255
batch 125 loss: 0.0005574894370511174
batch 130 loss: 0.00055774130159989
batch 135 loss: 0.0005576536990702152
batch 140 loss: 0.0005576812895014882
batch 145 loss: 0.000557789218146354
batch 150 loss: 0.0005577089148573577
batch 155 loss: 0.0005576370167545974
batch 160 loss: 0.0005577384843491017
batch 165 loss: 0.0005577485426329076
batch 170 loss: 0.000557744549587369
batch 175 loss: 0.0005577193340286612
batch 180 loss: 0.0005577539326623082
batch 185 loss: 0.0005577437579631806
batch 190 loss: 0.0005576498806476593
batch 195 loss: 0.0005577867035754025
batch 200 loss: 0.0005577495670877397
batch 205 loss: 0.0005576493800617755
batch 210 loss: 0.0005577021162025631
batch 215 loss: 0.0005576344323344528
batch 220 loss: 0.0005577315809205174
batch 225 loss: 0.0005576660973019898
batch 230 loss: 0.0005576828727498651
batch 235 loss: 0.0005576416733674705
batch 240 loss: 0.0005575605668127537
Training Loss: 0.000557683400499324
Validation Loss: 0.0005576934063962351
Epoch 72:
batch 5 loss: 0.0005576460971496999
batch 10 loss: 0.0005576225812546909
batch 15 loss: 0.0005577218835242093
batch 20 loss: 0.0005576828727498651
batch 25 loss: 0.000557662092614919
batch 30 loss: 0.000557780615054071
batch 35 loss: 0.0005578388227149844
batch 40 loss: 0.0005576941883191466
batch 45 loss: 0.0005576638970524073
batch 50 loss: 0.0005578495794907213
batch 55 loss: 0.0005577343166805804
batch 60 loss: 0.0005576696945354343
batch 65 loss: 0.0005577960982918739
batch 70 loss: 0.0005577048752456904
batch 75 loss: 0.0005576294264756143
batch 80 loss: 0.0005576707422733307
batch 85 loss: 0.0005576483905315399
batch 90 loss: 0.0005577145144343376
batch 95 loss: 0.0005576545023359359
batch 100 loss: 0.0005576133728027344
batch 105 loss: 0.000557641324121505
batch 110 loss: 0.0005576718482188881
batch 115 loss: 0.0005576351075433194
batch 120 loss: 0.0005576892290264368
batch 125 loss: 0.0005576823838055134
batch 130 loss: 0.0005577510106377304
batch 135 loss: 0.0005577230243943631
batch 140 loss: 0.000557698484044522
batch 145 loss: 0.0005576956784352661
batch 150 loss: 0.0005577359348535538
batch 155 loss: 0.0005576750030741095
batch 160 loss: 0.0005575279821641744
batch 165 loss: 0.000557578110601753
batch 170 loss: 0.0005577341420575976
batch 175 loss: 0.0005577336763963103
batch 180 loss: 0.0005577561911195517
batch 185 loss: 0.0005576290539465844
batch 190 loss: 0.0005576976342126727
batch 195 loss: 0.0005576662137173116
batch 200 loss: 0.0005577225354500114
batch 205 loss: 0.000557597540318966
batch 210 loss: 0.0005576036288402975
batch 215 loss: 0.0005576175404712558
batch 220 loss: 0.0005577529780566692
batch 225 loss: 0.0005576441762968898
batch 230 loss: 0.0005576827796176076
batch 235 loss: 0.0005576402065344155
batch 240 loss: 0.0005576221039518714
Training Loss: 0.0005576834184466862
Validation Loss: 0.0005576934112468734
Epoch 73:
batch 5 loss: 0.0005576276453211904
batch 10 loss: 0.0005576012772507966
batch 15 loss: 0.0005576119176112116
batch 20 loss: 0.0005576323019340634
batch 25 loss: 0.000557630171533674
batch 30 loss: 0.000557725818362087
batch 35 loss: 0.0005576763302087784
batch 40 loss: 0.0005577966454438865
batch 45 loss: 0.0005577078205533326
batch 50 loss: 0.0005575995892286301
batch 55 loss: 0.0005577127332799137
batch 60 loss: 0.0005576489493250847
batch 65 loss: 0.0005577181698754429
batch 70 loss: 0.0005577165982685983
batch 75 loss: 0.0005577390897087753
batch 80 loss: 0.0005577855161391198
batch 85 loss: 0.0005576035473495722
batch 90 loss: 0.000557596841827035
batch 95 loss: 0.0005576590425334871
batch 100 loss: 0.0005577476229518652
batch 105 loss: 0.0005577369476668537
batch 110 loss: 0.0005577276810072362
batch 115 loss: 0.0005577574716880918
batch 120 loss: 0.0005577267264015972
batch 125 loss: 0.0005575684714131057
batch 130 loss: 0.0005576665629632771
batch 135 loss: 0.000557683827355504
batch 140 loss: 0.0005576649913564324
batch 145 loss: 0.0005577784148044884
batch 150 loss: 0.0005576937575824559
batch 155 loss: 0.0005577956093475222
batch 160 loss: 0.0005577078205533326
batch 165 loss: 0.000557788903824985
batch 170 loss: 0.0005578016047365963
batch 175 loss: 0.0005577184958383441
batch 180 loss: 0.0005576688679866492
batch 185 loss: 0.0005575577844865621
batch 190 loss: 0.0005576761090196669
batch 195 loss: 0.000557648774702102
batch 200 loss: 0.0005576973082497716
batch 205 loss: 0.0005576717318035662
batch 210 loss: 0.0005577008007094264
batch 215 loss: 0.0005575831164605916
batch 220 loss: 0.000557626283261925
batch 225 loss: 0.0005576261202804745
batch 230 loss: 0.0005576400551944971
batch 235 loss: 0.0005576547584496439
batch 240 loss: 0.0005576982162892819
Training Loss: 0.0005576834342112609
Validation Loss: 0.0005576934840064496
Epoch 74:
batch 5 loss: 0.0005575545597821474
batch 10 loss: 0.000557752640452236
batch 15 loss: 0.0005577162723056972
batch 20 loss: 0.0005577185074798763
batch 25 loss: 0.0005577537580393255
batch 30 loss: 0.0005576586001552642
batch 35 loss: 0.0005577737465500832
batch 40 loss: 0.0005575710209086537
batch 45 loss: 0.0005576273426413537
batch 50 loss: 0.0005576280993409455
batch 55 loss: 0.0005576377385295928
batch 60 loss: 0.0005576709168963135
batch 65 loss: 0.0005576194846071303
batch 70 loss: 0.0005576192983426153
batch 75 loss: 0.0005578365293331444
batch 80 loss: 0.0005576056661084295
batch 85 loss: 0.0005577451316639781
batch 90 loss: 0.0005577008239924907
batch 95 loss: 0.0005577097064815462
batch 100 loss: 0.0005577039439231158
batch 105 loss: 0.0005577765987254679
batch 110 loss: 0.0005576698109507561
batch 115 loss: 0.0005578143987804651
batch 120 loss: 0.0005576478084549308
batch 125 loss: 0.0005577371222898365
batch 130 loss: 0.0005575877497904002
batch 135 loss: 0.0005577516974881291
batch 140 loss: 0.0005576884606853128
batch 145 loss: 0.0005577037460170686
batch 150 loss: 0.000557597482111305
batch 155 loss: 0.0005576890660449862
batch 160 loss: 0.0005577573319897056
batch 165 loss: 0.0005576600669883192
batch 170 loss: 0.0005576305207796395
batch 175 loss: 0.0005577339907176793
batch 180 loss: 0.0005577127682045102
batch 185 loss: 0.0005576597643084825
batch 190 loss: 0.0005575973074883223
batch 195 loss: 0.0005576797178946435
batch 200 loss: 0.0005576030118390918
batch 205 loss: 0.0005577195202931762
batch 210 loss: 0.0005577421979978681
batch 215 loss: 0.0005576132796704769
batch 220 loss: 0.0005576234194450081
batch 225 loss: 0.0005577233619987965
batch 230 loss: 0.0005577590898610651
batch 235 loss: 0.0005576772382482886
batch 240 loss: 0.0005576437804847955
Training Loss: 0.0005576834186892181
Validation Loss: 0.0005576934054261073
Epoch 75:
batch 5 loss: 0.0005578184500336647
batch 10 loss: 0.000557615701109171
batch 15 loss: 0.0005576727446168662
batch 20 loss: 0.0005576418247073889
batch 25 loss: 0.0005577618954703212
batch 30 loss: 0.0005577298696152865
batch 35 loss: 0.0005575837218202651
batch 40 loss: 0.0005578210577368737
batch 45 loss: 0.0005576924071647227
batch 50 loss: 0.0005576825933530927
batch 55 loss: 0.0005576370400376618
batch 60 loss: 0.0005576618132181466
batch 65 loss: 0.0005577086354605854
batch 70 loss: 0.0005577405565418303
batch 75 loss: 0.0005576584022492171
batch 80 loss: 0.0005577338277362287
batch 85 loss: 0.0005576171795837581
batch 90 loss: 0.0005576464463956654
batch 95 loss: 0.0005577476578764618
batch 100 loss: 0.0005576483090408146
batch 105 loss: 0.0005577025236561895
batch 110 loss: 0.0005576198571361601
batch 115 loss: 0.0005576983559876681
batch 120 loss: 0.0005576287629082799
batch 125 loss: 0.0005577191826887429
batch 130 loss: 0.0005576293100602925
batch 135 loss: 0.0005577495903708041
batch 140 loss: 0.0005577219999395311
batch 145 loss: 0.0005577603471465409
batch 150 loss: 0.0005576369818300009
batch 155 loss: 0.0005576555035077035
batch 160 loss: 0.000557726074475795
batch 165 loss: 0.0005577893811278045
batch 170 loss: 0.0005576502415351569
batch 175 loss: 0.0005577575415372848
batch 180 loss: 0.0005576667957939207
batch 185 loss: 0.0005577222793363035
batch 190 loss: 0.0005577535601332783
batch 195 loss: 0.000557574164122343
batch 200 loss: 0.0005575918359681964
batch 205 loss: 0.0005576029536314309
batch 210 loss: 0.0005576627561822533
batch 215 loss: 0.0005577187985181808
batch 220 loss: 0.0005576481111347675
batch 225 loss: 0.0005576178897172213
batch 230 loss: 0.0005575868301093579
batch 235 loss: 0.0005577169824391604
batch 240 loss: 0.0005576749332249165
Training Loss: 0.0005576834099580689
Validation Loss: 0.000557693449081853
Epoch 76:
batch 5 loss: 0.0005576742347329855
batch 10 loss: 0.0005576153984293341
batch 15 loss: 0.0005576895549893379
batch 20 loss: 0.0005576067138463259
batch 25 loss: 0.0005576739553362131
batch 30 loss: 0.0005576573428697884
batch 35 loss: 0.0005576973082497716
batch 40 loss: 0.0005577557021752
batch 45 loss: 0.0005577115807682276
batch 50 loss: 0.0005576761206611991
batch 55 loss: 0.000557654700241983
batch 60 loss: 0.0005577109288424254
batch 65 loss: 0.0005577777163125574
batch 70 loss: 0.0005576996016316115
batch 75 loss: 0.0005575605668127537
batch 80 loss: 0.0005577505682595075
batch 85 loss: 0.0005577001138590276
batch 90 loss: 0.0005576864583417773
batch 95 loss: 0.0005576101946644485
batch 100 loss: 0.0005576049559749662
batch 105 loss: 0.000557571358513087
batch 110 loss: 0.0005576756200753152
batch 115 loss: 0.0005577316856943071
batch 120 loss: 0.0005576327908784151
batch 125 loss: 0.0005577609408646822
batch 130 loss: 0.0005576651077717542
batch 135 loss: 0.0005577578325755894
batch 140 loss: 0.0005577438627369702
batch 145 loss: 0.0005577112548053265
batch 150 loss: 0.0005576899158768356
batch 155 loss: 0.0005577010684646666
batch 160 loss: 0.000557704537641257
batch 165 loss: 0.0005577080999501049
batch 170 loss: 0.0005576619761995972
batch 175 loss: 0.0005576984025537967
batch 180 loss: 0.0005577407311648131
batch 185 loss: 0.0005576883559115231
batch 190 loss: 0.000557669170666486
batch 195 loss: 0.0005576815805397928
batch 200 loss: 0.0005576010909862817
batch 205 loss: 0.0005576740368269384
batch 210 loss: 0.0005578243522904814
batch 215 loss: 0.0005576270283199847
batch 220 loss: 0.0005576542927883566
batch 225 loss: 0.0005576354800723493
batch 230 loss: 0.0005576776224188506
batch 235 loss: 0.0005576985306106508
batch 240 loss: 0.0005577031173743307
Training Loss: 0.0005576834075327497
Validation Loss: 0.0005576934393805762
Epoch 77:
batch 5 loss: 0.0005575610557571054
batch 10 loss: 0.0005577512085437775
batch 15 loss: 0.0005575572606176138
batch 20 loss: 0.000557724095415324
batch 25 loss: 0.0005576570401899517
batch 30 loss: 0.0005575887393206358
batch 35 loss: 0.0005577451549470425
batch 40 loss: 0.0005576033610850573
batch 45 loss: 0.0005577150965109468
batch 50 loss: 0.0005577183677814901
batch 55 loss: 0.0005576363881118595
batch 60 loss: 0.0005577552015893162
batch 65 loss: 0.0005576552473939955
batch 70 loss: 0.0005577978910878301
batch 75 loss: 0.0005577986012212932
batch 80 loss: 0.0005576727562583983
batch 85 loss: 0.0005576584837399424
batch 90 loss: 0.00055771121988073
batch 95 loss: 0.0005576525698415935
batch 100 loss: 0.0005577637581154704
batch 105 loss: 0.000557712058071047
batch 110 loss: 0.0005577567033469677
batch 115 loss: 0.000557591556571424
batch 120 loss: 0.0005577178089879453
batch 125 loss: 0.0005576104624196887
batch 130 loss: 0.000557696248870343
batch 135 loss: 0.0005578199401497841
batch 140 loss: 0.0005576211493462324
batch 145 loss: 0.0005576156661845743
batch 150 loss: 0.000557708996348083
batch 155 loss: 0.0005577733740210533
batch 160 loss: 0.0005576627678237856
batch 165 loss: 0.0005576592870056629
batch 170 loss: 0.0005576575989834964
batch 175 loss: 0.0005576903000473976
batch 180 loss: 0.0005577593459747731
batch 185 loss: 0.0005575906368903815
batch 190 loss: 0.0005576633266173303
batch 195 loss: 0.0005577158182859421
batch 200 loss: 0.0005576720228418708
batch 205 loss: 0.0005577802890911699
batch 210 loss: 0.0005577218835242093
batch 215 loss: 0.000557546503841877
batch 220 loss: 0.0005576314870268106
batch 225 loss: 0.0005575969815254211
batch 230 loss: 0.0005576829658821225
batch 235 loss: 0.0005576386582106351
batch 240 loss: 0.0005577859352342785
Training Loss: 0.0005576834014694517
Validation Loss: 0.0005576934083364904
Epoch 78:
batch 5 loss: 0.0005576544208452106
batch 10 loss: 0.0005577201955020428
batch 15 loss: 0.0005576384370215237
batch 20 loss: 0.0005576070863753558
batch 25 loss: 0.0005576543509960175
batch 30 loss: 0.0005577538977377117
batch 35 loss: 0.0005575645482167602
batch 40 loss: 0.0005576655268669129
batch 45 loss: 0.0005577811738476157
batch 50 loss: 0.0005577025702223181
batch 55 loss: 0.000557716959156096
batch 60 loss: 0.000557722698431462
batch 65 loss: 0.0005577411968261004
batch 70 loss: 0.0005577156320214271
batch 75 loss: 0.0005576356197707355
batch 80 loss: 0.0005577498464845121
batch 85 loss: 0.0005576647236011922
batch 90 loss: 0.0005575964460149407
batch 95 loss: 0.0005576680414378643
batch 100 loss: 0.0005576958879828453
batch 105 loss: 0.0005576551076956094
batch 110 loss: 0.0005577163537964225
batch 115 loss: 0.0005577506497502327
batch 120 loss: 0.0005577155854552985
batch 125 loss: 0.0005577542237006128
batch 130 loss: 0.000557765702251345
batch 135 loss: 0.0005576483905315399
batch 140 loss: 0.0005577066564001143
batch 145 loss: 0.0005576961440965534
batch 150 loss: 0.0005576437339186669
batch 155 loss: 0.0005576710449531674
batch 160 loss: 0.0005576549214310944
batch 165 loss: 0.0005576021387241781
batch 170 loss: 0.0005576888564974069
batch 175 loss: 0.0005576940719038248
batch 180 loss: 0.0005575591116212308
batch 185 loss: 0.0005576826049946248
batch 190 loss: 0.0005576047347858548
batch 195 loss: 0.0005575375515036284
batch 200 loss: 0.0005578242940828204
batch 205 loss: 0.0005576616385951638
batch 210 loss: 0.0005577006028033793
batch 215 loss: 0.0005576439201831817
batch 220 loss: 0.0005577404284849763
batch 225 loss: 0.0005576886469498277
batch 230 loss: 0.0005577263422310352
batch 235 loss: 0.0005577109637670219
batch 240 loss: 0.0005577095202170312
Training Loss: 0.0005576834000142601
Validation Loss: 0.0005576935082596417
Epoch 79:
batch 5 loss: 0.0005576462484896183
batch 10 loss: 0.0005577455391176045
batch 15 loss: 0.000557674583978951
batch 20 loss: 0.0005576075054705143
batch 25 loss: 0.0005576765979640186
batch 30 loss: 0.0005577251315116883
batch 35 loss: 0.000557673699222505
batch 40 loss: 0.0005575911374762655
batch 45 loss: 0.0005577288684435189
batch 50 loss: 0.0005576253752224147
batch 55 loss: 0.0005577113362960518
batch 60 loss: 0.0005576859228312969
batch 65 loss: 0.0005577140138484538
batch 70 loss: 0.0005577184958383441
batch 75 loss: 0.0005577390198595822
batch 80 loss: 0.0005577041301876307
batch 85 loss: 0.0005576942232437432
batch 90 loss: 0.0005577009753324092
batch 95 loss: 0.0005577158648520708
batch 100 loss: 0.0005576681112870574
batch 105 loss: 0.0005575731280259788
batch 110 loss: 0.0005576391355134547
batch 115 loss: 0.0005577749107033014
batch 120 loss: 0.0005578000796958804
batch 125 loss: 0.0005577057949267328
batch 130 loss: 0.0005576900322921575
batch 135 loss: 0.0005576517432928085
batch 140 loss: 0.0005577255971729756
batch 145 loss: 0.0005577913834713399
batch 150 loss: 0.0005576692870818079
batch 155 loss: 0.0005577032803557813
batch 160 loss: 0.000557726772967726
batch 165 loss: 0.0005576659808866679
batch 170 loss: 0.000557666877284646
batch 175 loss: 0.0005576990311965347
batch 180 loss: 0.000557586457580328
batch 185 loss: 0.0005577093921601773
batch 190 loss: 0.0005577198346145452
batch 195 loss: 0.0005577915580943227
batch 200 loss: 0.0005576694151386618
batch 205 loss: 0.0005575961084105074
batch 210 loss: 0.0005576416500844061
batch 215 loss: 0.0005576597061008215
batch 220 loss: 0.0005576126161031425
batch 225 loss: 0.0005576862604357302
batch 230 loss: 0.0005575788556598127
batch 235 loss: 0.0005576730822212994
batch 240 loss: 0.0005576486815698445
Training Loss: 0.0005576834048648986
Validation Loss: 0.0005576934112468734
Epoch 80:
batch 5 loss: 0.0005576510564424097
batch 10 loss: 0.000557742128148675
batch 15 loss: 0.0005576010677032173
batch 20 loss: 0.0005576308118179441
batch 25 loss: 0.0005576443974860013
batch 30 loss: 0.0005575982620939612
batch 35 loss: 0.0005577102769166231
batch 40 loss: 0.0005576317547820508
batch 45 loss: 0.0005576918483711779
batch 50 loss: 0.0005576890893280506
batch 55 loss: 0.0005577420350164175
batch 60 loss: 0.0005578547017648817
batch 65 loss: 0.0005577960750088095
batch 70 loss: 0.0005576755502261221
batch 75 loss: 0.0005577040137723088
batch 80 loss: 0.0005576130119152367
batch 85 loss: 0.0005576428724452853
batch 90 loss: 0.0005576714058406651
batch 95 loss: 0.0005577711970545351
batch 100 loss: 0.0005577125237323343
batch 105 loss: 0.0005576855037361383
batch 110 loss: 0.0005576224531978369
batch 115 loss: 0.0005575427552685141
batch 120 loss: 0.0005578277166932821
batch 125 loss: 0.0005578049225732684
batch 130 loss: 0.000557639286853373
batch 135 loss: 0.0005576387164182961
batch 140 loss: 0.0005577191477641463
batch 145 loss: 0.0005577338044531644
batch 150 loss: 0.0005577209289185703
batch 155 loss: 0.0005576045485213398
batch 160 loss: 0.0005577364470809698
batch 165 loss: 0.0005575842689722777
batch 170 loss: 0.0005577501375228167
batch 175 loss: 0.0005576665746048093
batch 180 loss: 0.0005576679133810103
batch 185 loss: 0.0005575550487264991
batch 190 loss: 0.0005577589152380824
batch 195 loss: 0.0005576681345701217
batch 200 loss: 0.0005577554809860885
batch 205 loss: 0.000557694782037288
batch 210 loss: 0.0005576611845754087
batch 215 loss: 0.0005576392519287765
batch 220 loss: 0.0005576890660449862
batch 225 loss: 0.0005576744442805648
batch 230 loss: 0.0005576922092586755
batch 235 loss: 0.000557652476709336
batch 240 loss: 0.0005576426745392382
Training Loss: 0.0005576833932233664
Validation Loss: 0.0005576934442312146
Epoch 81:
batch 5 loss: 0.000557623547501862
batch 10 loss: 0.0005577452480793
batch 15 loss: 0.0005577514297328889
batch 20 loss: 0.0005575640476308763
batch 25 loss: 0.0005576316732913255
batch 30 loss: 0.0005577404517680407
batch 35 loss: 0.0005576828378252685
batch 40 loss: 0.0005577226867899299
batch 45 loss: 0.0005578016862273216
batch 50 loss: 0.0005576148862019182
batch 55 loss: 0.0005577061325311661
batch 60 loss: 0.000557767238933593
batch 65 loss: 0.0005575637798756361
batch 70 loss: 0.0005575893330387772
batch 75 loss: 0.0005576979601755738
batch 80 loss: 0.0005576810450293124
batch 85 loss: 0.0005577300558798015
batch 90 loss: 0.000557743851095438
batch 95 loss: 0.0005577350035309792
batch 100 loss: 0.0005577240255661309
batch 105 loss: 0.0005575929302722215
batch 110 loss: 0.0005576533148996532
batch 115 loss: 0.0005576936411671341
batch 120 loss: 0.0005578047363087535
batch 125 loss: 0.0005576633266173303
batch 130 loss: 0.0005577131407335401
batch 135 loss: 0.0005576224648393691
batch 140 loss: 0.0005576203810051083
batch 145 loss: 0.0005576652474701405
batch 150 loss: 0.0005577460629865527
batch 155 loss: 0.0005577890085987746
batch 160 loss: 0.0005577799980528653
batch 165 loss: 0.0005577000323683023
batch 170 loss: 0.0005576245253905654
batch 175 loss: 0.0005577561561949552
batch 180 loss: 0.0005575887858867645
batch 185 loss: 0.0005576918949373067
batch 190 loss: 0.0005576176103204489
batch 195 loss: 0.0005576533847488462
batch 200 loss: 0.0005577309872023761
batch 205 loss: 0.0005576332798227668
batch 210 loss: 0.000557648646645248
batch 215 loss: 0.0005576704279519618
batch 220 loss: 0.0005576535360887647
batch 225 loss: 0.0005577037809416652
batch 230 loss: 0.0005576621508225799
batch 235 loss: 0.000557634502183646
batch 240 loss: 0.0005576727446168662
Training Loss: 0.0005576834087454093
Validation Loss: 0.0005576934422909592
Epoch 82:
batch 5 loss: 0.0005577055737376214
batch 10 loss: 0.0005576664581894875
batch 15 loss: 0.0005576706607826054
batch 20 loss: 0.0005576718715019525
batch 25 loss: 0.0005576722207479179
batch 30 loss: 0.0005577077274210751
batch 35 loss: 0.000557651394046843
batch 40 loss: 0.000557667831890285
batch 45 loss: 0.0005576693918555975
batch 50 loss: 0.0005576198920607567
batch 55 loss: 0.0005576882394962013
batch 60 loss: 0.0005577168893069028
batch 65 loss: 0.0005577845382504165
batch 70 loss: 0.0005575667484663427
batch 75 loss: 0.0005576849915087223
batch 80 loss: 0.0005576751776970923
batch 85 loss: 0.0005578143405728042
batch 90 loss: 0.000557656737510115
batch 95 loss: 0.0005576371680945158
batch 100 loss: 0.0005576652940362692
batch 105 loss: 0.0005576703348197043
batch 110 loss: 0.0005576514871791005
batch 115 loss: 0.0005577107076533139
batch 120 loss: 0.0005576144554652274
batch 125 loss: 0.0005576353287324309
batch 130 loss: 0.0005576716503128409
batch 135 loss: 0.0005577104049734772
batch 140 loss: 0.0005577953299507499
batch 145 loss: 0.0005576987750828266
batch 150 loss: 0.0005576271680183709
batch 155 loss: 0.0005576119408942759
batch 160 loss: 0.0005577817792072892
batch 165 loss: 0.000557680323254317
batch 170 loss: 0.0005576226860284806
batch 175 loss: 0.0005576569936238229
batch 180 loss: 0.000557711988221854
batch 185 loss: 0.0005577962496317923
batch 190 loss: 0.0005576614290475846
batch 195 loss: 0.0005576626164838672
batch 200 loss: 0.0005576429306529462
batch 205 loss: 0.0005577678442932665
batch 210 loss: 0.0005577521747909487
batch 215 loss: 0.0005576423252932727
batch 220 loss: 0.0005577059928327799
batch 225 loss: 0.0005576526746153831
batch 230 loss: 0.0005577129661105574
batch 235 loss: 0.0005577397532761097
batch 240 loss: 0.0005576213588938117
Training Loss: 0.0005576833920107068
Validation Loss: 0.000557693403485852
Epoch 83:
batch 5 loss: 0.0005577222793363035
batch 10 loss: 0.0005576884257607162
batch 15 loss: 0.0005575884017162025
batch 20 loss: 0.0005575951072387397
batch 25 loss: 0.0005577319767326117
batch 30 loss: 0.0005576928029768169
batch 35 loss: 0.000557656807359308
batch 40 loss: 0.0005577265401370823
batch 45 loss: 0.000557624245993793
batch 50 loss: 0.0005576580646447837
batch 55 loss: 0.0005576378549449146
batch 60 loss: 0.0005578313488513231
batch 65 loss: 0.0005575341405346989
batch 70 loss: 0.0005576802650466561
batch 75 loss: 0.000557648646645248
batch 80 loss: 0.0005576691823080182
batch 85 loss: 0.0005577592062763869
batch 90 loss: 0.0005577689269557595
batch 95 loss: 0.0005577175645157695
batch 100 loss: 0.0005576471914537251
batch 105 loss: 0.0005576885188929737
batch 110 loss: 0.0005575590766966343
batch 115 loss: 0.0005577027914114296
batch 120 loss: 0.0005576902185566723
batch 125 loss: 0.0005577396717853844
batch 130 loss: 0.0005577851668931543
batch 135 loss: 0.0005577657138928771
batch 140 loss: 0.0005576121155172586
batch 145 loss: 0.0005577172269113362
batch 150 loss: 0.0005577456438913941
batch 155 loss: 0.000557651708368212
batch 160 loss: 0.000557549565564841
batch 165 loss: 0.0005576008232310414
batch 170 loss: 0.0005577618721872568
batch 175 loss: 0.000557633861899376
batch 180 loss: 0.0005576125695370138
batch 185 loss: 0.0005576809868216515
batch 190 loss: 0.0005577452713623643
batch 195 loss: 0.0005576557363383472
batch 200 loss: 0.0005577163770794869
batch 205 loss: 0.0005577038158662617
batch 210 loss: 0.0005576799740083516
batch 215 loss: 0.0005577675648964942
batch 220 loss: 0.0005577926174737513
batch 225 loss: 0.0005576177267357707
batch 230 loss: 0.0005576818482950329
batch 235 loss: 0.0005576965399086475
batch 240 loss: 0.0005576687050051987
Training Loss: 0.0005576833893428557
Validation Loss: 0.0005576934199780226
Epoch 84:
batch 5 loss: 0.0005576631636358797
batch 10 loss: 0.0005577062256634235
batch 15 loss: 0.0005576146417297423
batch 20 loss: 0.0005575811606831849
batch 25 loss: 0.0005576808704063297
batch 30 loss: 0.0005578011157922446
batch 35 loss: 0.0005577471340075136
batch 40 loss: 0.0005577474948950112
batch 45 loss: 0.0005576553172431886
batch 50 loss: 0.0005576491937972605
batch 55 loss: 0.0005576589028351009
batch 60 loss: 0.0005576076568104327
batch 65 loss: 0.0005576250609010458
batch 70 loss: 0.0005576824769377708
batch 75 loss: 0.000557582953479141
batch 80 loss: 0.0005576734663918614
batch 85 loss: 0.0005577466450631619
batch 90 loss: 0.0005576345836743712
batch 95 loss: 0.000557764305267483
batch 100 loss: 0.0005577541654929518
batch 105 loss: 0.0005576753406785429
batch 110 loss: 0.0005576180061325431
batch 115 loss: 0.0005576550378464162
batch 120 loss: 0.0005576735595241189
batch 125 loss: 0.0005577678908593953
batch 130 loss: 0.0005577505333349108
batch 135 loss: 0.0005577180534601211
batch 140 loss: 0.0005575725343078374
batch 145 loss: 0.000557596399448812
batch 150 loss: 0.0005576152820140123
batch 155 loss: 0.0005577852483838796
batch 160 loss: 0.0005578163778409362
batch 165 loss: 0.0005577723146416247
batch 170 loss: 0.000557777239009738
batch 175 loss: 0.0005576703115366399
batch 180 loss: 0.0005578217911534012
batch 185 loss: 0.000557622592896223
batch 190 loss: 0.0005577702075242996
batch 195 loss: 0.0005576207768172026
batch 200 loss: 0.000557597610168159
batch 205 loss: 0.0005576797178946435
batch 210 loss: 0.0005576531169936061
batch 215 loss: 0.0005577684030868113
batch 220 loss: 0.0005577282048761844
batch 225 loss: 0.0005576451658271253
batch 230 loss: 0.0005575957242399454
batch 235 loss: 0.0005576675874181091
batch 240 loss: 0.0005575911141932011
Training Loss: 0.0005576833891003237
Validation Loss: 0.0005576934025157243
Epoch 85:

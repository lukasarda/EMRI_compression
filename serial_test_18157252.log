no change     /sps/lisaf/lkarda/miniconda3/condabin/conda
no change     /sps/lisaf/lkarda/miniconda3/bin/conda
no change     /sps/lisaf/lkarda/miniconda3/bin/conda-env
no change     /sps/lisaf/lkarda/miniconda3/bin/activate
no change     /sps/lisaf/lkarda/miniconda3/bin/deactivate
no change     /sps/lisaf/lkarda/miniconda3/etc/profile.d/conda.sh
no change     /sps/lisaf/lkarda/miniconda3/etc/fish/conf.d/conda.fish
no change     /sps/lisaf/lkarda/miniconda3/shell/condabin/Conda.psm1
no change     /sps/lisaf/lkarda/miniconda3/shell/condabin/conda-hook.ps1
no change     /sps/lisaf/lkarda/miniconda3/lib/python3.12/site-packages/xontrib/conda.xsh
no change     /sps/lisaf/lkarda/miniconda3/etc/profile.d/conda.csh
no change     /pbs/home/l/lkarda/.bashrc
No action taken.
# of samples: 24000
Batchsize: 100
# of batches: 240
Epoch 1:
batch 5 loss: 0.01133201401680708
batch 10 loss: 0.007468017842620611
batch 15 loss: 0.0042846600990742445
batch 20 loss: 0.0025916835758835076
batch 25 loss: 0.0018957207910716533
batch 30 loss: 0.0015827663242816924
batch 35 loss: 0.001396274915896356
batch 40 loss: 0.001281768409535289
batch 45 loss: 0.0012114308308809995
batch 50 loss: 0.0011687962105497718
batch 55 loss: 0.001124757924117148
batch 60 loss: 0.0011010432848706842
batch 65 loss: 0.001077745179645717
batch 70 loss: 0.0010451949201524258
batch 75 loss: 0.0010256303707137705
batch 80 loss: 0.0010084514156915247
batch 85 loss: 0.0009707488236017526
batch 90 loss: 0.000957598234526813
batch 95 loss: 0.0009077809634618461
batch 100 loss: 0.0009006834123283624
batch 105 loss: 0.0008972490672022104
batch 110 loss: 0.0008734952658414841
batch 115 loss: 0.0008802849100902676
batch 120 loss: 0.000846336642280221
batch 125 loss: 0.0008495781570672989
batch 130 loss: 0.0008193617220968008
batch 135 loss: 0.0008303702692501247
batch 140 loss: 0.0008078917860984802
batch 145 loss: 0.0008342531160451472
batch 150 loss: 0.0008590772282332182
batch 155 loss: 0.0008476617280393839
batch 160 loss: 0.0008276711916550994
batch 165 loss: 0.000818499072920531
batch 170 loss: 0.0007865975960157812
batch 175 loss: 0.0007686025928705931
batch 180 loss: 0.0007654028129763901
batch 185 loss: 0.0007594631751999259
batch 190 loss: 0.0007555769174359739
batch 195 loss: 0.0007338470546528697
batch 200 loss: 0.0007332447101362049
batch 205 loss: 0.0007209909148514271
batch 210 loss: 0.0006975856027565897
batch 215 loss: 0.0007016672170720994
batch 220 loss: 0.000690641242545098
batch 225 loss: 0.0006866415496915579
batch 230 loss: 0.0006910592084750534
batch 235 loss: 0.0006771527114324272
batch 240 loss: 0.000673954701051116
Training Loss: 0.0013784776189519714
Validation Loss: 0.0006278986276205008
Epoch 2:
batch 5 loss: 0.0006659928010776639
batch 10 loss: 0.0006622306071221828
batch 15 loss: 0.0006502759759314358
batch 20 loss: 0.0006540561094880104
batch 25 loss: 0.0006469468469731509
batch 30 loss: 0.0006404496030882001
batch 35 loss: 0.0006417522090487182
batch 40 loss: 0.0006344288471154868
batch 45 loss: 0.0006471491418778896
batch 50 loss: 0.0006376703269779683
batch 55 loss: 0.0006316056358627975
batch 60 loss: 0.0006281913490965962
batch 65 loss: 0.0006161184865050018
batch 70 loss: 0.0006170161534100771
batch 75 loss: 0.0006200103322044015
batch 80 loss: 0.0006151553126983345
batch 85 loss: 0.0006133583490736782
batch 90 loss: 0.000613673112820834
batch 95 loss: 0.0006173594039864839
batch 100 loss: 0.0006357057602144778
batch 105 loss: 0.0006839276058599353
batch 110 loss: 0.0006420566234737635
batch 115 loss: 0.0006425617844797671
batch 120 loss: 0.000645024108234793
batch 125 loss: 0.0006271531688980758
batch 130 loss: 0.0006193754496052861
batch 135 loss: 0.0006162715726532042
batch 140 loss: 0.0006090831360779702
batch 145 loss: 0.0006188158760778606
batch 150 loss: 0.0006195579189807177
batch 155 loss: 0.0006132065784186125
batch 160 loss: 0.0006014889455400408
batch 165 loss: 0.0006022106041200459
batch 170 loss: 0.0006025873124599456
batch 175 loss: 0.0005983517272397876
batch 180 loss: 0.0005943411728367209
batch 185 loss: 0.0005934269865974784
batch 190 loss: 0.000592782546300441
batch 195 loss: 0.0005934727611020208
batch 200 loss: 0.0006041019456461072
batch 205 loss: 0.0006292634760029614
batch 210 loss: 0.000606261077336967
batch 215 loss: 0.000595824234187603
batch 220 loss: 0.000598822149913758
batch 225 loss: 0.0006160844233818353
batch 230 loss: 0.0006143278791569173
batch 235 loss: 0.000604809878859669
batch 240 loss: 0.0005972701939754188
Training Loss: 0.0006223251562914811
Validation Loss: 0.0005828851067538683
Epoch 3:
batch 5 loss: 0.0005915162852033973
batch 10 loss: 0.0005915736081078648
batch 15 loss: 0.000586751673836261
batch 20 loss: 0.0005819788784720004
batch 25 loss: 0.0005835108691826463
batch 30 loss: 0.0005847252439707517
batch 35 loss: 0.0005864903912879526
batch 40 loss: 0.0005863929050974548
batch 45 loss: 0.0005829297704622149
batch 50 loss: 0.0005830702022649348
batch 55 loss: 0.000581604172475636
batch 60 loss: 0.000585621502250433
batch 65 loss: 0.0005879633827134967
batch 70 loss: 0.000581223308108747
batch 75 loss: 0.0005828093038871884
batch 80 loss: 0.0005789389251731336
batch 85 loss: 0.0005805295542813838
batch 90 loss: 0.000582729175221175
batch 95 loss: 0.0005787460366263985
batch 100 loss: 0.0005782934837043286
batch 105 loss: 0.0005829595378600061
batch 110 loss: 0.0005905742407776415
batch 115 loss: 0.000600373896304518
batch 120 loss: 0.0005894518224522471
batch 125 loss: 0.0005814595613628625
batch 130 loss: 0.0006033062818460166
batch 135 loss: 0.000634554831776768
batch 140 loss: 0.0006044268142431974
batch 145 loss: 0.0005833660368807613
batch 150 loss: 0.0005797848454676569
batch 155 loss: 0.0005761540378443897
batch 160 loss: 0.000578352902084589
batch 165 loss: 0.0005770255927927792
batch 170 loss: 0.0005761037580668926
batch 175 loss: 0.0005901502212509513
batch 180 loss: 0.0005872419802471996
batch 185 loss: 0.000585705996491015
batch 190 loss: 0.0005749261006712913
batch 195 loss: 0.000573166087269783
batch 200 loss: 0.0005771583179011941
batch 205 loss: 0.000575461087282747
batch 210 loss: 0.0005900156684219837
batch 215 loss: 0.0005944508593529463
batch 220 loss: 0.00058123191120103
batch 225 loss: 0.0005733216530643404
batch 230 loss: 0.000580794143024832
batch 235 loss: 0.0005790547467768193
batch 240 loss: 0.0005811947514303029
Training Loss: 0.000584982632426545
Validation Loss: 0.0005809962574858218
Epoch 4:
batch 5 loss: 0.0005801408318802714
batch 10 loss: 0.000573966430965811
batch 15 loss: 0.0005726783769205212
batch 20 loss: 0.0005718631087802351
batch 25 loss: 0.0005853803711943328
batch 30 loss: 0.0005795540171675384
batch 35 loss: 0.0005937317269854248
batch 40 loss: 0.0005893899360671639
batch 45 loss: 0.0005791246658191085
batch 50 loss: 0.0005755533929914236
batch 55 loss: 0.0005717862281017005
batch 60 loss: 0.0005705754971131683
batch 65 loss: 0.0005677491659298539
batch 70 loss: 0.0006362672196701169
batch 75 loss: 0.0007755789207294584
batch 80 loss: 0.0007365811732597649
batch 85 loss: 0.000644042668864131
batch 90 loss: 0.0006118785357102751
batch 95 loss: 0.000595520855858922
batch 100 loss: 0.0005847905646078289
batch 105 loss: 0.0005843399208970368
batch 110 loss: 0.0006091728340834379
batch 115 loss: 0.0005865582847036421
batch 120 loss: 0.0005933650420047343
batch 125 loss: 0.0005886330269277096
batch 130 loss: 0.0005883751437067986
batch 135 loss: 0.0005819392506964504
batch 140 loss: 0.0005766308633610607
batch 145 loss: 0.000574768683873117
batch 150 loss: 0.0005743666319176554
batch 155 loss: 0.0005715176579542458
batch 160 loss: 0.0005717975087463856
batch 165 loss: 0.0005690687336027622
batch 170 loss: 0.0005691346246749163
batch 175 loss: 0.0005692061153240502
batch 180 loss: 0.0005740572232753038
batch 185 loss: 0.0005724868387915194
batch 190 loss: 0.0005764435278251767
batch 195 loss: 0.0005738652893342078
batch 200 loss: 0.0005723850452341139
batch 205 loss: 0.0005711730103939771
batch 210 loss: 0.00056943129748106
batch 215 loss: 0.0005669836420565844
batch 220 loss: 0.0005692712031304837
batch 225 loss: 0.0005747611518017948
batch 230 loss: 0.0005733648198656738
batch 235 loss: 0.0005746259819716215
batch 240 loss: 0.0005766107817180455
Training Loss: 0.0005885518296660545
Validation Loss: 0.0005768020511216794
Epoch 5:
batch 5 loss: 0.000576163164805621
batch 10 loss: 0.0005752741009928287
batch 15 loss: 0.0005748085561208427
batch 20 loss: 0.0005722910282202065
batch 25 loss: 0.0005761141539551318
batch 30 loss: 0.0005756046972237528
batch 35 loss: 0.0005723911919631064
batch 40 loss: 0.0005679942085407674
batch 45 loss: 0.0005696797044947744
batch 50 loss: 0.0005676964414305985
batch 55 loss: 0.0005686390330083668
batch 60 loss: 0.0005696426029317081
batch 65 loss: 0.000569296907633543
batch 70 loss: 0.0005712083075195551
batch 75 loss: 0.0005681279930286109
batch 80 loss: 0.0005693597020581364
batch 85 loss: 0.0005684909643605352
batch 90 loss: 0.000567608792334795
batch 95 loss: 0.0005688894540071488
batch 100 loss: 0.0005675427848473192
batch 105 loss: 0.0005654884735122323
batch 110 loss: 0.0005682779126800596
batch 115 loss: 0.0005670586950145661
batch 120 loss: 0.0005687261000275612
batch 125 loss: 0.0005668568424880505
batch 130 loss: 0.0005763184977695346
batch 135 loss: 0.0005652831750921905
batch 140 loss: 0.0005686055403202773
batch 145 loss: 0.0005707243457436561
batch 150 loss: 0.0005719871260225773
batch 155 loss: 0.00056778957368806
batch 160 loss: 0.0005708017852157354
batch 165 loss: 0.0005693168728612364
batch 170 loss: 0.0005666901357471943
batch 175 loss: 0.0005678107379935681
batch 180 loss: 0.000570721470285207
batch 185 loss: 0.0005671657738275826
batch 190 loss: 0.0005661051953211426
batch 195 loss: 0.0005668408004567028
batch 200 loss: 0.0005647708545438946
batch 205 loss: 0.0005649267113767564
batch 210 loss: 0.0005661292816512287
batch 215 loss: 0.0005646281060762703
batch 220 loss: 0.0005671841790899634
batch 225 loss: 0.000566562230233103
batch 230 loss: 0.0005643916898407042
batch 235 loss: 0.0005658071371726692
batch 240 loss: 0.0005653382395394146
Training Loss: 0.0005689402348555935
Validation Loss: 0.0005677297604658331
Epoch 6:
batch 5 loss: 0.0005650842795148492
batch 10 loss: 0.0005651192157529294
batch 15 loss: 0.0005662900628522038
batch 20 loss: 0.000568586599547416
batch 25 loss: 0.0005653915461152792
batch 30 loss: 0.0005655104643665255
batch 35 loss: 0.0005654972395859659
batch 40 loss: 0.0005650257226079702
batch 45 loss: 0.0005653428263030947
batch 50 loss: 0.0005662565468810499
batch 55 loss: 0.0005671793827787041
batch 60 loss: 0.0005654931184835732
batch 65 loss: 0.0005641923635266721
batch 70 loss: 0.0005678445333614946
batch 75 loss: 0.0005662824842147529
batch 80 loss: 0.0005662643117830158
batch 85 loss: 0.0005673832376487554
batch 90 loss: 0.0005662152892909944
batch 95 loss: 0.0005664247437380254
batch 100 loss: 0.0005723430775105953
batch 105 loss: 0.0006234582629986108
batch 110 loss: 0.0005647974321618676
batch 115 loss: 0.0005651834071613848
batch 120 loss: 0.00056486054090783
batch 125 loss: 0.0005676375236362219
batch 130 loss: 0.0009562478633597493
batch 135 loss: 0.0005648298072628676
batch 140 loss: 0.0005647332058288157
batch 145 loss: 0.0007056653848849237
batch 150 loss: 0.0005660782684572041
batch 155 loss: 0.0005659314105287194
batch 160 loss: 0.0005661664647050202
batch 165 loss: 0.0005667799268849194
batch 170 loss: 0.0005639289156533778
batch 175 loss: 0.0005658354493789375
batch 180 loss: 0.0005642393371090293
batch 185 loss: 0.0005640389164909721
batch 190 loss: 0.0005646855919621885
batch 195 loss: 0.0005660996539518237
batch 200 loss: 0.0005672616767697036
batch 205 loss: 0.0005655023735016585
batch 210 loss: 0.0005661032977513969
batch 215 loss: 0.0005654323962517082
batch 220 loss: 0.0005753334145992995
batch 225 loss: 0.0005718565895222128
batch 230 loss: 0.0005647024954669178
batch 235 loss: 0.0005653355154208839
batch 240 loss: 0.0005922480951994658
Training Loss: 0.0005790145888264912
Validation Loss: 0.0005683976254658773
Epoch 7:
batch 5 loss: 0.000565093185286969
batch 10 loss: 0.0005669726058840751
batch 15 loss: 0.0005673507344909013
batch 20 loss: 0.0005647097830660641
batch 25 loss: 0.0005656894063577056
batch 30 loss: 0.0005685166106559336
batch 35 loss: 0.0005651296814903617
batch 40 loss: 0.0005666804383508861
batch 45 loss: 0.0005673238658346236
batch 50 loss: 0.0005658025736920535
batch 55 loss: 0.0005664468393661082
batch 60 loss: 0.0005644318298436701
batch 65 loss: 0.000566889310721308
batch 70 loss: 0.0005648194579407573
batch 75 loss: 0.0005671375198289752
batch 80 loss: 0.0005666002747602761
batch 85 loss: 0.0005658004432916641
batch 90 loss: 0.0005641755647957325
batch 95 loss: 0.0005669284262694418
batch 100 loss: 0.0005690074642188847
batch 105 loss: 0.0005640130490064621
batch 110 loss: 0.0005649086087942123
batch 115 loss: 0.0005686372518539428
batch 120 loss: 0.0005657292786054313
batch 125 loss: 0.0005743930698372424
batch 130 loss: 0.0005668936064466834
batch 135 loss: 0.0005670595681294798
batch 140 loss: 0.0005654124426655472
batch 145 loss: 0.0005673514329828322
batch 150 loss: 0.0005661909817717969
batch 155 loss: 0.0005667987745255232
batch 160 loss: 0.0005657691857777536
batch 165 loss: 0.0005671748192980885
batch 170 loss: 0.0005693632061593235
batch 175 loss: 0.0005658645415678621
batch 180 loss: 0.0005676966393366456
batch 185 loss: 0.000566799147054553
batch 190 loss: 0.0005656208260916174
batch 195 loss: 0.0005661296891048551
batch 200 loss: 0.0005657198955304921
batch 205 loss: 0.000565074582118541
batch 210 loss: 0.0005656301393173635
batch 215 loss: 0.000565767812076956
batch 220 loss: 0.000566486525349319
batch 225 loss: 0.0005658696638420225
batch 230 loss: 0.0005659198970533908
batch 235 loss: 0.0005666709505021573
batch 240 loss: 0.0005667378660291434
Training Loss: 0.0005664831138953256
Validation Loss: 0.0005681962657642241
Epoch 8:
batch 5 loss: 0.000565462838858366
batch 10 loss: 0.0005650524282827974
batch 15 loss: 0.0005640618968755007
batch 20 loss: 0.000564986513927579
batch 25 loss: 0.0005651241517625749
batch 30 loss: 0.0005636746762320399
batch 35 loss: 0.0005665925913490355
batch 40 loss: 0.0005649909027852118
batch 45 loss: 0.0005722050555050373
batch 50 loss: 0.0005673990352079272
batch 55 loss: 0.0005665130796842277
batch 60 loss: 0.0005858437274582684
batch 65 loss: 0.0005732788005843759
batch 70 loss: 0.0005738341715186834
batch 75 loss: 0.0005755843711085617
batch 80 loss: 0.000576431944500655
batch 85 loss: 0.0005789450951851904
batch 90 loss: 0.0005761406966485084
batch 95 loss: 0.0005795503151603043
batch 100 loss: 0.0005745612666942179
batch 105 loss: 0.0005740537657402456
batch 110 loss: 0.000573452387470752
batch 115 loss: 0.0005709936958737671
batch 120 loss: 0.0005703736562281847
batch 125 loss: 0.0005727720912545919
batch 130 loss: 0.0005722361616790295
batch 135 loss: 0.0005700774374417961
batch 140 loss: 0.0005696666776202619
batch 145 loss: 0.0005672653438523412
batch 150 loss: 0.0005673275212757289
batch 155 loss: 0.0005672414787113667
batch 160 loss: 0.0005661114235408604
batch 165 loss: 0.0005682930815964938
batch 170 loss: 0.000566283892840147
batch 175 loss: 0.0005645398516207934
batch 180 loss: 0.0005730975768528879
batch 185 loss: 0.0005666023353114724
batch 190 loss: 0.0005691057071089744
batch 195 loss: 0.00057092314818874
batch 200 loss: 0.0005703898728825152
batch 205 loss: 0.000568818289320916
batch 210 loss: 0.0005698588211089373
batch 215 loss: 0.0005714891012758017
batch 220 loss: 0.0005692316219210625
batch 225 loss: 0.0005675786989741028
batch 230 loss: 0.0005677693872712553
batch 235 loss: 0.0005648285034112633
batch 240 loss: 0.0005669038277119398
Training Loss: 0.0005699483107794852
Validation Loss: 0.0005690258248553921
Epoch 9:
batch 5 loss: 0.0005667416844516993
batch 10 loss: 0.0005637199035845696
batch 15 loss: 0.0005644474760629237
batch 20 loss: 0.0005660885246470571
batch 25 loss: 0.000563608470838517
batch 30 loss: 0.0005661278846673667
batch 35 loss: 0.0005674164276570082
batch 40 loss: 0.0005638807895593345
batch 45 loss: 0.0005655598477460444
batch 50 loss: 0.0005639678565785289
batch 55 loss: 0.0005651860847137868
batch 60 loss: 0.0005646414821967483
batch 65 loss: 0.000566956028342247
batch 70 loss: 0.0005647648475132882
batch 75 loss: 0.00056759063154459
batch 80 loss: 0.0005670049344189465
batch 85 loss: 0.0005662682233378291
batch 90 loss: 0.0005668129306286573
batch 95 loss: 0.0005663358140736818
batch 100 loss: 0.0005650718696415425
batch 105 loss: 0.0005672089639119804
batch 110 loss: 0.0005651678773574531
batch 115 loss: 0.0005649875965900719
batch 120 loss: 0.0005638623610138893
batch 125 loss: 0.0005638060043565929
batch 130 loss: 0.0005639016861096024
batch 135 loss: 0.0005621024640277029
batch 140 loss: 0.006314089719671756
batch 145 loss: 0.0031458215322345494
batch 150 loss: 0.0036746595054864884
batch 155 loss: 0.0031553084030747415
batch 160 loss: 0.002583816507831216
batch 165 loss: 0.002164834411814809
batch 170 loss: 0.0019009467912837863
batch 175 loss: 0.0016783130588009954
batch 180 loss: 0.0014899706467986107
batch 185 loss: 0.001317740767262876
batch 190 loss: 0.001172482338733971
batch 195 loss: 0.0010342099238187074
batch 200 loss: 0.0009298638673499226
batch 205 loss: 0.000855574815068394
batch 210 loss: 0.0008024877752177417
batch 215 loss: 0.0007735441555269063
batch 220 loss: 0.0007468872354365885
batch 225 loss: 0.0007379346061497927
batch 230 loss: 0.0007262841332703829
batch 235 loss: 0.0007096796296536922
batch 240 loss: 0.0007075609639286995
Training Loss: 0.0010809424886247144
Validation Loss: 0.0006284795109725868
Epoch 10:
batch 5 loss: 0.0006936940713785589
batch 10 loss: 0.0006816781940869987
batch 15 loss: 0.0006718074553646147
batch 20 loss: 0.0006637132610194385
batch 25 loss: 0.0006581065012142062
batch 30 loss: 0.0006496097659692169
batch 35 loss: 0.0006429512985050678
batch 40 loss: 0.0006429793545976281
batch 45 loss: 0.0006304775713942945
batch 50 loss: 0.0006325172493234277
batch 55 loss: 0.000630107510369271
batch 60 loss: 0.0006235752487555146
batch 65 loss: 0.0006231375969946385
batch 70 loss: 0.0006219401257112622
batch 75 loss: 0.0006150067551061511
batch 80 loss: 0.000610715162474662
batch 85 loss: 0.0006056561716832221
batch 90 loss: 0.000604906736407429
batch 95 loss: 0.0006070230971090496
batch 100 loss: 0.0006301940535195172
batch 105 loss: 0.0006165103288367391
batch 110 loss: 0.0006190926767885685
batch 115 loss: 0.0006136116455309093
batch 120 loss: 0.000603517924901098
batch 125 loss: 0.000596711307298392
batch 130 loss: 0.0005925053032115102
batch 135 loss: 0.0005915209301747381
batch 140 loss: 0.0005895294481888414
batch 145 loss: 0.0005881464458070695
batch 150 loss: 0.0005888361716642976
batch 155 loss: 0.000584766932297498
batch 160 loss: 0.0005876440089195966
batch 165 loss: 0.0006020865170285105
batch 170 loss: 0.0006020768429152668
batch 175 loss: 0.000709340930916369
batch 180 loss: 0.0006718808319419623
batch 185 loss: 0.000655238062608987
batch 190 loss: 0.0006412977119907737
batch 195 loss: 0.000626710255164653
batch 200 loss: 0.0006157045951113105
batch 205 loss: 0.0006020144792273641
batch 210 loss: 0.0005997759639285505
batch 215 loss: 0.0005922396434471011
batch 220 loss: 0.0005928304861299693
batch 225 loss: 0.0005882240016944707
batch 230 loss: 0.0005868670297786594
batch 235 loss: 0.0005859294207766653
batch 240 loss: 0.000583121390081942
Training Loss: 0.000620156843069708
Validation Loss: 0.0005689592469328394
Epoch 11:
batch 5 loss: 0.0005812026327475905
batch 10 loss: 0.0005789339076727629
batch 15 loss: 0.0005804663873277604
batch 20 loss: 0.0005801651044748723
batch 25 loss: 0.0005764280562289059
batch 30 loss: 0.0005775930010713636
batch 35 loss: 0.0005738725885748863
batch 40 loss: 0.0005732295103371143
batch 45 loss: 0.0005743558518588543
batch 50 loss: 0.0005748326773755252
batch 55 loss: 0.0005731177749112249
batch 60 loss: 0.0005739856045693159
batch 65 loss: 0.0005714972619898617
batch 70 loss: 0.000570983113721013
batch 75 loss: 0.0005700704408809542
batch 80 loss: 0.0005702053080312907
batch 85 loss: 0.0005707613774575293
batch 90 loss: 0.0005718573462218046
batch 95 loss: 0.0005740087130106985
batch 100 loss: 0.0005763878114521503
batch 105 loss: 0.0005969936260953546
batch 110 loss: 0.0005912121618166566
batch 115 loss: 0.0005752166616730392
batch 120 loss: 0.0005961649818345905
batch 125 loss: 0.0006534594227559865
batch 130 loss: 0.0006418995908461511
batch 135 loss: 0.0006151903653517365
batch 140 loss: 0.0005990566336549818
batch 145 loss: 0.0005805972148664295
batch 150 loss: 0.0005821225582621992
batch 155 loss: 0.0005768882110714912
batch 160 loss: 0.0005759699153713882
batch 165 loss: 0.0005742407636716961
batch 170 loss: 0.0005730140022933483
batch 175 loss: 0.0005697867949493229
batch 180 loss: 0.000569023925345391
batch 185 loss: 0.0005692324019037187
batch 190 loss: 0.0005681162932887673
batch 195 loss: 0.0005677110166288912
batch 200 loss: 0.0005679122754372656
batch 205 loss: 0.0005665853735990822
batch 210 loss: 0.0005682101473212242
batch 215 loss: 0.0005667356192134321
batch 220 loss: 0.0005662068841047585
batch 225 loss: 0.000565261032897979
batch 230 loss: 0.000565378472674638
batch 235 loss: 0.0005655015702359378
batch 240 loss: 0.0005650776904076338
Training Loss: 0.0005784733349476786
Validation Loss: 0.0005605873050323377
Epoch 12:
batch 5 loss: 0.0005648030899465084
batch 10 loss: 0.0005659938557073474
batch 15 loss: 0.0005650820210576057
batch 20 loss: 0.0005651760613545776
batch 25 loss: 0.0005648504709824919
batch 30 loss: 0.0005667670862749219
batch 35 loss: 0.0005697906715795397
batch 40 loss: 0.0005684304051101208
batch 45 loss: 0.0005645963014103472
batch 50 loss: 0.0005669535370543599
batch 55 loss: 0.0005674107000231743
batch 60 loss: 0.0005666783428750933
batch 65 loss: 0.0005645099678076804
batch 70 loss: 0.0005740400170907378
batch 75 loss: 0.0006514542154036462
batch 80 loss: 0.0006326847593300045
batch 85 loss: 0.0006085229804739356
batch 90 loss: 0.0005997294210828841
batch 95 loss: 0.0005840233527123929
batch 100 loss: 0.0005772107630036772
batch 105 loss: 0.0005698449560441077
batch 110 loss: 0.000567290442995727
batch 115 loss: 0.0005653002299368382
batch 120 loss: 0.000565890152938664
batch 125 loss: 0.0005682582035660743
batch 130 loss: 0.0005662103998474777
batch 135 loss: 0.0005646693054586649
batch 140 loss: 0.0005749836564064026
batch 145 loss: 0.0005924575845710934
batch 150 loss: 0.0005912930821068585
batch 155 loss: 0.0005810612230561674
batch 160 loss: 0.0005732775782234967
batch 165 loss: 0.0005665453732945025
batch 170 loss: 0.0005652666208334267
batch 175 loss: 0.0005685962736606598
batch 180 loss: 0.0005726494244299829
batch 185 loss: 0.0005736113642342388
batch 190 loss: 0.000571345875505358
batch 195 loss: 0.0005675777909345924
batch 200 loss: 0.0005645009921863675
batch 205 loss: 0.0005634684581309557
batch 210 loss: 0.0005664015654474497
batch 215 loss: 0.0005681784823536873
batch 220 loss: 0.0005696951993741095
batch 225 loss: 0.0005684520932845771
batch 230 loss: 0.0005650763981975615
batch 235 loss: 0.0005636819172650575
batch 240 loss: 0.000562660489231348
Training Loss: 0.0005738948573707602
Validation Loss: 0.0005578449451907848
Epoch 13:
batch 5 loss: 0.0005710336961783468
batch 10 loss: 0.0005826580105349422
batch 15 loss: 0.0005931550404056907
batch 20 loss: 0.0005886537721380592
batch 25 loss: 0.0005820761667564512
batch 30 loss: 0.0005779875442385674
batch 35 loss: 0.0005731674726121127
batch 40 loss: 0.0005695321364328265
batch 45 loss: 0.0005670376471243799
batch 50 loss: 0.0005642397096380592
batch 55 loss: 0.0005640551564283669
batch 60 loss: 0.0005626003257930279
batch 65 loss: 0.0005618060589767992
batch 70 loss: 0.0005615083733573556
batch 75 loss: 0.0005608299281448126
batch 80 loss: 0.0005606895894743503
batch 85 loss: 0.0005609670770354569
batch 90 loss: 0.0005602648248896003
batch 95 loss: 0.0005601408542133868
batch 100 loss: 0.0005609253072179854
batch 105 loss: 0.0005602737073786557
batch 110 loss: 0.0005597849725745618
batch 115 loss: 0.0005598836462013424
batch 120 loss: 0.0005596052040345966
batch 125 loss: 0.0005660626455210149
batch 130 loss: 0.0005644781864248216
batch 135 loss: 0.0005673010367900133
batch 140 loss: 0.0005672933184541762
batch 145 loss: 0.0005667392746545374
batch 150 loss: 0.0005661947885528207
batch 155 loss: 0.0005636626505292952
batch 160 loss: 0.0005619669682346284
batch 165 loss: 0.0005612456006929278
batch 170 loss: 0.0005604898440651595
batch 175 loss: 0.0005601880373433232
batch 180 loss: 0.0005604281439445912
batch 185 loss: 0.000559530290775001
batch 190 loss: 0.0005594374146312475
batch 195 loss: 0.0005592051660642028
batch 200 loss: 0.0005594431073404849
batch 205 loss: 0.0005591274006292224
batch 210 loss: 0.0005592227797023952
batch 215 loss: 0.0005591988796368241
batch 220 loss: 0.000559038168285042
batch 225 loss: 0.000558905559591949
batch 230 loss: 0.0005581859033554793
batch 235 loss: 0.0005589421489275992
batch 240 loss: 0.000558729178737849
Training Loss: 0.0005645394315555071
Validation Loss: 0.0005576936198243251
Epoch 14:
batch 5 loss: 0.000558845279738307
batch 10 loss: 0.0005588346626609564
batch 15 loss: 0.0005587324383668601
batch 20 loss: 0.0005587681196630001
batch 25 loss: 0.0005586320767179132
batch 30 loss: 0.0005589058040641248
batch 35 loss: 0.0005585769074968993
batch 40 loss: 0.000558378710411489
batch 45 loss: 0.0005583636229857802
batch 50 loss: 0.0005584710044786334
batch 55 loss: 0.0005586987128481269
batch 60 loss: 0.000558426696807146
batch 65 loss: 0.0005589367705397308
batch 70 loss: 0.0005586303072050214
batch 75 loss: 0.0005585304577834904
batch 80 loss: 0.0005591015098616481
batch 85 loss: 0.0005589141277596354
batch 90 loss: 0.0005586336366832257
batch 95 loss: 0.0005589056410826743
batch 100 loss: 0.0005586155923083425
batch 105 loss: 0.000559065374545753
batch 110 loss: 0.000558427965734154
batch 115 loss: 0.0005589882959611714
batch 120 loss: 0.0005587605410255492
batch 125 loss: 0.0005585041013546288
batch 130 loss: 0.00055857440456748
batch 135 loss: 0.0005586325190961361
batch 140 loss: 0.0005586074781604111
batch 145 loss: 0.0005585808423347772
batch 150 loss: 0.0005585476872511208
batch 155 loss: 0.0005585831124335528
batch 160 loss: 0.0005587130901403726
batch 165 loss: 0.0005586029612459243
batch 170 loss: 0.0005583249847404658
batch 175 loss: 0.0005588326836004853
batch 180 loss: 0.0005585142178460955
batch 185 loss: 0.0005622281576506793
batch 190 loss: 0.0005620952462777496
batch 195 loss: 0.000564663705881685
batch 200 loss: 0.000566091132350266
batch 205 loss: 0.0005647076526656747
batch 210 loss: 0.0005644030636176467
batch 215 loss: 0.0005629175226204097
batch 220 loss: 0.0005617812392301857
batch 225 loss: 0.000561058393213898
batch 230 loss: 0.0005610109423287213
batch 235 loss: 0.0005599966854788363
batch 240 loss: 0.0005597222945652903
Training Loss: 0.0005596424661537942
Validation Loss: 0.0005576949100941419
Epoch 15:
batch 5 loss: 0.0005595634342171252
batch 10 loss: 0.0005591808585450053
batch 15 loss: 0.0005593100097030402
batch 20 loss: 0.000559382513165474
batch 25 loss: 0.0005587050574831665
batch 30 loss: 0.0005593053414486348
batch 35 loss: 0.000559506006538868
batch 40 loss: 0.0005595256807282567
batch 45 loss: 0.0005593501846306026
batch 50 loss: 0.0005592105095274747
batch 55 loss: 0.0005590574815869332
batch 60 loss: 0.0005592805333435536
batch 65 loss: 0.0005592266214080154
batch 70 loss: 0.0005593311740085483
batch 75 loss: 0.0005591519759036601
batch 80 loss: 0.0005593396024778485
batch 85 loss: 0.0005589499603956937
batch 90 loss: 0.000559081498067826
batch 95 loss: 0.0005590030108578503
batch 100 loss: 0.0005588730215094984
batch 105 loss: 0.0005591159802861512
batch 110 loss: 0.0005587973864749074
batch 115 loss: 0.0005590940359979868
batch 120 loss: 0.0005590779823251068
batch 125 loss: 0.000558744405861944
batch 130 loss: 0.0005588948959484696
batch 135 loss: 0.0005586981656961143
batch 140 loss: 0.0005591330933384598
batch 145 loss: 0.0005586574086919426
batch 150 loss: 0.0005590176326222718
batch 155 loss: 0.0005589123698882759
batch 160 loss: 0.0005588371888734401
batch 165 loss: 0.0005592290544882417
batch 170 loss: 0.0005588766653090715
batch 175 loss: 0.0005586061161011457
batch 180 loss: 0.0005587922292761505
batch 185 loss: 0.000558951823040843
batch 190 loss: 0.0005587516701780259
batch 195 loss: 0.0005587891675531865
batch 200 loss: 0.0005588147090747952
batch 205 loss: 0.0005587922991253435
batch 210 loss: 0.0005587063380517066
batch 215 loss: 0.0005587789812125266
batch 220 loss: 0.0005585068720392883
batch 225 loss: 0.0005587597843259573
batch 230 loss: 0.0005586136947385966
batch 235 loss: 0.0005585828330367804
batch 240 loss: 0.0005587686551734805
Training Loss: 0.0005589924148807768
Validation Loss: 0.0005576944686860468
Epoch 16:
batch 5 loss: 0.0005586538231000304
batch 10 loss: 0.000558581342920661
batch 15 loss: 0.0005586444051004947
batch 20 loss: 0.0005584411905147135
batch 25 loss: 0.0005586287938058376
batch 30 loss: 0.0005588361993432045
batch 35 loss: 0.0005586429848335684
batch 40 loss: 0.0005587028688751161
batch 45 loss: 0.0005584825994446874
batch 50 loss: 0.0005587137304246426
batch 55 loss: 0.0005587301682680845
batch 60 loss: 0.0005586971878074109
batch 65 loss: 0.0005587069550529123
batch 70 loss: 0.0005586771992966532
batch 75 loss: 0.0005587755353190005
batch 80 loss: 0.0005586491781286896
batch 85 loss: 0.0005588799482211471
batch 90 loss: 0.0005587628344073892
batch 95 loss: 0.0005586960120126605
batch 100 loss: 0.0005586453364230693
batch 105 loss: 0.0005585804930888117
batch 110 loss: 0.0005588415777310729
batch 115 loss: 0.0005585768143646419
batch 120 loss: 0.000558660295791924
batch 125 loss: 0.0005585071165114641
batch 130 loss: 0.0005588998552411795
batch 135 loss: 0.0005584094673395157
batch 140 loss: 0.0005588565836660564
batch 145 loss: 0.000558349781204015
batch 150 loss: 0.0005587897729128599
batch 155 loss: 0.0005587645922787487
batch 160 loss: 0.0005586337181739509
batch 165 loss: 0.0005586696090176702
batch 170 loss: 0.0005589364096522331
batch 175 loss: 0.0005583867663517594
batch 180 loss: 0.0005585824139416218
batch 185 loss: 0.0005584240658208728
batch 190 loss: 0.0005585546372458339
batch 195 loss: 0.0005587300169281661
batch 200 loss: 0.0005587446852587163
batch 205 loss: 0.0005584716913290322
batch 210 loss: 0.0005586921935901046
batch 215 loss: 0.000558497745078057
batch 220 loss: 0.0005589304957538844
batch 225 loss: 0.0005587831372395157
batch 230 loss: 0.0005585649283602834
batch 235 loss: 0.0005586574436165393
batch 240 loss: 0.0005585683276876808
Training Loss: 0.0005586586026765872
Validation Loss: 0.000557693763403222
Epoch 17:
batch 5 loss: 0.0005589557345956564
batch 10 loss: 0.0005586145096458494
batch 15 loss: 0.0005587578285485506
batch 20 loss: 0.0005585798295214772
batch 25 loss: 0.0005584881291724741
batch 30 loss: 0.000558562611695379
batch 35 loss: 0.0005587778519839049
batch 40 loss: 0.0005584221100434661
batch 45 loss: 0.0005584663129411637
batch 50 loss: 0.0005585674545727671
batch 55 loss: 0.0005587449064478278
batch 60 loss: 0.0005587589461356401
batch 65 loss: 0.0005585798877291382
batch 70 loss: 0.000558656791690737
batch 75 loss: 0.0005586333689279854
batch 80 loss: 0.0005585219012573361
batch 85 loss: 0.0005584003403782845
batch 90 loss: 0.0005583093967288733
batch 95 loss: 0.0005584979080595076
batch 100 loss: 0.000558774103410542
batch 105 loss: 0.0005584468599408865
batch 110 loss: 0.0005585114355199039
batch 115 loss: 0.0005586886312812567
batch 120 loss: 0.000558350863866508
batch 125 loss: 0.0005584254395216703
batch 130 loss: 0.0005583968595601618
batch 135 loss: 0.000558488245587796
batch 140 loss: 0.00055870272917673
batch 145 loss: 0.0005584767670370639
batch 150 loss: 0.0005587976891547441
batch 155 loss: 0.0005584826343692839
batch 160 loss: 0.0005586306913755834
batch 165 loss: 0.0005582702229730785
batch 170 loss: 0.0005585638340562582
batch 175 loss: 0.0005586472805589437
batch 180 loss: 0.0005583715159446001
batch 185 loss: 0.000558742182329297
batch 190 loss: 0.0005586411454714835
batch 195 loss: 0.0005584197118878364
batch 200 loss: 0.0005586000857874751
batch 205 loss: 0.0005588143249042332
batch 210 loss: 0.000558545789681375
batch 215 loss: 0.0005584405967965722
batch 220 loss: 0.0005585318198427558
batch 225 loss: 0.0005583509569987655
batch 230 loss: 0.0005583148798905313
batch 235 loss: 0.0005583038902841509
batch 240 loss: 0.000558496592566371
Training Loss: 0.000558552574996914
Validation Loss: 0.0005576950837469971
Epoch 18:
batch 5 loss: 0.000558218196965754
batch 10 loss: 0.0005584533675573767
batch 15 loss: 0.0005583185236901044
batch 20 loss: 0.0005584756261669099
batch 25 loss: 0.0005583165446296334
batch 30 loss: 0.0005583360907621682
batch 35 loss: 0.0005583493271842599
batch 40 loss: 0.0005586119717918336
batch 45 loss: 0.0005583269987255335
batch 50 loss: 0.0005585438455455005
batch 55 loss: 0.0005582530866377056
batch 60 loss: 0.0005584867205470801
batch 65 loss: 0.000558469514362514
batch 70 loss: 0.0005583538906648756
batch 75 loss: 0.0005582788493484258
batch 80 loss: 0.00055851946817711
batch 85 loss: 0.0005583458580076695
batch 90 loss: 0.0005583925405517221
batch 95 loss: 0.0005584406899288297
batch 100 loss: 0.0005583334132097661
batch 105 loss: 0.0005582023644819855
batch 110 loss: 0.0005584193975664675
batch 115 loss: 0.0005578857613727451
batch 120 loss: 0.0005580930737778544
batch 125 loss: 0.000557980767916888
batch 130 loss: 0.0005581339588388801
batch 135 loss: 0.0005581792676821351
batch 140 loss: 0.0005580479395575821
batch 145 loss: 0.0005581127246841788
batch 150 loss: 0.0005579584045335651
batch 155 loss: 0.0005581150879152119
batch 160 loss: 0.0005581940175034105
batch 165 loss: 0.0005581911071203649
batch 170 loss: 0.0005582717945799232
batch 175 loss: 0.0005580760072916747
batch 180 loss: 0.000558121723588556
batch 185 loss: 0.0005582851357758045
batch 190 loss: 0.0005580840399488807
batch 195 loss: 0.0005580404540523887
batch 200 loss: 0.0005583469523116946
batch 205 loss: 0.0005580644006840885
batch 210 loss: 0.0005581080331467092
batch 215 loss: 0.0005583006655797363
batch 220 loss: 0.0005581659963354469
batch 225 loss: 0.0005581055651418865
batch 230 loss: 0.0005583273828960955
batch 235 loss: 0.0005579862976446748
batch 240 loss: 0.0005579780088737607
Training Loss: 0.0005582416844845284
Validation Loss: 0.0005576934946778541
Epoch 19:
batch 5 loss: 0.0005580142606049776
batch 10 loss: 0.0005581457284279167
batch 15 loss: 0.0005578025244176388
batch 20 loss: 0.0005583652993664146
batch 25 loss: 0.0005581922945566475
batch 30 loss: 0.0005580536206252873
batch 35 loss: 0.000557989114895463
batch 40 loss: 0.0005582183366641402
batch 45 loss: 0.0005581389181315899
batch 50 loss: 0.0005579477408900857
batch 55 loss: 0.0005581067758612335
batch 60 loss: 0.0005582065554335713
batch 65 loss: 0.000558550818823278
batch 70 loss: 0.0005580607452429831
batch 75 loss: 0.0005582012236118317
batch 80 loss: 0.0005582283716648817
batch 85 loss: 0.0005580029566772283
batch 90 loss: 0.0005580217810347676
batch 95 loss: 0.0005584280705079436
batch 100 loss: 0.0005584575468674302
batch 105 loss: 0.0005583340534940362
batch 110 loss: 0.0005584281403571367
batch 115 loss: 0.0005582913290709257
batch 120 loss: 0.0005581633420661091
batch 125 loss: 0.0006808985490351915
batch 130 loss: 0.0009732706123031676
batch 135 loss: 0.0009131747647188604
batch 140 loss: 0.0008141123922541738
batch 145 loss: 0.0007441561785526574
batch 150 loss: 0.0006908648647367954
batch 155 loss: 0.0006503584096208215
batch 160 loss: 0.0006267026066780091
batch 165 loss: 0.0006160642951726913
batch 170 loss: 0.0006063781795091927
batch 175 loss: 0.0005973257008008659
batch 180 loss: 0.0005893530906178057
batch 185 loss: 0.0005839554942212999
batch 190 loss: 0.0005796145531348884
batch 195 loss: 0.0005765320849604905
batch 200 loss: 0.0005738397710956633
batch 205 loss: 0.000572012597694993
batch 210 loss: 0.0005702742375433445
batch 215 loss: 0.0005690022953785956
batch 220 loss: 0.0005675041582435369
batch 225 loss: 0.0005654779146425426
batch 230 loss: 0.0005646291538141668
batch 235 loss: 0.0005647051497362554
batch 240 loss: 0.0005631020874716341
Training Loss: 0.0005989512227339825
Validation Loss: 0.0005576991873870915
Epoch 20:
batch 5 loss: 0.0005623757955618202
batch 10 loss: 0.0005619169329293072
batch 15 loss: 0.000560919160488993
batch 20 loss: 0.0005605855607427656
batch 25 loss: 0.0005604019272141159
batch 30 loss: 0.0005600602831691504
batch 35 loss: 0.0005593070178292692
batch 40 loss: 0.0005593535606749356
batch 45 loss: 0.0005593771580606699
batch 50 loss: 0.0005590914632193744
batch 55 loss: 0.000559153815265745
batch 60 loss: 0.0005592505098320544
batch 65 loss: 0.0005589296342805028
batch 70 loss: 0.0005587351624853909
batch 75 loss: 0.0005591504625044764
batch 80 loss: 0.0005586667568422854
batch 85 loss: 0.0005588265252299607
batch 90 loss: 0.0005586625076830388
batch 95 loss: 0.0005586892948485911
batch 100 loss: 0.0005585159291513264
batch 105 loss: 0.0005585669656284154
batch 110 loss: 0.0005586666637100279
batch 115 loss: 0.0005586539511568845
batch 120 loss: 0.0005585060454905034
batch 125 loss: 0.0005586650455370546
batch 130 loss: 0.0005589121836237609
batch 135 loss: 0.0005588546744547784
batch 140 loss: 0.0005586944986134768
batch 145 loss: 0.0005587607738561928
batch 150 loss: 0.0005586171988397837
batch 155 loss: 0.0005584642989560962
batch 160 loss: 0.0005588061874732375
batch 165 loss: 0.0005584163125604391
batch 170 loss: 0.0005584311438724399
batch 175 loss: 0.0005586538231000304
batch 180 loss: 0.0005587940569967032
batch 185 loss: 0.000558373297099024
batch 190 loss: 0.000558615755289793
batch 195 loss: 0.0005584488273598254
batch 200 loss: 0.0005583476857282221
batch 205 loss: 0.0005582789308391511
batch 210 loss: 0.00055814542574808
batch 215 loss: 0.0005584544967859983
batch 220 loss: 0.0005583814112469554
batch 225 loss: 0.0005583744961768389
batch 230 loss: 0.0005581654841080308
batch 235 loss: 0.0005582387326285243
batch 240 loss: 0.000558067497331649
Training Loss: 0.0005589651108797018
Validation Loss: 0.0005576934190078948
Epoch 21:
batch 5 loss: 0.0005583426216617226
batch 10 loss: 0.0005581693374551832
batch 15 loss: 0.0005580844241194427
batch 20 loss: 0.0005581063451245427
batch 25 loss: 0.0005582368467003107
batch 30 loss: 0.0005582924000918865
batch 35 loss: 0.000558260502293706
batch 40 loss: 0.0005582020850852132
batch 45 loss: 0.0005583435064181686
batch 50 loss: 0.0005581627716310323
batch 55 loss: 0.0005582162295468152
batch 60 loss: 0.0005581780569627881
batch 65 loss: 0.0005582081037573516
batch 70 loss: 0.0005581866367720068
batch 75 loss: 0.0005581752397119999
batch 80 loss: 0.0005583021091297268
batch 85 loss: 0.0005579967168159783
batch 90 loss: 0.0005581748089753091
batch 95 loss: 0.0005580600467510521
batch 100 loss: 0.0005583311896771193
batch 105 loss: 0.0005583357764407992
batch 110 loss: 0.000558058253955096
batch 115 loss: 0.0005580052849836648
batch 120 loss: 0.0005579870427027345
batch 125 loss: 0.0005580847384408117
batch 130 loss: 0.000558242725674063
batch 135 loss: 0.0005580390570685267
batch 140 loss: 0.0005580859957262874
batch 145 loss: 0.0005581103498116136
batch 150 loss: 0.0005579985328949988
batch 155 loss: 0.0005578919779509306
batch 160 loss: 0.0005579359130933881
batch 165 loss: 0.0005579908727668225
batch 170 loss: 0.0005579131888225674
batch 175 loss: 0.0005581466597504914
batch 180 loss: 0.0005579880205914378
batch 185 loss: 0.0005580656463280321
batch 190 loss: 0.0005578943411819637
batch 195 loss: 0.0005579189048148692
batch 200 loss: 0.0005579560296609998
batch 205 loss: 0.000558224820997566
batch 210 loss: 0.0005579891032539309
batch 215 loss: 0.0005580475903116166
batch 220 loss: 0.0005581846460700035
batch 225 loss: 0.0005580123048275709
batch 230 loss: 0.0005582457291893661
batch 235 loss: 0.0005579509306699038
batch 240 loss: 0.0005579481017775834
Training Loss: 0.000558110052467479
Validation Loss: 0.0005576940059351424
Epoch 22:
batch 5 loss: 0.0005579822463914752
batch 10 loss: 0.0005578973446972668
batch 15 loss: 0.0005579251563176512
batch 20 loss: 0.000558090431150049
batch 25 loss: 0.0005581063684076071
batch 30 loss: 0.0005578514654189348
batch 35 loss: 0.000557870848570019
batch 40 loss: 0.0005578882293775678
batch 45 loss: 0.0005578686599619686
batch 50 loss: 0.0005578301032073795
batch 55 loss: 0.0005578434211201966
batch 60 loss: 0.0005581610021181405
batch 65 loss: 0.0005579914315603674
batch 70 loss: 0.0005580040044151247
batch 75 loss: 0.0005580518394708633
batch 80 loss: 0.0005579995573498309
batch 85 loss: 0.0005580430151894689
batch 90 loss: 0.0005578426411375403
batch 95 loss: 0.0005580616067163646
batch 100 loss: 0.0005579165299423039
batch 105 loss: 0.0005579483462497592
batch 110 loss: 0.0005581265431828797
batch 115 loss: 0.00055788136087358
batch 120 loss: 0.0005580845172517002
batch 125 loss: 0.0005580772296525538
batch 130 loss: 0.0005580875556915998
batch 135 loss: 0.0005578586249612271
batch 140 loss: 0.0005578980082646013
batch 145 loss: 0.0005579720484092832
batch 150 loss: 0.0005579506047070027
batch 155 loss: 0.0005579353542998433
batch 160 loss: 0.0005579727701842784
batch 165 loss: 0.0005577107542194426
batch 170 loss: 0.000557803362607956
batch 175 loss: 0.0005577642587013543
batch 180 loss: 0.000557861162815243
batch 185 loss: 0.0005578832002356649
batch 190 loss: 0.0005578123382292688
batch 195 loss: 0.0005578943178988993
batch 200 loss: 0.0005578335491009057
batch 205 loss: 0.000557974900584668
batch 210 loss: 0.0005577606149017811
batch 215 loss: 0.0005577742820605635
batch 220 loss: 0.000557773734908551
batch 225 loss: 0.0005576588795520365
batch 230 loss: 0.000557770172599703
batch 235 loss: 0.0005578274722211063
batch 240 loss: 0.000557786610443145
Training Loss: 0.0005579147599443483
Validation Loss: 0.0005576934005754689
Epoch 23:
batch 5 loss: 0.0005577143165282905
batch 10 loss: 0.0005577442119829356
batch 15 loss: 0.0005577902542427182
batch 20 loss: 0.0005576927098445595
batch 25 loss: 0.0005577959935180842
batch 30 loss: 0.0005577301606535911
batch 35 loss: 0.0005577038507908582
batch 40 loss: 0.0005579844233579934
batch 45 loss: 0.0005577043979428708
batch 50 loss: 0.0005577565752901137
batch 55 loss: 0.0005578591371886432
batch 60 loss: 0.0005578122683800757
batch 65 loss: 0.0005578826298005879
batch 70 loss: 0.0005578846903517842
batch 75 loss: 0.0005577849107794464
batch 80 loss: 0.0005577451549470425
batch 85 loss: 0.0005578190553933382
batch 90 loss: 0.0005578720127232372
batch 95 loss: 0.0005577632808126509
batch 100 loss: 0.000557916727848351
batch 105 loss: 0.0005579633289016783
batch 110 loss: 0.0005579550401307642
batch 115 loss: 0.0005580342141911388
batch 120 loss: 0.000557803432457149
batch 125 loss: 0.0005578813375905156
batch 130 loss: 0.0005576414871029556
batch 135 loss: 0.0005578198935836554
batch 140 loss: 0.0005577135947532952
batch 145 loss: 0.0005578571814112365
batch 150 loss: 0.0005578377400524914
batch 155 loss: 0.0005579342716373504
batch 160 loss: 0.0005578865646384656
batch 165 loss: 0.000557984015904367
batch 170 loss: 0.0005577844567596912
batch 175 loss: 0.0005578335141763092
batch 180 loss: 0.0005579092190600932
batch 185 loss: 0.0005578050971962511
batch 190 loss: 0.0005576895666308701
batch 195 loss: 0.0005580773926340043
batch 200 loss: 0.0005577926756814122
batch 205 loss: 0.00055785650620237
batch 210 loss: 0.0005577097064815462
batch 215 loss: 0.0005577408010140061
batch 220 loss: 0.0005578848300501704
batch 225 loss: 0.0005577318137511611
batch 230 loss: 0.0005578654468990863
batch 235 loss: 0.0005578626645728946
batch 240 loss: 0.0005577661679126323
Training Loss: 0.0005578245567448903
Validation Loss: 0.000557693464603896
Epoch 24:
batch 5 loss: 0.0005577645497396588
batch 10 loss: 0.0005577735253609716
batch 15 loss: 0.0005577339907176793
batch 20 loss: 0.0005577552947215736
batch 25 loss: 0.0005577809875831008
batch 30 loss: 0.0005578751093707979
batch 35 loss: 0.0005577369825914502
batch 40 loss: 0.0005577235831879079
batch 45 loss: 0.0005579437594860793
batch 50 loss: 0.0005578188924118876
batch 55 loss: 0.0005578399053774774
batch 60 loss: 0.0005576917319558561
batch 65 loss: 0.0005577325006015599
batch 70 loss: 0.0005577490432187915
batch 75 loss: 0.0005577632458880543
batch 80 loss: 0.000557692488655448
batch 85 loss: 0.0005577970179729164
batch 90 loss: 0.0005578921991400421
batch 95 loss: 0.0005576693802140653
batch 100 loss: 0.0005576724885031581
batch 105 loss: 0.0005576899740844965
batch 110 loss: 0.0005577062373049557
batch 115 loss: 0.0005578637705184519
batch 120 loss: 0.0005578992306254805
batch 125 loss: 0.0005577881354838609
batch 130 loss: 0.0005577922565862536
batch 135 loss: 0.0005578358774073422
batch 140 loss: 0.0005577424075454473
batch 145 loss: 0.0005578727927058935
batch 150 loss: 0.0005576781928539276
batch 155 loss: 0.0005577802890911699
batch 160 loss: 0.0005578017560765147
batch 165 loss: 0.0005577054223977029
batch 170 loss: 0.000557821081019938
batch 175 loss: 0.0005578891141340137
batch 180 loss: 0.0005576657247729599
batch 185 loss: 0.0005577450268901884
batch 190 loss: 0.000557977647986263
batch 195 loss: 0.0005578477634117007
batch 200 loss: 0.0005577384028583765
batch 205 loss: 0.0005577487405389548
batch 210 loss: 0.000557737611234188
batch 215 loss: 0.0005577918025664985
batch 220 loss: 0.0005577982985414565
batch 225 loss: 0.0005576901254244149
batch 230 loss: 0.0005577672971412539
batch 235 loss: 0.0005576466908678412
batch 240 loss: 0.0005578431650064885
Training Loss: 0.0005577764898286356
Validation Loss: 0.0005576934015455966
Epoch 25:
batch 5 loss: 0.0005577738862484694
batch 10 loss: 0.0005579476128332317
batch 15 loss: 0.0005577604402787984
batch 20 loss: 0.000557692558504641
batch 25 loss: 0.0005577239324338734
batch 30 loss: 0.0005575566319748759
batch 35 loss: 0.0005577476695179939
batch 40 loss: 0.000557672674767673
batch 45 loss: 0.0005577909643761814
batch 50 loss: 0.0005579960881732405
batch 55 loss: 0.0005577573901973665
batch 60 loss: 0.0005577793112024665
batch 65 loss: 0.0005577292758971453
batch 70 loss: 0.0005578216514550149
batch 75 loss: 0.0005577507661655545
batch 80 loss: 0.0005577207659371198
batch 85 loss: 0.0005578848882578314
batch 90 loss: 0.0005576373543590308
batch 95 loss: 0.0005577579373493791
batch 100 loss: 0.000557773991022259
batch 105 loss: 0.0005577161442488432
batch 110 loss: 0.0005579131189733744
batch 115 loss: 0.000557722442317754
batch 120 loss: 0.0005576968425884843
batch 125 loss: 0.0005577169824391604
batch 130 loss: 0.000557889009360224
batch 135 loss: 0.0005579206743277609
batch 140 loss: 0.0005577122210524976
batch 145 loss: 0.0005577390315011143
batch 150 loss: 0.0005577993346378207
batch 155 loss: 0.0005577097181230783
batch 160 loss: 0.0005578265525400638
batch 165 loss: 0.0005579023854807019
batch 170 loss: 0.0005578057374805212
batch 175 loss: 0.0005576470401138067
batch 180 loss: 0.0005577788106165826
batch 185 loss: 0.0005576890660449862
batch 190 loss: 0.0005575818475335836
batch 195 loss: 0.000557765387929976
batch 200 loss: 0.000557811395265162
batch 205 loss: 0.0005578476237133145
batch 210 loss: 0.0005579004529863596
batch 215 loss: 0.0005578236537985504
batch 220 loss: 0.0005577055620960891
batch 225 loss: 0.0005577021511271596
batch 230 loss: 0.0005577482632361352
batch 235 loss: 0.0005577921867370606
batch 240 loss: 0.0005578642012551427
Training Loss: 0.0005577709089266136
Validation Loss: 0.0005576934500519808
Epoch 26:
batch 5 loss: 0.0005578050040639937
batch 10 loss: 0.000557766086421907
batch 15 loss: 0.0005578715819865466
batch 20 loss: 0.0005577984265983105
batch 25 loss: 0.0005576489493250847
batch 30 loss: 0.0005577036179602146
batch 35 loss: 0.0005577186937443912
batch 40 loss: 0.0005576560972258449
batch 45 loss: 0.0005576902069151402
batch 50 loss: 0.000557788647711277
batch 55 loss: 0.0005577192641794682
batch 60 loss: 0.0005576488678343594
batch 65 loss: 0.0005578141426667571
batch 70 loss: 0.0005578521289862692
batch 75 loss: 0.0005577586009167135
batch 80 loss: 0.000557674653828144
batch 85 loss: 0.0005578123847953976
batch 90 loss: 0.0005576552357524633
batch 95 loss: 0.0005577912088483572
batch 100 loss: 0.0005578486830927432
batch 105 loss: 0.000557780684903264
batch 110 loss: 0.000557802664116025
batch 115 loss: 0.0005579052027314902
batch 120 loss: 0.0005576861789450049
batch 125 loss: 0.0005577047122642398
batch 130 loss: 0.0005576720228418708
batch 135 loss: 0.0005579158780165017
batch 140 loss: 0.0005577321397140622
batch 145 loss: 0.0005577882169745862
batch 150 loss: 0.0005577643401920796
batch 155 loss: 0.0005579036311246455
batch 160 loss: 0.0005577290197834372
batch 165 loss: 0.0005578288808465004
batch 170 loss: 0.0005577969131991267
batch 175 loss: 0.0005578654468990863
batch 180 loss: 0.000557738880161196
batch 185 loss: 0.0005579076241701841
batch 190 loss: 0.000557716644834727
batch 195 loss: 0.0005577407078817487
batch 200 loss: 0.0005577263189479708
batch 205 loss: 0.0005576741183176637
batch 210 loss: 0.0005577496136538685
batch 215 loss: 0.0005577815813012421
batch 220 loss: 0.0005577283794991672
batch 225 loss: 0.0005576319876126945
batch 230 loss: 0.0005578787298873067
batch 235 loss: 0.0005577778676524759
batch 240 loss: 0.0005577214527875185
Training Loss: 0.0005577640067106888
Validation Loss: 0.0005576934015455966
Epoch 27:
batch 5 loss: 0.0005577520234510303
batch 10 loss: 0.0005577624076977372
batch 15 loss: 0.0005577834090217948
batch 20 loss: 0.0005577734089456498
batch 25 loss: 0.0005577466450631619
batch 30 loss: 0.000557714095339179
batch 35 loss: 0.0005576383788138628
batch 40 loss: 0.0005577968899160623
batch 45 loss: 0.0005576257477514446
batch 50 loss: 0.0005577587522566319
batch 55 loss: 0.0005577918142080307
batch 60 loss: 0.0005577101139351726
batch 65 loss: 0.0005578320939093828
batch 70 loss: 0.0005577329779043793
batch 75 loss: 0.0005577404983341694
batch 80 loss: 0.0005578594864346087
batch 85 loss: 0.0005577860749326647
batch 90 loss: 0.0005577363190241158
batch 95 loss: 0.0005577145610004663
batch 100 loss: 0.0005578732583671808
batch 105 loss: 0.0005578407552093267
batch 110 loss: 0.000557664968073368
batch 115 loss: 0.0005577233387157321
batch 120 loss: 0.000557730020955205
batch 125 loss: 0.0005577647010795772
batch 130 loss: 0.0005576061783358454
batch 135 loss: 0.0005579322460107505
batch 140 loss: 0.0005577883566729724
batch 145 loss: 0.0005577500676736235
batch 150 loss: 0.0005576813011430204
batch 155 loss: 0.0005577598349191248
batch 160 loss: 0.0005578308599069714
batch 165 loss: 0.000557840138208121
batch 170 loss: 0.0005577817675657571
batch 175 loss: 0.0005578007898293435
batch 180 loss: 0.0005577236763201654
batch 185 loss: 0.0005578068201430141
batch 190 loss: 0.0005576980765908957
batch 195 loss: 0.0005583603167906403
batch 200 loss: 0.0005579399759881199
batch 205 loss: 0.0005577953881584108
batch 210 loss: 0.0005579287651926279
batch 215 loss: 0.0005577781703323126
batch 220 loss: 0.0005581211298704147
batch 225 loss: 0.0005580989178270102
batch 230 loss: 0.0005578710464760661
batch 235 loss: 0.0005579494638368488
batch 240 loss: 0.0005577448406256736
Training Loss: 0.0005578008514324514
Validation Loss: 0.0005576934743051728
Epoch 28:
batch 5 loss: 0.0005577135249041021
batch 10 loss: 0.0005578852375037968
batch 15 loss: 0.0005577669129706919
batch 20 loss: 0.0005577429663389921
batch 25 loss: 0.0005577427800744772
batch 30 loss: 0.0005579268909059465
batch 35 loss: 0.0005578929209150374
batch 40 loss: 0.000557834014762193
batch 45 loss: 0.0005579221993684769
batch 50 loss: 0.0005576637689955532
batch 55 loss: 0.0005576416850090026
batch 60 loss: 0.0005578411044552922
batch 65 loss: 0.0005577464238740504
batch 70 loss: 0.0005577857373282313
batch 75 loss: 0.0005577153875492513
batch 80 loss: 0.0005578849581070244
batch 85 loss: 0.0005577922216616571
batch 90 loss: 0.0005577089264988899
batch 95 loss: 0.0005577484262175858
batch 100 loss: 0.0005577835370786488
batch 105 loss: 0.0005578962271101772
batch 110 loss: 0.0005578023032285273
batch 115 loss: 0.000557823316194117
batch 120 loss: 0.0005577846895903349
batch 125 loss: 0.0005576490657404065
batch 130 loss: 0.0005577619303949177
batch 135 loss: 0.0005576851428486407
batch 140 loss: 0.0005575900431722403
batch 145 loss: 0.0005577631178312004
batch 150 loss: 0.0005579121760092675
batch 155 loss: 0.0005576522322371602
batch 160 loss: 0.0005577000440098346
batch 165 loss: 0.0005578856682404876
batch 170 loss: 0.0005577800795435906
batch 175 loss: 0.0005576741416007281
batch 180 loss: 0.0005576933384872973
batch 185 loss: 0.0005578738870099187
batch 190 loss: 0.000557750032749027
batch 195 loss: 0.0005578378215432167
batch 200 loss: 0.0005576794967055321
batch 205 loss: 0.0005576973780989647
batch 210 loss: 0.0005578450742177665
batch 215 loss: 0.0005579127697274089
batch 220 loss: 0.000557798775844276
batch 225 loss: 0.0005577695788815618
batch 230 loss: 0.0005578201380558312
batch 235 loss: 0.0005576201947405934
batch 240 loss: 0.000557766342535615
Training Loss: 0.0005577742631430738
Validation Loss: 0.0005576934190078948
Epoch 29:
batch 5 loss: 0.0005577278789132833
batch 10 loss: 0.0005577461794018746
batch 15 loss: 0.0005577919306233525
batch 20 loss: 0.0005579244578257203
batch 25 loss: 0.0005576868657954037
batch 30 loss: 0.000557757739443332
batch 35 loss: 0.0005578012787736952
batch 40 loss: 0.0005577364237979055
batch 45 loss: 0.0005577557021752
batch 50 loss: 0.0005577771225944161
batch 55 loss: 0.0005577945848926902
batch 60 loss: 0.0005577720468863845
batch 65 loss: 0.0005579731543548406
batch 70 loss: 0.0005578341078944504
batch 75 loss: 0.0005577107775025069
batch 80 loss: 0.0005578057141974568
batch 85 loss: 0.0005577952251769602
batch 90 loss: 0.0005576309282332659
batch 95 loss: 0.0005577493691816926
batch 100 loss: 0.0005577153759077191
batch 105 loss: 0.0005576683557592333
batch 110 loss: 0.0005577999167144298
batch 115 loss: 0.0005577229661867022
batch 120 loss: 0.0005577242234721779
batch 125 loss: 0.0005577260861173272
batch 130 loss: 0.0005577165982685983
batch 135 loss: 0.0005577848758548498
batch 140 loss: 0.0005576871102675795
batch 145 loss: 0.0005576991941779851
batch 150 loss: 0.000557637051679194
batch 155 loss: 0.0005576244788244366
batch 160 loss: 0.00055773442145437
batch 165 loss: 0.0005577551550231874
batch 170 loss: 0.0005577041185460985
batch 175 loss: 0.0005577463773079217
batch 180 loss: 0.0005576899158768356
batch 185 loss: 0.0005576628143899142
batch 190 loss: 0.0005577472038567066
batch 195 loss: 0.0005577638046815991
batch 200 loss: 0.0005576661904342472
batch 205 loss: 0.000557811395265162
batch 210 loss: 0.0005576828494668007
batch 215 loss: 0.0005578465643338859
batch 220 loss: 0.0005577664007432759
batch 225 loss: 0.0005577480304054915
batch 230 loss: 0.0005576595780439675
batch 235 loss: 0.0005577133619226515
batch 240 loss: 0.0005576429422944785
Training Loss: 0.0005577420592696096
Validation Loss: 0.0005576934131871288
Epoch 30:
batch 5 loss: 0.0005578191368840635
batch 10 loss: 0.0005577593110501766
batch 15 loss: 0.0005576795432716608
batch 20 loss: 0.0005575967719778418
batch 25 loss: 0.0005576852941885591
batch 30 loss: 0.0005577953765168786
batch 35 loss: 0.0005576851544901729
batch 40 loss: 0.0005577834439463913
batch 45 loss: 0.0005577053525485098
batch 50 loss: 0.0005576841067522764
batch 55 loss: 0.0005577846080996096
batch 60 loss: 0.0005577073781751097
batch 65 loss: 0.0005578064941801131
batch 70 loss: 0.0005576998693868518
batch 75 loss: 0.0005577173666097224
batch 80 loss: 0.0005578016047365963
batch 85 loss: 0.0005575975868850946
batch 90 loss: 0.0005578337470069528
batch 95 loss: 0.0005578737240284681
batch 100 loss: 0.0005581628880463541
batch 105 loss: 0.0005584346363320947
batch 110 loss: 0.0005580733064562083
batch 115 loss: 0.0005576764466241002
batch 120 loss: 0.0005577282630838454
batch 125 loss: 0.0005577512201853096
batch 130 loss: 0.0005578225944191217
batch 135 loss: 0.0005576340365223587
batch 140 loss: 0.0005577167379669845
batch 145 loss: 0.0005575951538048685
batch 150 loss: 0.0005577338626608253
batch 155 loss: 0.0005576700321398675
batch 160 loss: 0.0005576621973887086
batch 165 loss: 0.0005576678435318172
batch 170 loss: 0.0005576150259003043
batch 175 loss: 0.000557607423979789
batch 180 loss: 0.0005576302297413349
batch 185 loss: 0.000557846890296787
batch 190 loss: 0.0005576647468842566
batch 195 loss: 0.0005576805444434286
batch 200 loss: 0.0005577700794674456
batch 205 loss: 0.000557640683837235
batch 210 loss: 0.0005577229312621057
batch 215 loss: 0.0005576457595452666
batch 220 loss: 0.0005577711155638099
batch 225 loss: 0.0005576994153670967
batch 230 loss: 0.0005576549796387553
batch 235 loss: 0.00055764903081581
batch 240 loss: 0.0005577440024353564
Training Loss: 0.0005577434989390895
Validation Loss: 0.0005576934219182779
Epoch 31:
batch 5 loss: 0.0005577860865741968
batch 10 loss: 0.0005576544906944036
batch 15 loss: 0.0005577996489591897
batch 20 loss: 0.0005577457486651838
batch 25 loss: 0.0005577230942435563
batch 30 loss: 0.0005577019415795803
batch 35 loss: 0.0005576526047661901
batch 40 loss: 0.0005577487288974225
batch 45 loss: 0.0005575977498665452
batch 50 loss: 0.0005576518247835338
batch 55 loss: 0.0005576976109296083
batch 60 loss: 0.0005576546187512577
batch 65 loss: 0.0005576306022703648
batch 70 loss: 0.0005576708819717169
batch 75 loss: 0.0005577656324021518
batch 80 loss: 0.0005576231633313
batch 85 loss: 0.0005577339441515505
batch 90 loss: 0.0005577562260441482
batch 95 loss: 0.0005577434320002794
batch 100 loss: 0.0005576450494118035
batch 105 loss: 0.0005576157360337675
batch 110 loss: 0.0005576433963142335
batch 115 loss: 0.0005577455507591367
batch 120 loss: 0.0005576644674874842
batch 125 loss: 0.0005575883667916059
batch 130 loss: 0.0005576751078478992
batch 135 loss: 0.0005576668190769851
batch 140 loss: 0.0005578009178861976
batch 145 loss: 0.0005577564239501953
batch 150 loss: 0.0005577834905125201
batch 155 loss: 0.0005577327799983322
batch 160 loss: 0.0005576689611189068
batch 165 loss: 0.0005576991708949209
batch 170 loss: 0.0005577593576163054
batch 175 loss: 0.0005577663774602115
batch 180 loss: 0.0005577522097155452
batch 185 loss: 0.0005578839220106602
batch 190 loss: 0.0005577595438808203
batch 195 loss: 0.0005577138392254711
batch 200 loss: 0.0005577148986048996
batch 205 loss: 0.0005577642936259508
batch 210 loss: 0.0005576529307290912
batch 215 loss: 0.0005576389841735363
batch 220 loss: 0.0005577012780122459
batch 225 loss: 0.0005576738039962947
batch 230 loss: 0.0005576671450398862
batch 235 loss: 0.0005575891700573266
batch 240 loss: 0.0005577874951995909
Training Loss: 0.0005577051982982084
Validation Loss: 0.0005576934044559796
Epoch 32:
batch 5 loss: 0.0005577375879511238
batch 10 loss: 0.0005577225703746081
batch 15 loss: 0.0005577333620749414
batch 20 loss: 0.0005577655974775553
batch 25 loss: 0.0005577644449658691
batch 30 loss: 0.0005576448631472886
batch 35 loss: 0.0005575979128479957
batch 40 loss: 0.0005577730014920234
batch 45 loss: 0.0005576776340603829
batch 50 loss: 0.000557621254120022
batch 55 loss: 0.0005577308125793934
batch 60 loss: 0.0005576521507464349
batch 65 loss: 0.0005576921394094825
batch 70 loss: 0.0005577296018600464
batch 75 loss: 0.0005576628958806395
batch 80 loss: 0.0005576065857894718
batch 85 loss: 0.0005577564472332597
batch 90 loss: 0.0005577062489464879
batch 95 loss: 0.0005577026749961078
batch 100 loss: 0.0005577165167778731
batch 105 loss: 0.0005577260395511985
batch 110 loss: 0.0005575438844971359
batch 115 loss: 0.0005575814982876181
batch 120 loss: 0.0005576655501499772
batch 125 loss: 0.0005575897987000645
batch 130 loss: 0.0005576524650678039
batch 135 loss: 0.000557690067216754
batch 140 loss: 0.0005577019997872412
batch 145 loss: 0.0005577385541982949
batch 150 loss: 0.0005577559815719724
batch 155 loss: 0.0005577249918133021
batch 160 loss: 0.0005577454343438148
batch 165 loss: 0.0005577959935180842
batch 170 loss: 0.0005578325130045414
batch 175 loss: 0.0005577634670771659
batch 180 loss: 0.0005577288451604545
batch 185 loss: 0.00055766929872334
batch 190 loss: 0.0005576509633101523
batch 195 loss: 0.0005576791474595666
batch 200 loss: 0.0005576993688009679
batch 205 loss: 0.0005577216972596944
batch 210 loss: 0.0005576415918767452
batch 215 loss: 0.0005577320698648691
batch 220 loss: 0.0005576512077823282
batch 225 loss: 0.0005576860043220222
batch 230 loss: 0.0005577535484917462
batch 235 loss: 0.0005576714873313903
batch 240 loss: 0.000557697203475982
Training Loss: 0.0005576976036536507
Validation Loss: 0.0005576934112468734
Epoch 33:
batch 5 loss: 0.0005577141768299043
batch 10 loss: 0.0005576959694735706
batch 15 loss: 0.0005576034891419113
batch 20 loss: 0.0005576618830673396
batch 25 loss: 0.0005576979834586382
batch 30 loss: 0.0005575387855060399
batch 35 loss: 0.000557650881819427
batch 40 loss: 0.0005576856201514602
batch 45 loss: 0.0005578033393248916
batch 50 loss: 0.0005577005562372505
batch 55 loss: 0.0005576709052547812
batch 60 loss: 0.0005575444432906806
batch 65 loss: 0.000557684397790581
batch 70 loss: 0.0005576678435318172
batch 75 loss: 0.0005576487979851663
batch 80 loss: 0.000557708682026714
batch 85 loss: 0.0005576073192059994
batch 90 loss: 0.0005577005445957184
batch 95 loss: 0.0005577835720032454
batch 100 loss: 0.0005576855153776705
batch 105 loss: 0.0005577396834269166
batch 110 loss: 0.0005577976582571865
batch 115 loss: 0.0005576143739745021
batch 120 loss: 0.0005577227217145264
batch 125 loss: 0.0005577789153903723
batch 130 loss: 0.0005575673654675484
batch 135 loss: 0.000557741813827306
batch 140 loss: 0.000557761627715081
batch 145 loss: 0.0005576922674663364
batch 150 loss: 0.0005577594507485628
batch 155 loss: 0.0005576784955337643
batch 160 loss: 0.0005576880066655576
batch 165 loss: 0.0005577688571065664
batch 170 loss: 0.0005577184958383441
batch 175 loss: 0.0005576970987021923
batch 180 loss: 0.0005576527444645762
batch 185 loss: 0.0005577377625741065
batch 190 loss: 0.0005577501025982202
batch 195 loss: 0.0005577152129262686
batch 200 loss: 0.0005576608586125076
batch 205 loss: 0.0005577133037149906
batch 210 loss: 0.0005577450385317207
batch 215 loss: 0.0005576608120463789
batch 220 loss: 0.0005577507195994258
batch 225 loss: 0.0005577277508564294
batch 230 loss: 0.0005577326402999461
batch 235 loss: 0.0005577094852924347
batch 240 loss: 0.0005576174124144017
Training Loss: 0.0005576949037883121
Validation Loss: 0.000557693403485852
Epoch 34:
batch 5 loss: 0.0005577200092375279
batch 10 loss: 0.000557749264407903
batch 15 loss: 0.0005577230011112988
batch 20 loss: 0.0005575513583607972
batch 25 loss: 0.0005576933268457651
batch 30 loss: 0.0005578473093919456
batch 35 loss: 0.0005576682393439114
batch 40 loss: 0.0005576250841841102
batch 45 loss: 0.0005578276701271534
batch 50 loss: 0.0005576464696787298
batch 55 loss: 0.000557655212469399
batch 60 loss: 0.000557677773758769
batch 65 loss: 0.0005577522679232061
batch 70 loss: 0.0005577222444117069
batch 75 loss: 0.0005576289491727948
batch 80 loss: 0.0005577887408435344
batch 85 loss: 0.0005576140130870045
batch 90 loss: 0.0005576946772634983
batch 95 loss: 0.0005575995659455657
batch 100 loss: 0.0005576686700806022
batch 105 loss: 0.0005577286472544074
batch 110 loss: 0.0005575978779233992
batch 115 loss: 0.0005577772855758667
batch 120 loss: 0.0005578021751716733
batch 125 loss: 0.0005576470051892102
batch 130 loss: 0.0005576545721851289
batch 135 loss: 0.0005576354800723493
batch 140 loss: 0.000557628006208688
batch 145 loss: 0.0005576495546847582
batch 150 loss: 0.0005577154224738479
batch 155 loss: 0.0005576966446824372
batch 160 loss: 0.0005577059811912477
batch 165 loss: 0.0005575990304350853
batch 170 loss: 0.0005577972857281566
batch 175 loss: 0.0005577011033892632
batch 180 loss: 0.0005575966322794556
batch 185 loss: 0.0005576834082603455
batch 190 loss: 0.0005577541538514197
batch 195 loss: 0.000557652476709336
batch 200 loss: 0.0005576246767304838
batch 205 loss: 0.00055781229166314
batch 210 loss: 0.0005577343283221126
batch 215 loss: 0.0005576798226684332
batch 220 loss: 0.0005576447350904345
batch 225 loss: 0.0005576651659794152
batch 230 loss: 0.0005576325813308359
batch 235 loss: 0.0005577747244387866
batch 240 loss: 0.0005577083677053452
Training Loss: 0.0005576906934341726
Validation Loss: 0.0005576934141572565
Epoch 35:
batch 5 loss: 0.0005576908704824745
batch 10 loss: 0.000557713897433132
batch 15 loss: 0.0005577140138484538
batch 20 loss: 0.0005577124422416091
batch 25 loss: 0.000557686504907906
batch 30 loss: 0.0005576176918111742
batch 35 loss: 0.0005577154923230409
batch 40 loss: 0.0005576943513005972
batch 45 loss: 0.0005576770403422415
batch 50 loss: 0.0005577264935709536
batch 55 loss: 0.0005576671101152897
batch 60 loss: 0.0005577410920523107
batch 65 loss: 0.0005576418014243245
batch 70 loss: 0.000557664583902806
batch 75 loss: 0.0005576870986260474
batch 80 loss: 0.0005577522679232061
batch 85 loss: 0.0005577807198278606
batch 90 loss: 0.0005577006726525724
batch 95 loss: 0.0005576076568104327
batch 100 loss: 0.0005576294148340821
batch 105 loss: 0.0005577547010034323
batch 110 loss: 0.0005577140487730503
batch 115 loss: 0.0005576875759288668
batch 120 loss: 0.0005577344563789666
batch 125 loss: 0.0005576633615419268
batch 130 loss: 0.0005576725699938834
batch 135 loss: 0.0005576752009801567
batch 140 loss: 0.000557689112611115
batch 145 loss: 0.0005577212083153427
batch 150 loss: 0.0005576135939918458
batch 155 loss: 0.0005576483439654112
batch 160 loss: 0.00055771607439965
batch 165 loss: 0.0005576263531111181
batch 170 loss: 0.0005576928495429456
batch 175 loss: 0.0005575892748311162
batch 180 loss: 0.0005576960509642958
batch 185 loss: 0.000557604234199971
batch 190 loss: 0.0005576902185566723
batch 195 loss: 0.0005577024887315929
batch 200 loss: 0.0005575621500611306
batch 205 loss: 0.0005577566334977746
batch 210 loss: 0.000557684525847435
batch 215 loss: 0.0005575934192165732
batch 220 loss: 0.0005576447234489024
batch 225 loss: 0.0005577429896220565
batch 230 loss: 0.000557837204542011
batch 235 loss: 0.0005576896248385311
batch 240 loss: 0.000557671021670103
Training Loss: 0.0005576853172290914
Validation Loss: 0.0005576933918443199
Epoch 36:
batch 5 loss: 0.0005576828029006719
batch 10 loss: 0.000557625200599432
batch 15 loss: 0.0005577125819399952
batch 20 loss: 0.0005577104631811381
batch 25 loss: 0.0005576136754825711
batch 30 loss: 0.0005577834206633269
batch 35 loss: 0.0005577338044531644
batch 40 loss: 0.0005576365627348423
batch 45 loss: 0.0005578423733823001
batch 50 loss: 0.000557692360598594
batch 55 loss: 0.0005576728261075913
batch 60 loss: 0.0005577520350925624
batch 65 loss: 0.000557697971817106
batch 70 loss: 0.0005577174364589155
batch 75 loss: 0.0005575677962042392
batch 80 loss: 0.0005576803698204458
batch 85 loss: 0.0005577171803452074
batch 90 loss: 0.0005577876465395093
batch 95 loss: 0.0005575636285357177
batch 100 loss: 0.0005577250034548342
batch 105 loss: 0.0005575566436164081
batch 110 loss: 0.0005576253985054791
batch 115 loss: 0.0005577130010351539
batch 120 loss: 0.0005576256196945905
batch 125 loss: 0.0005576900439336896
batch 130 loss: 0.0005576748517341912
batch 135 loss: 0.0005577346193604172
batch 140 loss: 0.0005576345953159034
batch 145 loss: 0.0005576093681156635
batch 150 loss: 0.0005575699382461607
batch 155 loss: 0.0005576902884058654
batch 160 loss: 0.0005576826282776892
batch 165 loss: 0.0005578254815191031
batch 170 loss: 0.0005576728843152523
batch 175 loss: 0.0005576923140324652
batch 180 loss: 0.0005576875177212059
batch 185 loss: 0.0005577435600571335
batch 190 loss: 0.0005576944095082581
batch 195 loss: 0.000557787180878222
batch 200 loss: 0.0005576416035182775
batch 205 loss: 0.0005577250733040274
batch 210 loss: 0.0005577346077188849
batch 215 loss: 0.0005575231509283185
batch 220 loss: 0.0005577057017944753
batch 225 loss: 0.0005577549454756081
batch 230 loss: 0.0005577179254032671
batch 235 loss: 0.0005576740368269384
batch 240 loss: 0.0005577332223765552
Training Loss: 0.0005576882448319035
Validation Loss: 0.0005576933860235537
Epoch 37:
batch 5 loss: 0.0005577014409936965
batch 10 loss: 0.0005577617674134671
batch 15 loss: 0.0005577953881584108
batch 20 loss: 0.0005577962030656636
batch 25 loss: 0.0005577145959250629
batch 30 loss: 0.0005576762487180531
batch 35 loss: 0.0005577064934186637
batch 40 loss: 0.0005576867144554854
batch 45 loss: 0.0005576360505074263
batch 50 loss: 0.0005576664698310196
batch 55 loss: 0.0005577807081863284
batch 60 loss: 0.0005577156320214271
batch 65 loss: 0.0005575675866566598
batch 70 loss: 0.0005577182630077005
batch 75 loss: 0.0005577374831773341
batch 80 loss: 0.0005577309057116508
batch 85 loss: 0.0005576034542173147
batch 90 loss: 0.0005577311967499554
batch 95 loss: 0.0005577021976932884
batch 100 loss: 0.0005577032337896526
batch 105 loss: 0.0005575884249992668
batch 110 loss: 0.0005577048286795616
batch 115 loss: 0.0005576450028456747
batch 120 loss: 0.0005575278191827238
batch 125 loss: 0.0005577204166911543
batch 130 loss: 0.0005577052594162524
batch 135 loss: 0.00055766177829355
batch 140 loss: 0.0005577184725552798
batch 145 loss: 0.0005575661547482013
batch 150 loss: 0.0005576212191954255
batch 155 loss: 0.0005577606614679098
batch 160 loss: 0.0005576542229391634
batch 165 loss: 0.0005577241769060493
batch 170 loss: 0.0005578074953518808
batch 175 loss: 0.0005577175528742373
batch 180 loss: 0.0005576758412644267
batch 185 loss: 0.0005576784838922322
batch 190 loss: 0.0005576177150942385
batch 195 loss: 0.000557706318795681
batch 200 loss: 0.0005577583913691341
batch 205 loss: 0.0005575896822847426
batch 210 loss: 0.0005576751660555601
batch 215 loss: 0.0005576890311203897
batch 220 loss: 0.0005577263655140996
batch 225 loss: 0.0005576424999162554
batch 230 loss: 0.0005577085074037313
batch 235 loss: 0.0005576782976277172
batch 240 loss: 0.0005577079369686544
Training Loss: 0.000557689786607322
Validation Loss: 0.0005576934141572565
Epoch 38:
batch 5 loss: 0.0005578427226282656
batch 10 loss: 0.0005577150965109468
batch 15 loss: 0.0005577548057772219
batch 20 loss: 0.0005576716735959053
batch 25 loss: 0.0005577472038567066
batch 30 loss: 0.0005576060153543949
batch 35 loss: 0.0005577613599598407
batch 40 loss: 0.0005577724776230752
batch 45 loss: 0.0005577777163125574
batch 50 loss: 0.0005576213938184082
batch 55 loss: 0.0005577073898166418
batch 60 loss: 0.0005577420466579497
batch 65 loss: 0.0005577544914558529
batch 70 loss: 0.0005576677387580276
batch 75 loss: 0.0005576311028562486
batch 80 loss: 0.0005577619886025786
batch 85 loss: 0.0005575629533268511
batch 90 loss: 0.0005574807524681092
batch 95 loss: 0.0005574759445153177
batch 100 loss: 0.000557674653828144
batch 105 loss: 0.0005577377160079777
batch 110 loss: 0.0005577425588853657
batch 115 loss: 0.0005576506140641868
batch 120 loss: 0.0005576158873736858
batch 125 loss: 0.0005577152944169939
batch 130 loss: 0.0005575288436375558
batch 135 loss: 0.0005576584953814745
batch 140 loss: 0.0005575983319431544
batch 145 loss: 0.0005573518457822502
batch 150 loss: 0.0005574614740908145
batch 155 loss: 0.0005576272495090961
batch 160 loss: 0.000557615514844656
batch 165 loss: 0.0005576628842391074
batch 170 loss: 0.0005578047595918179
batch 175 loss: 0.0005576325580477715
batch 180 loss: 0.0005577466334216296
batch 185 loss: 0.0005577806732617319
batch 190 loss: 0.0005576268304139376
batch 195 loss: 0.000557675922755152
batch 200 loss: 0.0005576853640377521
batch 205 loss: 0.0005576352472417056
batch 210 loss: 0.0005574038717895746
batch 215 loss: 0.0005575335584580898
batch 220 loss: 0.0005575463175773621
batch 225 loss: 0.0005573934526182711
batch 230 loss: 0.000557581556495279
batch 235 loss: 0.0005575102171860635
batch 240 loss: 0.0005574761889874935
Training Loss: 0.0005576401956204791
Validation Loss: 0.0005574364321849619
Epoch 39:
batch 5 loss: 0.0005575005663558841
batch 10 loss: 0.0005573731265030802
batch 15 loss: 0.0005572885740548373
batch 20 loss: 0.000557129830121994
batch 25 loss: 0.0005567320273257792
batch 30 loss: 0.0005566267762333154
batch 35 loss: 0.0005565451225265861
batch 40 loss: 0.0005563595565035939
batch 45 loss: 0.0005560623598285019
batch 50 loss: 0.0005556585732847452
batch 55 loss: 0.0005551069159992039
batch 60 loss: 0.00055486363125965
batch 65 loss: 0.0005548291723243892
batch 70 loss: 0.0005547838169150055
batch 75 loss: 0.0005543791339732707
batch 80 loss: 0.0005560946301557124
batch 85 loss: 0.0005549662513658404
batch 90 loss: 0.0005543998442590237
batch 95 loss: 0.0005541542312130332
batch 100 loss: 0.0005533667397685349
batch 105 loss: 0.0005535333417356014
batch 110 loss: 0.0005529553862288594
batch 115 loss: 0.0005529872723855078
batch 120 loss: 0.0005528504843823612
batch 125 loss: 0.0005525117041543127
batch 130 loss: 0.0005527390982024372
batch 135 loss: 0.0005527103203348815
batch 140 loss: 0.0005526604829356075
batch 145 loss: 0.000552103342488408
batch 150 loss: 0.0005512741976417601
batch 155 loss: 0.0005512157455086708
batch 160 loss: 0.0005516596254892647
batch 165 loss: 0.0005514896474778652
batch 170 loss: 0.0005503144580870867
batch 175 loss: 0.000550084002315998
batch 180 loss: 0.0005497585050761699
batch 185 loss: 0.0005493322503753006
batch 190 loss: 0.0005487157381139695
batch 195 loss: 0.0005484111490659416
batch 200 loss: 0.0005488445167429745
batch 205 loss: 0.0005485971225425601
batch 210 loss: 0.0005478309700265527
batch 215 loss: 0.0005470717325806618
batch 220 loss: 0.000545711861923337
batch 225 loss: 0.000546294660307467
batch 230 loss: 0.0005456681014038622
batch 235 loss: 0.000545907742343843
batch 240 loss: 0.0005443959962576628
Training Loss: 0.0005523302153354355
Validation Loss: 0.0005394244779987882
Epoch 40:
batch 5 loss: 0.0005439469823613763
batch 10 loss: 0.0005439395434223115
batch 15 loss: 0.000541685929056257
batch 20 loss: 0.0005391850019805134
batch 25 loss: 0.0005380722228437662
batch 30 loss: 0.0005361129529774189
batch 35 loss: 0.0005335562862455844
batch 40 loss: 0.000537897611502558
batch 45 loss: 0.0005356660345569253
batch 50 loss: 0.0005340677336789668
batch 55 loss: 0.0005325450911186635
batch 60 loss: 0.0005312886321917176
batch 65 loss: 0.0005284951417706907
batch 70 loss: 0.0005300573189742863
batch 75 loss: 0.0005564948660321534
batch 80 loss: 0.0005572056747041642
batch 85 loss: 0.0005573534406721592
batch 90 loss: 0.0005572106689214707
batch 95 loss: 0.0005573154077865184
batch 100 loss: 0.000557009840849787
batch 105 loss: 0.0005565708270296454
batch 110 loss: 0.0005563830956816674
batch 115 loss: 0.0005564089864492416
batch 120 loss: 0.0005561796831898391
batch 125 loss: 0.0005559935350902378
batch 130 loss: 0.0005557394702918828
batch 135 loss: 0.0005555969546549022
batch 140 loss: 0.0005554511793889105
batch 145 loss: 0.0005554792587645352
batch 150 loss: 0.0005550412926822901
batch 155 loss: 0.0005552267422899604
batch 160 loss: 0.0005549816298298538
batch 165 loss: 0.0005545461550354958
batch 170 loss: 0.0005546031170524657
batch 175 loss: 0.0005542982718907297
batch 180 loss: 0.0005540802143514156
batch 185 loss: 0.0005538097699172795
batch 190 loss: 0.0005532729788683355
batch 195 loss: 0.0005532775772735477
batch 200 loss: 0.0005530108814127743
batch 205 loss: 0.0005527850473299623
batch 210 loss: 0.0005527087952941657
batch 215 loss: 0.0005524427746422589
batch 220 loss: 0.0005524336826056242
batch 225 loss: 0.0005516813136637211
batch 230 loss: 0.0005519437021575868
batch 235 loss: 0.000552100851200521
batch 240 loss: 0.0005506824934855103
Training Loss: 0.0005492882638160761
Validation Loss: 0.0005537181025526176
Epoch 41:
batch 5 loss: 0.00054859290830791
batch 10 loss: 0.0005474938312545419
batch 15 loss: 0.0005464486195705831
batch 20 loss: 0.0005451768054626882
batch 25 loss: 0.0005424608010798692
batch 30 loss: 0.000541071139741689
batch 35 loss: 0.0005386877921409905
batch 40 loss: 0.0005387238808907569
batch 45 loss: 0.0005384098622016609
batch 50 loss: 0.0005375828361138702
batch 55 loss: 0.0005341296782717109
batch 60 loss: 0.0005349981249310077
batch 65 loss: 0.0005331958294846117
batch 70 loss: 0.0005317556206136942
batch 75 loss: 0.0005319059826433658
batch 80 loss: 0.0005306281731463969
batch 85 loss: 0.0005292998510412871
batch 90 loss: 0.0005288528394885361
batch 95 loss: 0.0005300257820636034
batch 100 loss: 0.0005299040116369724
batch 105 loss: 0.0005292730056680739
batch 110 loss: 0.0005293971975333988
batch 115 loss: 0.0005291868932545185
batch 120 loss: 0.0005284786573611199
batch 125 loss: 0.0005261618178337812
batch 130 loss: 0.0005265878280624747
batch 135 loss: 0.0005263691302388907
batch 140 loss: 0.0005266078747808933
batch 145 loss: 0.0005258290213532746
batch 150 loss: 0.0005261085345409811
batch 155 loss: 0.0005264478619210422
batch 160 loss: 0.0005232601659372448
batch 165 loss: 0.0005255069001577795
batch 170 loss: 0.0005266993772238493
batch 175 loss: 0.0005241344566456974
batch 180 loss: 0.0005233716452494264
batch 185 loss: 0.0005248446017503738
batch 190 loss: 0.0005231676273979247
batch 195 loss: 0.0005228541791439057
batch 200 loss: 0.0005234540207311511
batch 205 loss: 0.0005234689335338772
batch 210 loss: 0.0005231551243923604
batch 215 loss: 0.0005218810518272221
batch 220 loss: 0.0005222747684456408
batch 225 loss: 0.0005204824963584542
batch 230 loss: 0.0005212761810980737
batch 235 loss: 0.0005229290924035013
batch 240 loss: 0.0005233788164332509
Training Loss: 0.0005299152423200818
Validation Loss: 0.0005105407627221818
Epoch 42:
batch 5 loss: 0.000522641884163022
batch 10 loss: 0.0005206753616221249
batch 15 loss: 0.0005197212216444313
batch 20 loss: 0.0005193116841837764
batch 25 loss: 0.000518641050439328
batch 30 loss: 0.0005189679795876145
batch 35 loss: 0.0005217412370257079
batch 40 loss: 0.0005206982488743961
batch 45 loss: 0.0005205103312619031
batch 50 loss: 0.0005203447770327329
batch 55 loss: 0.0005169833893887699
batch 60 loss: 0.0005163331748917699
batch 65 loss: 0.0005186368827708066
batch 70 loss: 0.0005175820202566684
batch 75 loss: 0.0005172869423404336
batch 80 loss: 0.0005154834012500942
batch 85 loss: 0.0005164080765098333
batch 90 loss: 0.0005187721806578338
batch 95 loss: 0.0005165040493011475
batch 100 loss: 0.0005177114973776043
batch 105 loss: 0.0005198064493015409
batch 110 loss: 0.0005169392214156687
batch 115 loss: 0.0005169090465642512
batch 120 loss: 0.0005165771814063192
batch 125 loss: 0.0005161734065040946
batch 130 loss: 0.0005161599605344236
batch 135 loss: 0.0005152677651494742
batch 140 loss: 0.0005157228792086243
batch 145 loss: 0.0005143565824255348
batch 150 loss: 0.0005144062568433582
batch 155 loss: 0.000515204411931336
batch 160 loss: 0.000515584065578878
batch 165 loss: 0.0005159878521226347
batch 170 loss: 0.0005150298704393208
batch 175 loss: 0.0005151748424395919
batch 180 loss: 0.0005147924297489226
batch 185 loss: 0.0005130292847752571
batch 190 loss: 0.0005144129041582346
batch 195 loss: 0.0005121574737131596
batch 200 loss: 0.0005141649860888719
batch 205 loss: 0.0005146244191564619
batch 210 loss: 0.0005120243993587791
batch 215 loss: 0.0005089231417514384
batch 220 loss: 0.0005141441361047328
batch 225 loss: 0.0005112802376970649
batch 230 loss: 0.0005091151921078563
batch 235 loss: 0.0005117714405059815
batch 240 loss: 0.0005096291890367866
Training Loss: 0.0005161317586801791
Validation Loss: 0.0004949029942508786
Epoch 43:
batch 5 loss: 0.0005090367863886059
batch 10 loss: 0.0005085494718514383
batch 15 loss: 0.000506763206794858
batch 20 loss: 0.0005059854360297322
batch 25 loss: 0.0005058822105638682
batch 30 loss: 0.0005067042191512882
batch 35 loss: 0.0005054237088188529
batch 40 loss: 0.0005069800885394215
batch 45 loss: 0.0005082363146357239
batch 50 loss: 0.000503839086741209
batch 55 loss: 0.0005058891838416457
batch 60 loss: 0.000506759830750525
batch 65 loss: 0.0005063309450633824
batch 70 loss: 0.0005063411081209779
batch 75 loss: 0.0005028986604884266
batch 80 loss: 0.0005022874101996422
batch 85 loss: 0.0005061614327132701
batch 90 loss: 0.0005047328420914709
batch 95 loss: 0.0005022277124226094
batch 100 loss: 0.0005060771480202674
batch 105 loss: 0.0005009061540476977
batch 110 loss: 0.000500859459862113
batch 115 loss: 0.000503139873035252
batch 120 loss: 0.0005011902539990842
batch 125 loss: 0.000505056546535343
batch 130 loss: 0.0005018813069909811
batch 135 loss: 0.0005031128996051848
batch 140 loss: 0.0005013823276385665
batch 145 loss: 0.0005016346811316907
batch 150 loss: 0.0005000324104912579
batch 155 loss: 0.0004986316664144397
batch 160 loss: 0.000499904528260231
batch 165 loss: 0.0004966070875525475
batch 170 loss: 0.0005012334790080786
batch 175 loss: 0.0004970305599272251
batch 180 loss: 0.0005012918380089104
batch 185 loss: 0.0005029752966947854
batch 190 loss: 0.0004996333969756961
batch 195 loss: 0.0005000509438104928
batch 200 loss: 0.000497006019577384
batch 205 loss: 0.0004964952706359327
batch 210 loss: 0.0004987694672308862
batch 215 loss: 0.000499635562300682
batch 220 loss: 0.0004997308016754687
batch 225 loss: 0.0004969162051565945
batch 230 loss: 0.0004947367240674793
batch 235 loss: 0.0004964825580827892
batch 240 loss: 0.0004953532479703426
Training Loss: 0.0005022664035398823
Validation Loss: 0.00048119148656648275
Epoch 44:
batch 5 loss: 0.0004917972721159459
batch 10 loss: 0.0004887344490271062
batch 15 loss: 0.0004880076099652797
batch 20 loss: 0.00048405745765194296
batch 25 loss: 0.00048211397952400146
batch 30 loss: 0.0004842276801355183
batch 35 loss: 0.00048435094067826866
batch 40 loss: 0.00048288882244378327
batch 45 loss: 0.0004804581229109317
batch 50 loss: 0.0004803747753612697
batch 55 loss: 0.00048469431349076333
batch 60 loss: 0.0004804635944310576
batch 65 loss: 0.00047975770430639384
batch 70 loss: 0.00047638291143812237
batch 75 loss: 0.0004782424948643893
batch 80 loss: 0.0004799473099410534
batch 85 loss: 0.00047929437714628876
batch 90 loss: 0.0004802715498954058
batch 95 loss: 0.00047496596234850583
batch 100 loss: 0.0004741258278954774
batch 105 loss: 0.0004751751490402967
batch 110 loss: 0.0004760854586493224
batch 115 loss: 0.00047546426067128776
batch 120 loss: 0.0004745253885630518
batch 125 loss: 0.00047364011988975107
batch 130 loss: 0.00047258399426937104
batch 135 loss: 0.00047293396783061327
batch 140 loss: 0.00047254645032808186
batch 145 loss: 0.0004716430499684066
batch 150 loss: 0.00047266442561522126
batch 155 loss: 0.0004728159576188773
batch 160 loss: 0.0004771494714077562
batch 165 loss: 0.0004731426772195846
batch 170 loss: 0.00047218824620358645
batch 175 loss: 0.00047570692258886994
batch 180 loss: 0.0004726250714156777
batch 185 loss: 0.00046820483403280376
batch 190 loss: 0.000470720196608454
batch 195 loss: 0.00046988532412797215
batch 200 loss: 0.0004697841766756028
batch 205 loss: 0.0004732342844363302
batch 210 loss: 0.000469086307566613
batch 215 loss: 0.0004690748697612435
batch 220 loss: 0.00047143516130745413
batch 225 loss: 0.00047254744567908346
batch 230 loss: 0.00047091974993236364
batch 235 loss: 0.000468236138112843
batch 240 loss: 0.00046551389386877416
Training Loss: 0.00047613937810335
Validation Loss: 0.00044849270683092375
Epoch 45:
batch 5 loss: 0.000468463113065809
batch 10 loss: 0.00046336179366335273
batch 15 loss: 0.0004675676755141467
batch 20 loss: 0.0004709592496510595
batch 25 loss: 0.000467396411113441
batch 30 loss: 0.00046498442534357307
batch 35 loss: 0.00046657497296109796
batch 40 loss: 0.0004640038649085909
batch 45 loss: 0.00046597024193033575
batch 50 loss: 0.0004642804677132517
batch 55 loss: 0.0004655260650906712
batch 60 loss: 0.0004658975696656853
batch 65 loss: 0.00046776996459811925
batch 70 loss: 0.0004656663164496422
batch 75 loss: 0.00046650953008793296
batch 80 loss: 0.0004638962680473924
batch 85 loss: 0.0004620927618816495
batch 90 loss: 0.0004648641333915293
batch 95 loss: 0.0004658170393668115
batch 100 loss: 0.0004612440650817007
batch 105 loss: 0.0004633892618585378
batch 110 loss: 0.0004625596047844738
batch 115 loss: 0.00046313323546200993
batch 120 loss: 0.000461363437352702
batch 125 loss: 0.0004622607317287475
batch 130 loss: 0.0004654568096157163
batch 135 loss: 0.0004622973094228655
batch 140 loss: 0.0004638785496354103
batch 145 loss: 0.00046163639053702353
batch 150 loss: 0.00046634188620373605
batch 155 loss: 0.0004627689835615456
batch 160 loss: 0.0004589340765960515
batch 165 loss: 0.0004650360089726746
batch 170 loss: 0.000463787087937817
batch 175 loss: 0.0004638067097403109
batch 180 loss: 0.0004617016646079719
batch 185 loss: 0.0004575282451696694
batch 190 loss: 0.00046285774442367256
batch 195 loss: 0.00046211900771595535
batch 200 loss: 0.0004606319183949381
batch 205 loss: 0.000466963613871485
batch 210 loss: 0.00046240860247053205
batch 215 loss: 0.0004590298340190202
batch 220 loss: 0.0004574001766741276
batch 225 loss: 0.0004613879369571805
batch 230 loss: 0.00046268603182397783
batch 235 loss: 0.0004599764768499881
batch 240 loss: 0.0004596442449837923
Training Loss: 0.0004636214898103693
Validation Loss: 0.00043313601539315033
Epoch 46:
batch 5 loss: 0.0004615903424564749
batch 10 loss: 0.000460941536584869
batch 15 loss: 0.00046278497320599853
batch 20 loss: 0.0004598835250362754
batch 25 loss: 0.000462394836358726
batch 30 loss: 0.0004613893455825746
batch 35 loss: 0.0004581860266625881
batch 40 loss: 0.0004571758443489671
batch 45 loss: 0.0004603041335940361
batch 50 loss: 0.00046262296964414416
batch 55 loss: 0.0004606198228430003
batch 60 loss: 0.00046296099317260085
batch 65 loss: 0.00046084034256637095
batch 70 loss: 0.0004581298097036779
batch 75 loss: 0.000459624087670818
batch 80 loss: 0.000460868637310341
batch 85 loss: 0.00046254327753558755
batch 90 loss: 0.0004604840418323874
batch 95 loss: 0.00045982043957337737
batch 100 loss: 0.00045707087847404184
batch 105 loss: 0.00046345332521013916
batch 110 loss: 0.0004608124028891325
batch 115 loss: 0.00046054207487031815
batch 120 loss: 0.0004524765943642706
batch 125 loss: 0.0004640679340809584
batch 130 loss: 0.00045705928932875394
batch 135 loss: 0.00045845400309190153
batch 140 loss: 0.0004602986038662493
batch 145 loss: 0.00046271243481896816
batch 150 loss: 0.0004606945556588471
batch 155 loss: 0.0004627937683835626
batch 160 loss: 0.0004620123072527349
batch 165 loss: 0.00045616919524036346
batch 170 loss: 0.00045919405529275535
batch 175 loss: 0.00046271298197098076
batch 180 loss: 0.00045939080882817507
batch 185 loss: 0.0004637165227904916
batch 190 loss: 0.00045747046824544667
batch 195 loss: 0.0004587611882016063
batch 200 loss: 0.00045579596189782023
batch 205 loss: 0.0004617294005583972
batch 210 loss: 0.00046006928896531464
batch 215 loss: 0.00045948135084472597
batch 220 loss: 0.00046011960948817433
batch 225 loss: 0.00046063528279773893
batch 230 loss: 0.0004610835341736674
batch 235 loss: 0.0004590838041622192
batch 240 loss: 0.00046441389713436365
Training Loss: 0.0004603216772617695
Validation Loss: 0.0004308844606081645
Epoch 47:
batch 5 loss: 0.00046439007855951785
batch 10 loss: 0.000468280166387558
batch 15 loss: 0.0004618892620783299
batch 20 loss: 0.00045923769939690826
batch 25 loss: 0.00045760797802358867
batch 30 loss: 0.00046117708552628756
batch 35 loss: 0.0004584512673318386
batch 40 loss: 0.0004599209933076054
batch 45 loss: 0.00045995376422069967
batch 50 loss: 0.00045926368329674006
batch 55 loss: 0.00045834603370167317
batch 60 loss: 0.0004631269141100347
batch 65 loss: 0.00045849206508137287
batch 70 loss: 0.0004597571911290288
batch 75 loss: 0.0004599285777658224
batch 80 loss: 0.0004555674851872027
batch 85 loss: 0.00045819460065104066
batch 90 loss: 0.00045769272255711255
batch 95 loss: 0.0004582128836773336
batch 100 loss: 0.00045383183169178665
batch 105 loss: 0.0004579485103022307
batch 110 loss: 0.0004600697953719646
batch 115 loss: 0.0004589428834151477
batch 120 loss: 0.0004577744752168655
batch 125 loss: 0.00045958441914990545
batch 130 loss: 0.0004585541435517371
batch 135 loss: 0.0004609001858625561
batch 140 loss: 0.00045977249974384906
batch 145 loss: 0.00045838428777642546
batch 150 loss: 0.0004534763109404594
batch 155 loss: 0.00046011764206923547
batch 160 loss: 0.0004607929615303874
batch 165 loss: 0.00045701185008510946
batch 170 loss: 0.00045489505282603204
batch 175 loss: 0.0004577895510010421
batch 180 loss: 0.00045606386847794054
batch 185 loss: 0.00045180570450611415
batch 190 loss: 0.0004582437046337873
batch 195 loss: 0.000454427202930674
batch 200 loss: 0.00045252470881678163
batch 205 loss: 0.000455651106312871
batch 210 loss: 0.0004556006228085607
batch 215 loss: 0.0004558222950436175
batch 220 loss: 0.0004560057248454541
batch 225 loss: 0.0004591011733282357
batch 230 loss: 0.0004547065240330994
batch 235 loss: 0.000457054196158424
batch 240 loss: 0.000452718319138512
Training Loss: 0.00045810545840746877
Validation Loss: 0.00042337765626143664
Epoch 48:
batch 5 loss: 0.00048492258647456763
batch 10 loss: 0.000524240592494607
batch 15 loss: 0.0005140887573361397
batch 20 loss: 0.0005047370679676533
batch 25 loss: 0.0004969689180143178
batch 30 loss: 0.000488744827453047
batch 35 loss: 0.0004867568146437407
batch 40 loss: 0.0004802067531272769
batch 45 loss: 0.00048385452828370035
batch 50 loss: 0.00047860488411970435
batch 55 loss: 0.0004776818212121725
batch 60 loss: 0.0004738091956824064
batch 65 loss: 0.00047534817713312805
batch 70 loss: 0.00047040132340043784
batch 75 loss: 0.0004683366452809423
batch 80 loss: 0.0004697200900409371
batch 85 loss: 0.00046784799196757375
batch 90 loss: 0.00047196918749250474
batch 95 loss: 0.0004667059110943228
batch 100 loss: 0.00046427659108303485
batch 105 loss: 0.00046397570986300707
batch 110 loss: 0.0004652219417039305
batch 115 loss: 0.00046477416181005536
batch 120 loss: 0.00046432378585450353
batch 125 loss: 0.00046255955821834506
batch 130 loss: 0.00046294168569147585
batch 135 loss: 0.00045639536692760886
batch 140 loss: 0.0004587857227306813
batch 145 loss: 0.00046364852460101247
batch 150 loss: 0.00045850711758248507
batch 155 loss: 0.00045780567452311514
batch 160 loss: 0.0004566354269627482
batch 165 loss: 0.00045993321109563114
batch 170 loss: 0.0004599691601470113
batch 175 loss: 0.00045906183077022434
batch 180 loss: 0.00046236440539360046
batch 185 loss: 0.0004588778945617378
batch 190 loss: 0.00045189870288595555
batch 195 loss: 0.0004534433304797858
batch 200 loss: 0.0004532781196758151
batch 205 loss: 0.0004576191946398467
batch 210 loss: 0.00045158337452448903
batch 215 loss: 0.0004534464154858142
batch 220 loss: 0.0004503851116169244
batch 225 loss: 0.0004584976122714579
batch 230 loss: 0.00045559515710920097
batch 235 loss: 0.00045507960603572426
batch 240 loss: 0.0004524294112343341
Training Loss: 0.0004682970808062237
Validation Loss: 0.0004240085501805879
Epoch 49:
batch 5 loss: 0.00048466402222402394
batch 10 loss: 0.0005270853405818343
batch 15 loss: 0.0005159709951840341
batch 20 loss: 0.0005059413379058242
batch 25 loss: 0.0004948930989485234
batch 30 loss: 0.0004834693972952664
batch 35 loss: 0.00047238884144462645
batch 40 loss: 0.00047011947026476264
batch 45 loss: 0.0004614786186721176
batch 50 loss: 0.0004612957593053579
batch 55 loss: 0.00045994085376150907
batch 60 loss: 0.0004603253561072052
batch 65 loss: 0.00045995726832188667
batch 70 loss: 0.00045546238543465735
batch 75 loss: 0.0004590288153849542
batch 80 loss: 0.0004603871377184987
batch 85 loss: 0.00045290233101695775
batch 90 loss: 0.00045162555179558697
batch 95 loss: 0.00045499341795220973
batch 100 loss: 0.0004501000279560685
batch 105 loss: 0.0004516742075793445
batch 110 loss: 0.0004499908536672592
batch 115 loss: 0.0004525196913164109
batch 120 loss: 0.000454171618912369
batch 125 loss: 0.0004517911409493536
batch 130 loss: 0.00044919109204784037
batch 135 loss: 0.00045264351647347214
batch 140 loss: 0.00044317981228232385
batch 145 loss: 0.0004494803608395159
batch 150 loss: 0.00044483974343165753
batch 155 loss: 0.00044785343343392017
batch 160 loss: 0.0004440148186404258
batch 165 loss: 0.00044638566905632617
batch 170 loss: 0.00044992348412051795
batch 175 loss: 0.0004489553684834391
batch 180 loss: 0.00044494090834632514
batch 185 loss: 0.0004488584934733808
batch 190 loss: 0.0004467364226002246
batch 195 loss: 0.0004428235930390656
batch 200 loss: 0.0004454832640476525
batch 205 loss: 0.00044312771060504017
batch 210 loss: 0.00044040112989023327
batch 215 loss: 0.00044532971223816277
batch 220 loss: 0.0004428080690559
batch 225 loss: 0.0004438187694177032
batch 230 loss: 0.0004437997238710523
batch 235 loss: 0.00044549232698045673
batch 240 loss: 0.0004405486513860524
Training Loss: 0.00045735028361377773
Validation Loss: 0.00041360683438445753
Epoch 50:
batch 5 loss: 0.0004490835010074079
batch 10 loss: 0.0004789183847606182
batch 15 loss: 0.00046697933576069774
batch 20 loss: 0.0004615074081812054
batch 25 loss: 0.0004527622542809695
batch 30 loss: 0.00045399461523629723
batch 35 loss: 0.0004492738517001271
batch 40 loss: 0.000450528523651883
batch 45 loss: 0.000443833926692605
batch 50 loss: 0.00044761073077097534
batch 55 loss: 0.0004491239320486784
batch 60 loss: 0.0004423265054356307
batch 65 loss: 0.00044064130634069443
batch 70 loss: 0.0004455855174455792
batch 75 loss: 0.00044244511518627406
batch 80 loss: 0.00044184779399074613
batch 85 loss: 0.0004392146540340036
batch 90 loss: 0.0004439095035195351
batch 95 loss: 0.00044048558338545264
batch 100 loss: 0.00044344865018501877
batch 105 loss: 0.0004401982354465872
batch 110 loss: 0.00043937194859609006
batch 115 loss: 0.0004435920505784452
batch 120 loss: 0.00044121486716903747
batch 125 loss: 0.00044522061361931267
batch 130 loss: 0.0004411886911839247
batch 135 loss: 0.00044152376358397305
batch 140 loss: 0.00044195392401888964
batch 145 loss: 0.0004364916414488107
batch 150 loss: 0.000440673396224156
batch 155 loss: 0.0004430419998243451
batch 160 loss: 0.00043307868181727824
batch 165 loss: 0.00044070662697777153
batch 170 loss: 0.00043776012025773523
batch 175 loss: 0.00043934866553172467
batch 180 loss: 0.00043036315473727883
batch 185 loss: 0.0004366211593151093
batch 190 loss: 0.0004363790329080075
batch 195 loss: 0.00043640912044793365
batch 200 loss: 0.00043491446995176376
batch 205 loss: 0.0004373364383354783
batch 210 loss: 0.0004365593777038157
batch 215 loss: 0.00044091625604778526
batch 220 loss: 0.00042986574699170886
batch 225 loss: 0.0004316634323913604
batch 230 loss: 0.000431247177766636
batch 235 loss: 0.0004388012341223657
batch 240 loss: 0.0004353148338850588
Training Loss: 0.00044260995321868297
Validation Loss: 0.0004010767297586426
Epoch 51:
batch 5 loss: 0.0004332957323640585
batch 10 loss: 0.00043541273917071523
batch 15 loss: 0.00043773705838248136
batch 20 loss: 0.0004358872654847801
batch 25 loss: 0.0004357153957244009
batch 30 loss: 0.0004314716556109488
batch 35 loss: 0.0004326648951973766
batch 40 loss: 0.00043288901797495783
batch 45 loss: 0.0004331654577981681
batch 50 loss: 0.00042672206182032825
batch 55 loss: 0.00043156055617146196
batch 60 loss: 0.0004330600902903825
batch 65 loss: 0.00043174283928237855
batch 70 loss: 0.00043495498248375953
batch 75 loss: 0.00043128113611601293
batch 80 loss: 0.0004327812872361392
batch 85 loss: 0.00043514627031981945
batch 90 loss: 0.0004299461492337286
batch 95 loss: 0.00042903692228719593
batch 100 loss: 0.00043213069438934325
batch 105 loss: 0.0004325842368416488
batch 110 loss: 0.000429582322249189
batch 115 loss: 0.000431341165676713
batch 120 loss: 0.0004250870901159942
batch 125 loss: 0.000426159577909857
batch 130 loss: 0.0004299840598832816
batch 135 loss: 0.0004298347805161029
batch 140 loss: 0.00043205262045376003
batch 145 loss: 0.0004314076853916049
batch 150 loss: 0.0004356466117314994
batch 155 loss: 0.00043209671857766805
batch 160 loss: 0.0004295729857403785
batch 165 loss: 0.0004214333486743271
batch 170 loss: 0.000431048747850582
batch 175 loss: 0.00042704015504568815
batch 180 loss: 0.00042670145048759876
batch 185 loss: 0.00043329704203642905
batch 190 loss: 0.0004244808689691126
batch 195 loss: 0.0004302456043660641
batch 200 loss: 0.00042592673562467096
batch 205 loss: 0.0004249363671988249
batch 210 loss: 0.00042929703486151995
batch 215 loss: 0.00042265632073394953
batch 220 loss: 0.00042289275443181397
batch 225 loss: 0.00042691546841524544
batch 230 loss: 0.0004310078977141529
batch 235 loss: 0.00042723208898678424
batch 240 loss: 0.0004275397106539458
Training Loss: 0.0004303042428849343
Validation Loss: 0.00039338487889229633
Epoch 52:
batch 5 loss: 0.00042644444038160146
batch 10 loss: 0.0004290649725589901
batch 15 loss: 0.0004266053612809628
batch 20 loss: 0.00042582197929732504
batch 25 loss: 0.00042304089292883874
batch 30 loss: 0.0004243411938659847
batch 35 loss: 0.0004239913600031286
batch 40 loss: 0.00042128025670535864
batch 45 loss: 0.0004242308787070215
batch 50 loss: 0.0004265451862011105
batch 55 loss: 0.00042710601119324567
batch 60 loss: 0.0004257290915120393
batch 65 loss: 0.00042918192921206357
batch 70 loss: 0.00042363445390947163
batch 75 loss: 0.00042379469377920034
batch 80 loss: 0.0004200860974378884
batch 85 loss: 0.00042380125960335137
batch 90 loss: 0.00042803005781024697
batch 95 loss: 0.000418122170958668
batch 100 loss: 0.00042544579482637344
batch 105 loss: 0.00042322014924138783
batch 110 loss: 0.00042814044281840323
batch 115 loss: 0.00042212948901578786
batch 120 loss: 0.0004194420878775418
batch 125 loss: 0.00042347459238953886
batch 130 loss: 0.00042716741445474326
batch 135 loss: 0.0004218665068037808
batch 140 loss: 0.0004223234311211854
batch 145 loss: 0.00042406367138028147
batch 150 loss: 0.00042305855313315985
batch 155 loss: 0.00042187576182186606
batch 160 loss: 0.00042405439307913184
batch 165 loss: 0.00041758658480830493
batch 170 loss: 0.00042486896854825317
batch 175 loss: 0.0004226533346809447
batch 180 loss: 0.0004233601386658847
batch 185 loss: 0.00042200242751277983
batch 190 loss: 0.0004244271316565573
batch 195 loss: 0.00042005153954960406
batch 200 loss: 0.0004228495876304805
batch 205 loss: 0.00042222655611112714
batch 210 loss: 0.0004195103887468576
batch 215 loss: 0.00042262793867848815
batch 220 loss: 0.00041982450638897715
batch 225 loss: 0.0004221895709633827
batch 230 loss: 0.00042284951196052133
batch 235 loss: 0.0004256176471244544
batch 240 loss: 0.00041728967917151747
Training Loss: 0.0004234802101564128
Validation Loss: 0.0003883595442554603
Epoch 53:
batch 5 loss: 0.0004216429661028087
batch 10 loss: 0.0004165441379882395
batch 15 loss: 0.0004169548919890076
batch 20 loss: 0.00041933218017220497
batch 25 loss: 0.00041794944554567336
batch 30 loss: 0.0004177723836619407
batch 35 loss: 0.00042243460775353013
batch 40 loss: 0.00041972401086241005
batch 45 loss: 0.00041860071942210195
batch 50 loss: 0.00041774812270887194
batch 55 loss: 0.00041434314334765077
batch 60 loss: 0.00041818476165644825
batch 65 loss: 0.0004183154494967312
batch 70 loss: 0.0004227844241540879
batch 75 loss: 0.00042205053032375874
batch 80 loss: 0.00042008450836874547
batch 85 loss: 0.0004218126356136054
batch 90 loss: 0.0004148042935412377
batch 95 loss: 0.00041845773812383414
batch 100 loss: 0.0004159515374340117
batch 105 loss: 0.00041526240529492496
batch 110 loss: 0.0004169097286649048
batch 115 loss: 0.000408742151921615
batch 120 loss: 0.00041734739206731317
batch 125 loss: 0.00041807665256783367
batch 130 loss: 0.0004201570292934775
batch 135 loss: 0.0004186175763607025
batch 140 loss: 0.0004235970205627382
batch 145 loss: 0.00041804341017268596
batch 150 loss: 0.00042101533035747706
batch 155 loss: 0.0004208593280054629
batch 160 loss: 0.0004132738627959043
batch 165 loss: 0.00041448649717494844
batch 170 loss: 0.0004210538463667035
batch 175 loss: 0.00041705896728672087
batch 180 loss: 0.00042216297006234524
batch 185 loss: 0.00042295493185520174
batch 190 loss: 0.000419830420287326
batch 195 loss: 0.00041602810961194336
batch 200 loss: 0.0004172000626567751
batch 205 loss: 0.00041403170907869933
batch 210 loss: 0.00041852816939353944
batch 215 loss: 0.00042149581713601947
batch 220 loss: 0.0004181107913609594
batch 225 loss: 0.000419783202232793
batch 230 loss: 0.000419968378264457
batch 235 loss: 0.0004203124495688826
batch 240 loss: 0.00042187036015093324
Training Loss: 0.00041858898039208724
Validation Loss: 0.00038343777365904924
Epoch 54:
batch 5 loss: 0.00041930731385946273
batch 10 loss: 0.0004116309923119843
batch 15 loss: 0.000419618864543736
batch 20 loss: 0.00041441345820203424
batch 25 loss: 0.00041919369250535964
batch 30 loss: 0.0004158934927545488
batch 35 loss: 0.0004157001443672925
batch 40 loss: 0.00041122372495010494
batch 45 loss: 0.00041788335656747224
batch 50 loss: 0.0004156556504312903
batch 55 loss: 0.000417548546101898
batch 60 loss: 0.00041220627026632427
batch 65 loss: 0.00041034753085114064
batch 70 loss: 0.0004118237586226314
batch 75 loss: 0.00041544015402905643
batch 80 loss: 0.0004147364874370396
batch 85 loss: 0.000415220286231488
batch 90 loss: 0.0004100535123143345
batch 95 loss: 0.0004133890732191503
batch 100 loss: 0.00040954651194624603
batch 105 loss: 0.00041241139988414945
batch 110 loss: 0.0004113951115868986
batch 115 loss: 0.0004098052915651351
batch 120 loss: 0.000403761095367372
batch 125 loss: 0.00040255408966913817
batch 130 loss: 0.0004051525087561458
batch 135 loss: 0.00040404394967481495
batch 140 loss: 0.0004084461193997413
batch 145 loss: 0.00040604431414976717
batch 150 loss: 0.00040436917333863676
batch 155 loss: 0.00040418500429950655
batch 160 loss: 0.00041287707863375546
batch 165 loss: 0.0004087239794898778
batch 170 loss: 0.0004057818849105388
batch 175 loss: 0.0004030360083561391
batch 180 loss: 0.00040104473009705544
batch 185 loss: 0.00040730207110755144
batch 190 loss: 0.0004077191522810608
batch 195 loss: 0.0004008661780972034
batch 200 loss: 0.0004045457404572517
batch 205 loss: 0.0004029852221719921
batch 210 loss: 0.00040324509609490633
batch 215 loss: 0.0004040606436319649
batch 220 loss: 0.000402093242155388
batch 225 loss: 0.0004010701202787459
batch 230 loss: 0.00039982126909308133
batch 235 loss: 0.0003993348218500614
batch 240 loss: 0.00039596983697265387
Training Loss: 0.00040882245739339853
Validation Loss: 0.00036064436183854315
Epoch 55:
batch 5 loss: 0.00039874924113973974
batch 10 loss: 0.0004047631984576583
batch 15 loss: 0.00039782277308404447
batch 20 loss: 0.00039537007105536757
batch 25 loss: 0.0003983723116107285
batch 30 loss: 0.0004032165394164622
batch 35 loss: 0.00039486988680437207
batch 40 loss: 0.000394923088606447
batch 45 loss: 0.000401361909462139
batch 50 loss: 0.00039938310510478914
batch 55 loss: 0.0003975032072048634
batch 60 loss: 0.00040286184521391987
batch 65 loss: 0.00039803924737498165
batch 70 loss: 0.00040057009900920095
batch 75 loss: 0.0003977973945438862
batch 80 loss: 0.0003974855004344136
batch 85 loss: 0.00039579878211952745
batch 90 loss: 0.00039769542054273187
batch 95 loss: 0.00039875248330645263
batch 100 loss: 0.0004005495982710272
batch 105 loss: 0.00039764924440532923
batch 110 loss: 0.00040169102139770986
batch 115 loss: 0.00039930036291480064
batch 120 loss: 0.00039744944660924375
batch 125 loss: 0.00039803424733690916
batch 130 loss: 0.0003957440610975027
batch 135 loss: 0.00040087548550218346
batch 140 loss: 0.00040082272607833147
batch 145 loss: 0.0003961083013564348
batch 150 loss: 0.0004015075042843819
batch 155 loss: 0.00039933912339620294
batch 160 loss: 0.00039534543757326903
batch 165 loss: 0.00040062515763565897
batch 170 loss: 0.00039702465874142946
batch 175 loss: 0.0004013776138890535
batch 180 loss: 0.0004018315928988159
batch 185 loss: 0.0003926391014829278
batch 190 loss: 0.0003981206100434065
batch 195 loss: 0.0004004237300250679
batch 200 loss: 0.00039613324333913623
batch 205 loss: 0.0003973157436121255
batch 210 loss: 0.00039681532070972024
batch 215 loss: 0.00039659296162426473
batch 220 loss: 0.00039442395209334793
batch 225 loss: 0.0003940153925213963
batch 230 loss: 0.0003992215031757951
batch 235 loss: 0.0003975617932155728
batch 240 loss: 0.00039502314757555723
Training Loss: 0.0003983103789020485
Validation Loss: 0.0003540380232152529
Epoch 56:
batch 5 loss: 0.0004001715686172247
batch 10 loss: 0.000397209613583982
batch 15 loss: 0.00039567556814290583
batch 20 loss: 0.00039589256048202517
batch 25 loss: 0.00040166568360291424
batch 30 loss: 0.0003964860690757632
batch 35 loss: 0.0003998538013547659
batch 40 loss: 0.0003985561488661915
batch 45 loss: 0.00039661492919549344
batch 50 loss: 0.00039510803180746733
batch 55 loss: 0.00039645577198825775
batch 60 loss: 0.0003976970678195357
batch 65 loss: 0.0003987407253589481
batch 70 loss: 0.00039576113340444863
batch 75 loss: 0.0003957435023039579
batch 80 loss: 0.00039826062857173383
batch 85 loss: 0.00039587263599969444
batch 90 loss: 0.0003934517211746424
batch 95 loss: 0.00040017241262830795
batch 100 loss: 0.00039468344184570017
batch 105 loss: 0.00039505673921667037
batch 110 loss: 0.00039768205024302004
batch 115 loss: 0.000398109556408599
batch 120 loss: 0.00039530019275844095
batch 125 loss: 0.00039850228349678216
batch 130 loss: 0.00039425325230695306
batch 135 loss: 0.00039332020678557457
batch 140 loss: 0.0003938977781217545
batch 145 loss: 0.00039306832477450373
batch 150 loss: 0.00039217310841195286
batch 155 loss: 0.0003972655918914825
batch 160 loss: 0.0003994621685706079
batch 165 loss: 0.0003936720371711999
batch 170 loss: 0.00039577470161020754
batch 175 loss: 0.00040251596365123985
batch 180 loss: 0.00039719573105685414
batch 185 loss: 0.00039581861929036675
batch 190 loss: 0.0003942132869269699
batch 195 loss: 0.00039709627744741736
batch 200 loss: 0.0003999070846475661
batch 205 loss: 0.0003963443625252694
batch 210 loss: 0.00039864593418315053
batch 215 loss: 0.0003954320738557726
batch 220 loss: 0.00039747729897499084
batch 225 loss: 0.00040075036813504996
batch 230 loss: 0.00039491991046816113
batch 235 loss: 0.0004010026226751506
batch 240 loss: 0.0003970932913944125
Training Loss: 0.00039687549651716835
Validation Loss: 0.0003519643296992096
Epoch 57:
batch 5 loss: 0.00040224132244475185
batch 10 loss: 0.00040295104845426976
batch 15 loss: 0.0003978032560553402
batch 20 loss: 0.0003996984800323844
batch 25 loss: 0.0003972660575527698
batch 30 loss: 0.0003946501761674881
batch 35 loss: 0.0003958703950047493
batch 40 loss: 0.0003948989207856357
batch 45 loss: 0.00039922030409798024
batch 50 loss: 0.0003948914702050388
batch 55 loss: 0.00040069688111543655
batch 60 loss: 0.0003944263502489775
batch 65 loss: 0.00039291858556680383
batch 70 loss: 0.00039713832666166127
batch 75 loss: 0.0003926491248421371
batch 80 loss: 0.0003953288891352713
batch 85 loss: 0.00039493575459346173
batch 90 loss: 0.0003990023629739881
batch 95 loss: 0.0003981873218435794
batch 100 loss: 0.0003963992581702769
batch 105 loss: 0.00039794251206330954
batch 110 loss: 0.0003980268142186105
batch 115 loss: 0.00039546117768622934
batch 120 loss: 0.00039708535769023
batch 125 loss: 0.00039754368481226265
batch 130 loss: 0.0003998042084276676
batch 135 loss: 0.00039553577080368995
batch 140 loss: 0.00039602034958079456
batch 145 loss: 0.0003926760866306722
batch 150 loss: 0.0003939629066735506
batch 155 loss: 0.0003939970803912729
batch 160 loss: 0.0003915428416803479
batch 165 loss: 0.0003962597402278334
batch 170 loss: 0.00039494461379945277
batch 175 loss: 0.00039451916818507017
batch 180 loss: 0.00039453120552934706
batch 185 loss: 0.0003959505818784237
batch 190 loss: 0.0003979489498306066
batch 195 loss: 0.00039330282597802577
batch 200 loss: 0.00039271345594897865
batch 205 loss: 0.0003980320529080927
batch 210 loss: 0.0003918729838915169
batch 215 loss: 0.000388672697590664
batch 220 loss: 0.0003929687780328095
batch 225 loss: 0.0003962082962971181
batch 230 loss: 0.00039052728097885845
batch 235 loss: 0.0003901145188137889
batch 240 loss: 0.00039606739301234484
Training Loss: 0.00039573765873986605
Validation Loss: 0.00035318655039494237
Epoch 58:
batch 5 loss: 0.00042137226555496456
batch 10 loss: 0.0004549821431282908
batch 15 loss: 0.0004611525626387447
batch 20 loss: 0.0004415546602103859
batch 25 loss: 0.0004349476774223149
batch 30 loss: 0.0004315412836149335
batch 35 loss: 0.0004312218981795013
batch 40 loss: 0.0004222259391099215
batch 45 loss: 0.00041952476603910325
batch 50 loss: 0.00041132847545668485
batch 55 loss: 0.0004088472807779908
batch 60 loss: 0.0004091307055205107
batch 65 loss: 0.00040742639685049654
batch 70 loss: 0.0004032634664326906
batch 75 loss: 0.0004017949569970369
batch 80 loss: 0.00039965735049918294
batch 85 loss: 0.0003981054702308029
batch 90 loss: 0.0004012728342786431
batch 95 loss: 0.0003956263477448374
batch 100 loss: 0.0004011989280115813
batch 105 loss: 0.00040134958690032365
batch 110 loss: 0.0004031093674711883
batch 115 loss: 0.0003919663722626865
batch 120 loss: 0.00039708109688945114
batch 125 loss: 0.0004007553565315902
batch 130 loss: 0.00039196948637254536
batch 135 loss: 0.00039385242853313686
batch 140 loss: 0.0003946209151763469
batch 145 loss: 0.0003934003121685237
batch 150 loss: 0.00039583328180015087
batch 155 loss: 0.0003902122494764626
batch 160 loss: 0.0003934388398192823
batch 165 loss: 0.0003940269874874502
batch 170 loss: 0.0003931282088160515
batch 175 loss: 0.00038951198221184315
batch 180 loss: 0.0003942858951631933
batch 185 loss: 0.00038978364900685845
batch 190 loss: 0.0003887146187480539
batch 195 loss: 0.0003935088112484664
batch 200 loss: 0.0003940534661523998
batch 205 loss: 0.0003875315363984555
batch 210 loss: 0.00039421141264028847
batch 215 loss: 0.00039002576959319414
batch 220 loss: 0.00039218927267938854
batch 225 loss: 0.00039503666339442135
batch 230 loss: 0.0003910253872163594
batch 235 loss: 0.0003899194358382374
batch 240 loss: 0.0003885866783093661
Training Loss: 0.000403527176604257
Validation Loss: 0.00035105691010054824
Epoch 59:
batch 5 loss: 0.0004301228444091976
batch 10 loss: 0.0005273343762382865
batch 15 loss: 0.0005136885796673596
batch 20 loss: 0.0004956322954967618
batch 25 loss: 0.0004863463807851076
batch 30 loss: 0.000475052441470325
batch 35 loss: 0.00046620872453786435
batch 40 loss: 0.0004637072037439793
batch 45 loss: 0.0004521203984040767
batch 50 loss: 0.0004532748367637396
batch 55 loss: 0.00045386638375930486
batch 60 loss: 0.0004494921944569796
batch 65 loss: 0.00044230640633031727
batch 70 loss: 0.0004438007192220539
batch 75 loss: 0.0004453137866221368
batch 80 loss: 0.00043956150184385476
batch 85 loss: 0.0004393600334879011
batch 90 loss: 0.0004320294829085469
batch 95 loss: 0.00043242782121524217
batch 100 loss: 0.0004392413015011698
batch 105 loss: 0.00043324101134203377
batch 110 loss: 0.0004351698327809572
batch 115 loss: 0.00043334533111192284
batch 120 loss: 0.00043388923513703047
batch 125 loss: 0.0004296789993532002
batch 130 loss: 0.0004306149261537939
batch 135 loss: 0.00043508370290510354
batch 140 loss: 0.00043623364763334394
batch 145 loss: 0.0004325530433561653
batch 150 loss: 0.00043187699047848583
batch 155 loss: 0.0004339183971751481
batch 160 loss: 0.00042507621692493557
batch 165 loss: 0.0004289995762519538
batch 170 loss: 0.0004304165893699974
batch 175 loss: 0.0004257798951584846
batch 180 loss: 0.00043101730407215657
batch 185 loss: 0.00042752796434797347
batch 190 loss: 0.00042775776819325984
batch 195 loss: 0.0004305320850107819
batch 200 loss: 0.0004259083769284189
batch 205 loss: 0.00042395058553665874
batch 210 loss: 0.00042157540447078644
batch 215 loss: 0.00042769000283442437
batch 220 loss: 0.00042459142277948556
batch 225 loss: 0.0004268588963896036
batch 230 loss: 0.0004192131978925318
batch 235 loss: 0.00042608228977769613
batch 240 loss: 0.0004181263619102538
Training Loss: 0.0004414082660029332
Validation Loss: 0.0003955597164652621
Epoch 60:
batch 5 loss: 0.00043443930335342886
batch 10 loss: 0.000474912254139781
batch 15 loss: 0.00046852457453496756
batch 20 loss: 0.00045555844553746283
batch 25 loss: 0.0004465400124900043
batch 30 loss: 0.00044094152399338783
batch 35 loss: 0.0004332348529715091
batch 40 loss: 0.0004256146552506834
batch 45 loss: 0.00042438688105903564
batch 50 loss: 0.0004239155678078532
batch 55 loss: 0.00042788384016603234
batch 60 loss: 0.00042267164099030197
batch 65 loss: 0.0004218210990075022
batch 70 loss: 0.00042171761742793024
batch 75 loss: 0.00042384609114378693
batch 80 loss: 0.00042050202609971165
batch 85 loss: 0.0004240262962412089
batch 90 loss: 0.0004195863730274141
batch 95 loss: 0.0004195095621980727
batch 100 loss: 0.0004231010272633284
batch 105 loss: 0.0004248363489750773
batch 110 loss: 0.0004217273963149637
batch 115 loss: 0.0004219996277242899
batch 120 loss: 0.00042283746879547837
batch 125 loss: 0.0004244333889801055
batch 130 loss: 0.00042402982944622636
batch 135 loss: 0.00042042319546453655
batch 140 loss: 0.0004144522885326296
batch 145 loss: 0.00041807323577813804
batch 150 loss: 0.00042139152064919473
batch 155 loss: 0.0004221469338517636
batch 160 loss: 0.00042080332059413195
batch 165 loss: 0.0004239518428221345
batch 170 loss: 0.0004241131420712918
batch 175 loss: 0.000424486625706777
batch 180 loss: 0.0004171420994680375
batch 185 loss: 0.0004229968530125916
batch 190 loss: 0.0004226205986924469
batch 195 loss: 0.0004228769685141742
batch 200 loss: 0.00042121316073462367
batch 205 loss: 0.00042264904477633535
batch 210 loss: 0.0004176183545496315
batch 215 loss: 0.00041907819104380906
batch 220 loss: 0.0004144115606322885
batch 225 loss: 0.0004176193731836975
batch 230 loss: 0.00042063487926498057
batch 235 loss: 0.00041418547625653445
batch 240 loss: 0.0004182496457360685
Training Loss: 0.0004257028336724034
Validation Loss: 0.000388295590528287
Epoch 61:
batch 5 loss: 0.00041480603395029905
batch 10 loss: 0.00042048305040225386
batch 15 loss: 0.00041936678462661803
batch 20 loss: 0.00041819908656179903
batch 25 loss: 0.00041599812684580686
batch 30 loss: 0.00041623471188358965
batch 35 loss: 0.0004186858714092523
batch 40 loss: 0.00041709529468789695
batch 45 loss: 0.0004191251238808036
batch 50 loss: 0.00041660379501990975
batch 55 loss: 0.0004172675544396043
batch 60 loss: 0.0004244700539857149
batch 65 loss: 0.0004196799942292273
batch 70 loss: 0.0004181849304586649
batch 75 loss: 0.0004149437532760203
batch 80 loss: 0.0004161577322520316
batch 85 loss: 0.00041163437999784945
batch 90 loss: 0.0004161986871622503
batch 95 loss: 0.0004078510799445212
batch 100 loss: 0.0004109941073693335
batch 105 loss: 0.0004096953955013305
batch 110 loss: 0.00040446879575029016
batch 115 loss: 0.00040111737325787544
batch 120 loss: 0.0004006070259492844
batch 125 loss: 0.0004008402058389038
batch 130 loss: 0.0004045876150485128
batch 135 loss: 0.000403283309424296
batch 140 loss: 0.0004091939423233271
batch 145 loss: 0.00040322791319340466
batch 150 loss: 0.00041004019440151753
batch 155 loss: 0.00040136960451491176
batch 160 loss: 0.00040729111060500145
batch 165 loss: 0.00040261558606289325
batch 170 loss: 0.00039983788738027213
batch 175 loss: 0.00040429311920888724
batch 180 loss: 0.000400063896086067
batch 185 loss: 0.00039697408792562785
batch 190 loss: 0.00040294445352628827
batch 195 loss: 0.0004054190358147025
batch 200 loss: 0.00040824979660101233
batch 205 loss: 0.00041240567225031555
batch 210 loss: 0.00039681498310528696
batch 215 loss: 0.0003991054545622319
batch 220 loss: 0.00039868406020104885
batch 225 loss: 0.0003951185382902622
batch 230 loss: 0.00039196472498588265
batch 235 loss: 0.0003928076184820384
batch 240 loss: 0.0003896590846125036
Training Loss: 0.000408055429943488
Validation Loss: 0.0003639578712560857
Epoch 62:
batch 5 loss: 0.00039197237347252665
batch 10 loss: 0.0003889696265105158
batch 15 loss: 0.00039329933351837096
batch 20 loss: 0.00039267220417968927
batch 25 loss: 0.0003908478189259768
batch 30 loss: 0.0003878603805787861
batch 35 loss: 0.00038957993965595963
batch 40 loss: 0.0003948371740989387
batch 45 loss: 0.000391450768802315
batch 50 loss: 0.0003907975915353745
batch 55 loss: 0.00039120158180594444
batch 60 loss: 0.00039258216274902226
batch 65 loss: 0.0003929449710994959
batch 70 loss: 0.0003913322347216308
batch 75 loss: 0.0003895933099556714
batch 80 loss: 0.0003918234840966761
batch 85 loss: 0.0003970847115851939
batch 90 loss: 0.0003894322027917951
batch 95 loss: 0.00039366118726320566
batch 100 loss: 0.0003899411822203547
batch 105 loss: 0.00039172128308564427
batch 110 loss: 0.00038751502870582044
batch 115 loss: 0.00038968347362242637
batch 120 loss: 0.0003955809632316232
batch 125 loss: 0.0003898959665093571
batch 130 loss: 0.0003884247853420675
batch 135 loss: 0.00039003819692879916
batch 140 loss: 0.0003872873669024557
batch 145 loss: 0.00038321876781992613
batch 150 loss: 0.0003905858960933983
batch 155 loss: 0.00039224264328368007
batch 160 loss: 0.0003897461690939963
batch 165 loss: 0.0003912168031092733
batch 170 loss: 0.00039206104702316225
batch 175 loss: 0.0003888528619427234
batch 180 loss: 0.0003856585186440498
batch 185 loss: 0.0003942875424399972
batch 190 loss: 0.0003915684879757464
batch 195 loss: 0.0003968319681007415
batch 200 loss: 0.0003933112078811973
batch 205 loss: 0.0003891430387739092
batch 210 loss: 0.00038757931906729937
batch 215 loss: 0.0003897572460118681
batch 220 loss: 0.00038692562375217674
batch 225 loss: 0.00038703962345607577
batch 230 loss: 0.00038451903383247555
batch 235 loss: 0.0003837300231680274
batch 240 loss: 0.00038518198416568337
Training Loss: 0.00039032268978189677
Validation Loss: 0.000365511455553739
Epoch 63:
batch 5 loss: 0.00037982420763000847
batch 10 loss: 0.0003889567742589861
batch 15 loss: 0.00038132541230879725
batch 20 loss: 0.0003875413676723838
batch 25 loss: 0.0003833652939647436
batch 30 loss: 0.00038492095773108305
batch 35 loss: 0.0003867420076858252
batch 40 loss: 0.0003833875933196396
batch 45 loss: 0.0003837726020719856
batch 50 loss: 0.00038494201726280153
batch 55 loss: 0.00038035945035517214
batch 60 loss: 0.0003766321111470461
batch 65 loss: 0.0003905618970748037
batch 70 loss: 0.0003854918642900884
batch 75 loss: 0.0003802759689278901
batch 80 loss: 0.00038782036863267423
batch 85 loss: 0.00038525268901139497
batch 90 loss: 0.00038431090652011333
batch 95 loss: 0.00038184497971087693
batch 100 loss: 0.00038899999344721437
batch 105 loss: 0.00038364893407560885
batch 110 loss: 0.00039307971601374445
batch 115 loss: 0.00038275375263765456
batch 120 loss: 0.00038604369037784634
batch 125 loss: 0.00038710744702257215
batch 130 loss: 0.00038414454320445657
batch 135 loss: 0.00038062985404394565
batch 140 loss: 0.0003872786182910204
batch 145 loss: 0.00039132150704972445
batch 150 loss: 0.0003847599436994642
batch 155 loss: 0.0003806452441494912
batch 160 loss: 0.0003818801429588348
batch 165 loss: 0.0003773558943066746
batch 170 loss: 0.0003777825273573399
batch 175 loss: 0.00038028922863304616
batch 180 loss: 0.0003855632618069649
batch 185 loss: 0.00038175881491042674
batch 190 loss: 0.0003870653628837317
batch 195 loss: 0.00038535573403351007
batch 200 loss: 0.00038518725195899604
batch 205 loss: 0.00037862700992263854
batch 210 loss: 0.00038039378123357894
batch 215 loss: 0.00038081140373833475
batch 220 loss: 0.0003796446486376226
batch 225 loss: 0.0003743151144590229
batch 230 loss: 0.0003816423879470676
batch 235 loss: 0.0003753279394004494
batch 240 loss: 0.0003823860315605998
Training Loss: 0.00038339850519453954
Validation Loss: 0.00034341568243689835
Epoch 64:
batch 5 loss: 0.0003712350910063833
batch 10 loss: 0.00037726531154476107
batch 15 loss: 0.0003763599612284452
batch 20 loss: 0.00037210098234936596
batch 25 loss: 0.0003709633892867714
batch 30 loss: 0.00037491231341846287
batch 35 loss: 0.00037154643796384336
batch 40 loss: 0.00037112602149136364
batch 45 loss: 0.00036900079576298597
batch 50 loss: 0.00036688822438009084
batch 55 loss: 0.0003702217887621373
batch 60 loss: 0.0003694076673127711
batch 65 loss: 0.00036838536034338175
batch 70 loss: 0.0003656231332570314
batch 75 loss: 0.0003669919446110725
batch 80 loss: 0.00036102065350860355
batch 85 loss: 0.0003696886880788952
batch 90 loss: 0.0003678949666209519
batch 95 loss: 0.00036360087688080966
batch 100 loss: 0.00036425868165679276
batch 105 loss: 0.0003641712246462703
batch 110 loss: 0.00036382239777594806
batch 115 loss: 0.00036022417480126024
batch 120 loss: 0.0003569188062101603
batch 125 loss: 0.00035459016798995436
batch 130 loss: 0.00035462132655084133
batch 135 loss: 0.000355175364529714
batch 140 loss: 0.00035138469538651405
batch 145 loss: 0.0003525048785377294
batch 150 loss: 0.0003562813508324325
batch 155 loss: 0.00035040730144828556
batch 160 loss: 0.00035257701529189944
batch 165 loss: 0.0003551974310539663
batch 170 loss: 0.00035641543800011275
batch 175 loss: 0.00034990570857189595
batch 180 loss: 0.0003530240850523114
batch 185 loss: 0.0003509365837089717
batch 190 loss: 0.00035316441208124163
batch 195 loss: 0.00035300339222885666
batch 200 loss: 0.0003526125161442906
batch 205 loss: 0.00035296481801196935
batch 210 loss: 0.0003474441298749298
batch 215 loss: 0.00034897124278359114
batch 220 loss: 0.0003470434749033302
batch 225 loss: 0.00034733161446638406
batch 230 loss: 0.0003508986090309918
batch 235 loss: 0.00035222782753407955
batch 240 loss: 0.0003465029061771929
Training Loss: 0.00035997531631437596
Validation Loss: 0.0003008870732931731
Epoch 65:
batch 5 loss: 0.00034244853304699063
batch 10 loss: 0.00035017713671550157
batch 15 loss: 0.0003450718824751675
batch 20 loss: 0.00034652590402401985
batch 25 loss: 0.00034272100892849264
batch 30 loss: 0.00034779946436174213
batch 35 loss: 0.0003433841629885137
batch 40 loss: 0.0003483669075649232
batch 45 loss: 0.00034500727197155355
batch 50 loss: 0.000345450546592474
batch 55 loss: 0.00034517733729444444
batch 60 loss: 0.00034348050248809157
batch 65 loss: 0.0003437267092522234
batch 70 loss: 0.00034616856137290595
batch 75 loss: 0.0003464352514129132
batch 80 loss: 0.0003476968500763178
batch 85 loss: 0.00034841535380110146
batch 90 loss: 0.00034554133308120074
batch 95 loss: 0.00034687516163103285
batch 100 loss: 0.00034476908622309564
batch 105 loss: 0.0003495428885798901
batch 110 loss: 0.0003418680280447006
batch 115 loss: 0.00034170715953223406
batch 120 loss: 0.00034521325142122805
batch 125 loss: 0.0003444913774728775
batch 130 loss: 0.00034063095808960496
batch 135 loss: 0.00034033715492114424
batch 140 loss: 0.00033989925286732615
batch 145 loss: 0.0003361090086400509
batch 150 loss: 0.0003431771765463054
batch 155 loss: 0.00034021151950582864
batch 160 loss: 0.00033968925126828255
batch 165 loss: 0.00034037561854347584
batch 170 loss: 0.0003431062446907163
batch 175 loss: 0.0003451746888458729
batch 180 loss: 0.0003381730813998729
batch 185 loss: 0.0003404413175303489
batch 190 loss: 0.0003416900523006916
batch 195 loss: 0.00034340983256697655
batch 200 loss: 0.00034442327450960873
batch 205 loss: 0.0003394254832528532
batch 210 loss: 0.0003436927450820804
batch 215 loss: 0.0003393543476704508
batch 220 loss: 0.00033466878812760115
batch 225 loss: 0.00033912449143826964
batch 230 loss: 0.0003394987841602415
batch 235 loss: 0.0003392848360817879
batch 240 loss: 0.0003401449008379132
Training Loss: 0.0003431271766506446
Validation Loss: 0.00029094969989576687
Epoch 66:
batch 5 loss: 0.0003398834669496864
batch 10 loss: 0.00034326622844673695
batch 15 loss: 0.00033824757556430993
batch 20 loss: 0.0003402197558898479
batch 25 loss: 0.0003409984696190804
batch 30 loss: 0.0003380691749043763
batch 35 loss: 0.00033603942720219495
batch 40 loss: 0.00034142465447075667
batch 45 loss: 0.0003404276038054377
batch 50 loss: 0.0003373986284714192
batch 55 loss: 0.000342281284974888
batch 60 loss: 0.00034107466926798226
batch 65 loss: 0.00034079893375746904
batch 70 loss: 0.00033840195392258464
batch 75 loss: 0.0003419693559408188
batch 80 loss: 0.00033618180896155536
batch 85 loss: 0.0003414522565435618
batch 90 loss: 0.00033504278399050237
batch 95 loss: 0.00034024461056105795
batch 100 loss: 0.0003400422225240618
batch 105 loss: 0.00033726911060512067
batch 110 loss: 0.00033658156753517686
batch 115 loss: 0.00034065163345076144
batch 120 loss: 0.00034031273680739104
batch 125 loss: 0.0003379608795512468
batch 130 loss: 0.0003409893251955509
batch 135 loss: 0.0003401479392778128
batch 140 loss: 0.0003358450601808727
batch 145 loss: 0.0003417057218030095
batch 150 loss: 0.0003385188465472311
batch 155 loss: 0.000341616157675162
batch 160 loss: 0.00034083124483004213
batch 165 loss: 0.000339063024148345
batch 170 loss: 0.000338400126202032
batch 175 loss: 0.00033786761341616514
batch 180 loss: 0.00033738670172169807
batch 185 loss: 0.0003343978663906455
batch 190 loss: 0.00033992084790952505
batch 195 loss: 0.0003358706657309085
batch 200 loss: 0.0003393178805708885
batch 205 loss: 0.0003396166430320591
batch 210 loss: 0.0003357392502948642
batch 215 loss: 0.00034084886428900065
batch 220 loss: 0.0003378926427103579
batch 225 loss: 0.0003386230731848627
batch 230 loss: 0.00033751808223314583
batch 235 loss: 0.00033762302482500675
batch 240 loss: 0.00034008907969109716
Training Loss: 0.0003390848015745481
Validation Loss: 0.0002911358101603886
Epoch 67:
batch 5 loss: 0.0003439224499743432
batch 10 loss: 0.0003397463820874691
batch 15 loss: 0.00034373782109469174
batch 20 loss: 0.0003387007862329483
batch 25 loss: 0.0003388284414540976
batch 30 loss: 0.0003392930084373802
batch 35 loss: 0.0003385608026292175
batch 40 loss: 0.00033966233604587615
batch 45 loss: 0.0003378342546056956
batch 50 loss: 0.0003402852453291416
batch 55 loss: 0.0003392705169972032
batch 60 loss: 0.00033578933798708024
batch 65 loss: 0.0003381778602488339
batch 70 loss: 0.00033201146870851515
batch 75 loss: 0.00033474505762569605
batch 80 loss: 0.0003399730776436627
batch 85 loss: 0.00033428496681153774
batch 90 loss: 0.0003343875694554299
batch 95 loss: 0.00033833726192824545
batch 100 loss: 0.0003349979582708329
batch 105 loss: 0.000337404478341341
batch 110 loss: 0.0003384122741408646
batch 115 loss: 0.0003356386616360396
batch 120 loss: 0.00033707607653923335
batch 125 loss: 0.00033306158729828894
batch 130 loss: 0.00033618095912970605
batch 135 loss: 0.00033656898303888736
batch 140 loss: 0.0003345249395351857
batch 145 loss: 0.0003380693669896573
batch 150 loss: 0.0003353833279106766
batch 155 loss: 0.00033433259231969715
batch 160 loss: 0.0003335303335916251
batch 165 loss: 0.0003391991078387946
batch 170 loss: 0.0003329035302158445
batch 175 loss: 0.0003343331161886454
batch 180 loss: 0.00033107671188190577
batch 185 loss: 0.0003348203026689589
batch 190 loss: 0.00033124983892776074
batch 195 loss: 0.00033105660113506017
batch 200 loss: 0.00033353634644299744
batch 205 loss: 0.0003358153800945729
batch 210 loss: 0.00033488779445178807
batch 215 loss: 0.0003316214657388628
batch 220 loss: 0.0003378921071998775
batch 225 loss: 0.00033036668319255116
batch 230 loss: 0.0003343283198773861
batch 235 loss: 0.0003329697588924319
batch 240 loss: 0.00033452400239184497
Training Loss: 0.0003361106510662163
Validation Loss: 0.00028343943898410847
Epoch 68:
batch 5 loss: 0.0003747686860151589
batch 10 loss: 0.0005140219582244754
batch 15 loss: 0.000472719018580392
batch 20 loss: 0.00044455506140366196
batch 25 loss: 0.0004166542552411556
batch 30 loss: 0.0004015486396383494
batch 35 loss: 0.00038811297854408623
batch 40 loss: 0.0003789859591051936
batch 45 loss: 0.0003691607213113457
batch 50 loss: 0.0003640556649770588
batch 55 loss: 0.00035706385970115664
batch 60 loss: 0.00035380557528696954
batch 65 loss: 0.0003497196768876165
batch 70 loss: 0.00034851222881115973
batch 75 loss: 0.00034396504634059966
batch 80 loss: 0.00034369416534900664
batch 85 loss: 0.00034083553473465147
batch 90 loss: 0.0003468619252089411
batch 95 loss: 0.0003419518645387143
batch 100 loss: 0.00034038880257867275
batch 105 loss: 0.0003439857973717153
batch 110 loss: 0.0003360567206982523
batch 115 loss: 0.0003386680677067488
batch 120 loss: 0.00033761779777705667
batch 125 loss: 0.0003376676351763308
batch 130 loss: 0.0003362669434864074
batch 135 loss: 0.0003385074669495225
batch 140 loss: 0.00033226521918550134
batch 145 loss: 0.00033445358276367186
batch 150 loss: 0.0003334936045575887
batch 155 loss: 0.0003332839347422123
batch 160 loss: 0.0003339373506605625
batch 165 loss: 0.00033180175232701005
batch 170 loss: 0.00033013637294061483
batch 175 loss: 0.0003272902627941221
batch 180 loss: 0.0003298507770523429
batch 185 loss: 0.00033335256739519536
batch 190 loss: 0.00032901818631216886
batch 195 loss: 0.0003285133105237037
batch 200 loss: 0.00033128464128822087
batch 205 loss: 0.00032855577883310615
batch 210 loss: 0.00032790074474178257
batch 215 loss: 0.00032749889069236813
batch 220 loss: 0.0003247549757361412
batch 225 loss: 0.00032555877114646135
batch 230 loss: 0.0003269126813393086
batch 235 loss: 0.0003261668549384922
batch 240 loss: 0.0003273914975579828
Training Loss: 0.00035174112102443665
Validation Loss: 0.00027924011713669947
Epoch 69:
batch 5 loss: 0.00035092448233626784
batch 10 loss: 0.00044715701369568706
batch 15 loss: 0.00040891540702432395
batch 20 loss: 0.0003903996432200074
batch 25 loss: 0.0003765378787647933
batch 30 loss: 0.0003633419866673648
batch 35 loss: 0.00035483225947245954
batch 40 loss: 0.00034996637259609997
batch 45 loss: 0.0003455586440395564
batch 50 loss: 0.00034477312001399694
batch 55 loss: 0.0003383356204722077
batch 60 loss: 0.00034205170813947914
batch 65 loss: 0.00033685751259326935
batch 70 loss: 0.0003391035250388086
batch 75 loss: 0.00033384772832505404
batch 80 loss: 0.0003349816252011806
batch 85 loss: 0.00033565363846719263
batch 90 loss: 0.0003315561159979552
batch 95 loss: 0.00032912271562963725
batch 100 loss: 0.0003295867005363107
batch 105 loss: 0.00033113120589405297
batch 110 loss: 0.00032934953342191877
batch 115 loss: 0.0003276787232607603
batch 120 loss: 0.0003271808265708387
batch 125 loss: 0.0003290071850642562
batch 130 loss: 0.0003255407849792391
batch 135 loss: 0.0003245709289330989
batch 140 loss: 0.0003276729898061603
batch 145 loss: 0.00032615389209240676
batch 150 loss: 0.00032364675425924363
batch 155 loss: 0.0003210216702427715
batch 160 loss: 0.00032552763586863876
batch 165 loss: 0.0003257384232711047
batch 170 loss: 0.0003227125445846468
batch 175 loss: 0.0003226658736821264
batch 180 loss: 0.0003186389047186822
batch 185 loss: 0.00032158792018890383
batch 190 loss: 0.00032088132575154306
batch 195 loss: 0.0003205779765266925
batch 200 loss: 0.00032030842849053445
batch 205 loss: 0.0003190884890500456
batch 210 loss: 0.0003202804422471672
batch 215 loss: 0.00032265576883219185
batch 220 loss: 0.0003196496341843158
batch 225 loss: 0.0003217521531041712
batch 230 loss: 0.0003208830370567739
batch 235 loss: 0.0003186946676578373
batch 240 loss: 0.00031456970609724524
Training Loss: 0.00033609731508477125
Validation Loss: 0.0002581614418886602
Epoch 70:
batch 5 loss: 0.0003499665530398488
batch 10 loss: 0.0005519643309526145
batch 15 loss: 0.0005411614780314267
batch 20 loss: 0.0005213090917095542
batch 25 loss: 0.0005056622088886797
batch 30 loss: 0.0004939356469549239
batch 35 loss: 0.0004790076636709273
batch 40 loss: 0.00046803830773569646
batch 45 loss: 0.0004593936901073903
batch 50 loss: 0.00044716174015775324
batch 55 loss: 0.0004413714224938303
batch 60 loss: 0.0004286958777811378
batch 65 loss: 0.0004232030245475471
batch 70 loss: 0.00042530299397185444
batch 75 loss: 0.00041900347569026055
batch 80 loss: 0.00041029819403775035
batch 85 loss: 0.00040915154968388376
batch 90 loss: 0.00040076570585370066
batch 95 loss: 0.00040282985428348185
batch 100 loss: 0.00039392979815602305
batch 105 loss: 0.0003955097927246243
batch 110 loss: 0.0003947413875721395
batch 115 loss: 0.00039123286260291936
batch 120 loss: 0.00038766234647482636
batch 125 loss: 0.00038936252240091563
batch 130 loss: 0.00038720886223018167
batch 135 loss: 0.00038488018908537923
batch 140 loss: 0.00037622207310050726
batch 145 loss: 0.00037667567958123984
batch 150 loss: 0.0003779652528464794
batch 155 loss: 0.0003731807344593108
batch 160 loss: 0.0003759843006264418
batch 165 loss: 0.0003700494416989386
batch 170 loss: 0.0003650288679637015
batch 175 loss: 0.00036760528455488385
batch 180 loss: 0.0003653640451375395
batch 185 loss: 0.00036737092887051404
batch 190 loss: 0.0003649112011771649
batch 195 loss: 0.00036605040077120066
batch 200 loss: 0.00036324376706033947
batch 205 loss: 0.00036843669367954136
batch 210 loss: 0.00036801481619477274
batch 215 loss: 0.0003723087778780609
batch 220 loss: 0.0003681330243125558
batch 225 loss: 0.00036006459267809985
batch 230 loss: 0.0003647857753094286
batch 235 loss: 0.0003611385705880821
batch 240 loss: 0.00035954529303126035
Training Loss: 0.0004048922935908195
Validation Loss: 0.0003416091489877241
Epoch 71:
batch 5 loss: 0.00036039125989191235
batch 10 loss: 0.0003644671465735883
batch 15 loss: 0.0003519929363392293
batch 20 loss: 0.00035644865129143
batch 25 loss: 0.0003547643078491092
batch 30 loss: 0.00035554709611460564
batch 35 loss: 0.0003543839557096362
batch 40 loss: 0.0003564545186236501
batch 45 loss: 0.0003554593538865447
batch 50 loss: 0.00035356704029254615
batch 55 loss: 0.00035216695396229626
batch 60 loss: 0.00035505731939338147
batch 65 loss: 0.0003533495590090752
batch 70 loss: 0.0003515333868563175
batch 75 loss: 0.0003512625175062567
batch 80 loss: 0.00035412346478551625
batch 85 loss: 0.0003516433935146779
batch 90 loss: 0.00035107212606817485
batch 95 loss: 0.00035029349965043366
batch 100 loss: 0.00035298026632517575
batch 105 loss: 0.00034995597670786085
batch 110 loss: 0.00035020962241105735
batch 115 loss: 0.0003581999219022691
batch 120 loss: 0.00034946295199915766
batch 125 loss: 0.0003476124256849289
batch 130 loss: 0.00035168126341886816
batch 135 loss: 0.00034621107624843717
batch 140 loss: 0.0003480822022538632
batch 145 loss: 0.00034921111073344947
batch 150 loss: 0.00034690470201894643
batch 155 loss: 0.00034559264313429596
batch 160 loss: 0.0003437051083892584
batch 165 loss: 0.00035047983401454986
batch 170 loss: 0.0003523302788380533
batch 175 loss: 0.0003496351884678006
batch 180 loss: 0.00034334425581619146
batch 185 loss: 0.00034262672998011114
batch 190 loss: 0.00034871985553763807
batch 195 loss: 0.0003466532041784376
batch 200 loss: 0.00034408706706017255
batch 205 loss: 0.000343135796720162
batch 210 loss: 0.0003426218405365944
batch 215 loss: 0.00034145372919738295
batch 220 loss: 0.000345558364642784
batch 225 loss: 0.00033768376451916995
batch 230 loss: 0.0003433536912780255
batch 235 loss: 0.00033794048358686267
batch 240 loss: 0.00034005283378064633
Training Loss: 0.00034965551409792773
Validation Loss: 0.00031555862030169615
Epoch 72:
batch 5 loss: 0.0003405893570743501
batch 10 loss: 0.0003407359239645302
batch 15 loss: 0.00033768489374779164
batch 20 loss: 0.0003339660877827555
batch 25 loss: 0.00033556482521817087
batch 30 loss: 0.00034499972243793307
batch 35 loss: 0.0003429499047342688
batch 40 loss: 0.0003382494789548218
batch 45 loss: 0.00033652985584922137
batch 50 loss: 0.0003356677480041981
batch 55 loss: 0.0003366557240951806
batch 60 loss: 0.0003334384877234697
batch 65 loss: 0.00033621930633671583
batch 70 loss: 0.00033641060581430794
batch 75 loss: 0.00033669010153971615
batch 80 loss: 0.00033475257223472
batch 85 loss: 0.0003322744509205222
batch 90 loss: 0.0003302423341665417
batch 95 loss: 0.0003330913314130157
batch 100 loss: 0.00032776929438114164
batch 105 loss: 0.0003292648529168218
batch 110 loss: 0.0003320658637676388
batch 115 loss: 0.0003333248198032379
batch 120 loss: 0.00033417263766750694
batch 125 loss: 0.00032707263017073274
batch 130 loss: 0.0003269222273956984
batch 135 loss: 0.000323614984517917
batch 140 loss: 0.000326610280899331
batch 145 loss: 0.0003294897731393576
batch 150 loss: 0.000329904438694939
batch 155 loss: 0.0003239827055949718
batch 160 loss: 0.0003231709997635335
batch 165 loss: 0.0003248662629630417
batch 170 loss: 0.00031950125703588127
batch 175 loss: 0.0003248472639825195
batch 180 loss: 0.0003200251143425703
batch 185 loss: 0.00031987339025363326
batch 190 loss: 0.00031854716944508256
batch 195 loss: 0.00031983815715648235
batch 200 loss: 0.0003162067849189043
batch 205 loss: 0.0003194257151335478
batch 210 loss: 0.0003189656476024538
batch 215 loss: 0.0003202606050763279
batch 220 loss: 0.00032064426341094077
batch 225 loss: 0.00031859661685302855
batch 230 loss: 0.00032052668393589556
batch 235 loss: 0.0003174509503878653
batch 240 loss: 0.00031415907433256506
Training Loss: 0.00032870444119907915
Validation Loss: 0.0002733201346321342
Epoch 73:
batch 5 loss: 0.00031468349625356494
batch 10 loss: 0.0003121792804449797
batch 15 loss: 0.00031090108677744865
batch 20 loss: 0.00031114406301639973
batch 25 loss: 0.0003123980015516281
batch 30 loss: 0.00031311940983869135
batch 35 loss: 0.0003121848334558308
batch 40 loss: 0.0003106521617155522
batch 45 loss: 0.00031018836889415977
batch 50 loss: 0.0003088779398240149
batch 55 loss: 0.0003093919309321791
batch 60 loss: 0.0003117254353128374
batch 65 loss: 0.0003078770590946078
batch 70 loss: 0.0003065025608520955
batch 75 loss: 0.00030922144651412964
batch 80 loss: 0.00030812041950412095
batch 85 loss: 0.00031029225792735817
batch 90 loss: 0.000309147872030735
batch 95 loss: 0.00031015544082038107
batch 100 loss: 0.0003076674009207636
batch 105 loss: 0.00030793327023275195
batch 110 loss: 0.0003071687591727823
batch 115 loss: 0.0003068003396037966
batch 120 loss: 0.00030906546162441374
batch 125 loss: 0.0003058596746996045
batch 130 loss: 0.0003065188589971513
batch 135 loss: 0.0003064672579057515
batch 140 loss: 0.00031180136138573287
batch 145 loss: 0.0003103430208284408
batch 150 loss: 0.0003101573558524251
batch 155 loss: 0.00030691585852764546
batch 160 loss: 0.00030630794353783133
batch 165 loss: 0.0003047615522518754
batch 170 loss: 0.0003067470795940608
batch 175 loss: 0.0003039197064936161
batch 180 loss: 0.00030831354670226576
batch 185 loss: 0.0003067358280532062
batch 190 loss: 0.00030635500443167987
batch 195 loss: 0.00030399857205338777
batch 200 loss: 0.00030402775737456975
batch 205 loss: 0.0003043205477297306
batch 210 loss: 0.00030476672109216454
batch 215 loss: 0.0003054253698792309
batch 220 loss: 0.0003049400460440665
batch 225 loss: 0.00030369904125109314
batch 230 loss: 0.0003052402229513973
batch 235 loss: 0.00030417345114983616
batch 240 loss: 0.00030187598313204946
Training Loss: 0.00030793895954654243
Validation Loss: 0.0002506832769237614
Epoch 74:
batch 5 loss: 0.00030211240518838165
batch 10 loss: 0.0003010657208506018
batch 15 loss: 0.00030355473281815646
batch 20 loss: 0.0003008249157574028
batch 25 loss: 0.00030031875940039754
batch 30 loss: 0.0002991267770994455
batch 35 loss: 0.00029784056823700666
batch 40 loss: 0.00029911643359810115
batch 45 loss: 0.0002977973024826497
batch 50 loss: 0.0002987921063322574
batch 55 loss: 0.0002977566386107355
batch 60 loss: 0.0002971055917441845
batch 65 loss: 0.0002979436423629522
batch 70 loss: 0.0002961513993795961
batch 75 loss: 0.00029604213195852933
batch 80 loss: 0.00029598978580906986
batch 85 loss: 0.0002973799069877714
batch 90 loss: 0.0002976778894662857
batch 95 loss: 0.0002991080516949296
batch 100 loss: 0.00029406589455902574
batch 105 loss: 0.0002976286981720477
batch 110 loss: 0.00029385192319750784
batch 115 loss: 0.0002969475986901671
batch 120 loss: 0.00029404732631519435
batch 125 loss: 0.00029476131894625726
batch 130 loss: 0.00029489803127944467
batch 135 loss: 0.00029453799361363054
batch 140 loss: 0.00029533368069678545
batch 145 loss: 0.0002934338641352952
batch 150 loss: 0.0002941058250144124
batch 155 loss: 0.0002958770899567753
batch 160 loss: 0.0002960203040856868
batch 165 loss: 0.00029668359784409406
batch 170 loss: 0.0002958132536150515
batch 175 loss: 0.00029444823157973585
batch 180 loss: 0.00029428628622554245
batch 185 loss: 0.0002953101880848408
batch 190 loss: 0.0002949879795778543
batch 195 loss: 0.00029574952786788345
batch 200 loss: 0.0002947527158539742
batch 205 loss: 0.0002940497361123562
batch 210 loss: 0.0002925451670307666
batch 215 loss: 0.00029475436895154417
batch 220 loss: 0.00029287463403306904
batch 225 loss: 0.00029396318714134393
batch 230 loss: 0.0002934131189249456
batch 235 loss: 0.00029344854992814363
batch 240 loss: 0.00029355785227380693
Training Loss: 0.00029628859798928414
Validation Loss: 0.00023554892904940062
Epoch 75:
batch 5 loss: 0.00029040491790510714
batch 10 loss: 0.0002920525730587542
batch 15 loss: 0.0002912174793891609
batch 20 loss: 0.0002910896437242627
batch 25 loss: 0.00029021622030995787
batch 30 loss: 0.0002909015107434243
batch 35 loss: 0.0002891424228437245
batch 40 loss: 0.0002908124530222267
batch 45 loss: 0.00029093906632624564
batch 50 loss: 0.000291810353519395
batch 55 loss: 0.0002893379016313702
batch 60 loss: 0.00029115991783328353
batch 65 loss: 0.00028941447380930184
batch 70 loss: 0.00028940957854501904
batch 75 loss: 0.00029013697640039026
batch 80 loss: 0.000289833772694692
batch 85 loss: 0.00029094620258547367
batch 90 loss: 0.00029095119680278003
batch 95 loss: 0.0002909927046857774
batch 100 loss: 0.0002885579538997263
batch 105 loss: 0.0002925470238551497
batch 110 loss: 0.00028902809717692437
batch 115 loss: 0.0002888615825213492
batch 120 loss: 0.00028826326015405355
batch 125 loss: 0.00029000064823776485
batch 130 loss: 0.00028861324535682796
batch 135 loss: 0.0002876775513868779
batch 140 loss: 0.00028849077061749996
batch 145 loss: 0.0002894346718676388
batch 150 loss: 0.0002896195859648287
batch 155 loss: 0.00028969242703169584
batch 160 loss: 0.0002887144801206887
batch 165 loss: 0.0002890463278163224
batch 170 loss: 0.0002890216128434986
batch 175 loss: 0.0002898325852584094
batch 180 loss: 0.0002873486140742898
batch 185 loss: 0.000289596407674253
batch 190 loss: 0.0002900414285250008
batch 195 loss: 0.00028918355819769205
batch 200 loss: 0.00028836954152211547
batch 205 loss: 0.0002878293744288385
batch 210 loss: 0.00028780486318282785
batch 215 loss: 0.00028831270756199954
batch 220 loss: 0.00028945665690116584
batch 225 loss: 0.0002883503562770784
batch 230 loss: 0.00028972186846658586
batch 235 loss: 0.00028907119412906467
batch 240 loss: 0.0002880077750887722
Training Loss: 0.0002896096986660268
Validation Loss: 0.00022908339791077498
Epoch 76:
batch 5 loss: 0.0002878437400795519
batch 10 loss: 0.00028727129101753236
batch 15 loss: 0.00028800891013816
batch 20 loss: 0.0002871966455131769
batch 25 loss: 0.0002874279394745827
batch 30 loss: 0.0002894514356739819
batch 35 loss: 0.0002879958541598171
batch 40 loss: 0.00028752534417435526
batch 45 loss: 0.00029005922260694206
batch 50 loss: 0.00028763574664480984
batch 55 loss: 0.0002859762927982956
batch 60 loss: 0.00028956063324585556
batch 65 loss: 0.00028767260373570026
batch 70 loss: 0.0002872273907996714
batch 75 loss: 0.0002878497121855617
batch 80 loss: 0.0002880565298255533
batch 85 loss: 0.0002872757147997618
batch 90 loss: 0.0002880602143704891
batch 95 loss: 0.00028919890755787494
batch 100 loss: 0.0002874427242204547
batch 105 loss: 0.00028845215565524994
batch 110 loss: 0.00028736659442074597
batch 115 loss: 0.0002880369604099542
batch 120 loss: 0.00028842449537478385
batch 125 loss: 0.0002876721788197756
batch 130 loss: 0.00028659129166044297
batch 135 loss: 0.00028884090716019273
batch 140 loss: 0.00028659045929089186
batch 145 loss: 0.0002889539464376867
batch 150 loss: 0.00028885636129416525
batch 155 loss: 0.00028822325402870773
batch 160 loss: 0.00028833032702095806
batch 165 loss: 0.00028963818331249056
batch 170 loss: 0.0002885699330363423
batch 175 loss: 0.00028854888514615593
batch 180 loss: 0.0002878138271626085
batch 185 loss: 0.0002870677970349789
batch 190 loss: 0.00028912940178997814
batch 195 loss: 0.00028800933505408467
batch 200 loss: 0.0002878933795727789
batch 205 loss: 0.0002874208672437817
batch 210 loss: 0.0002875289996154606
batch 215 loss: 0.00028775971732102333
batch 220 loss: 0.0002898771897889674
batch 225 loss: 0.00028999015921726823
batch 230 loss: 0.00028730578487738966
batch 235 loss: 0.00028766426839865744
batch 240 loss: 0.0002886389964260161
Training Loss: 0.0002880819272832014
Validation Loss: 0.0002269747550599277
Epoch 77:
batch 5 loss: 0.0002886065281927586
batch 10 loss: 0.0002906518115196377
batch 15 loss: 0.00028993476298637687
batch 20 loss: 0.00028853256371803583
batch 25 loss: 0.00028775681857950985
batch 30 loss: 0.0002865386544726789
batch 35 loss: 0.00028703490388579664
batch 40 loss: 0.0002871057658921927
batch 45 loss: 0.00028676348156295715
batch 50 loss: 0.0002902690146584064
batch 55 loss: 0.0002868030278477818
batch 60 loss: 0.00028636042261496184
batch 65 loss: 0.0002881398017052561
batch 70 loss: 0.00028656432987190784
batch 75 loss: 0.0002879864303395152
batch 80 loss: 0.0002870792581234127
batch 85 loss: 0.00028992569423280656
batch 90 loss: 0.00028751728241331874
batch 95 loss: 0.00028860702295787635
batch 100 loss: 0.0002864212088752538
batch 105 loss: 0.0002872433280572295
batch 110 loss: 0.0002887143695261329
batch 115 loss: 0.0002864878682885319
batch 120 loss: 0.00028751871432177725
batch 125 loss: 0.00028763049631379544
batch 130 loss: 0.0002877478313166648
batch 135 loss: 0.0002875959617085755
batch 140 loss: 0.0002864580252207816
batch 145 loss: 0.0002861571731045842
batch 150 loss: 0.0002885336813051254
batch 155 loss: 0.00028725230949930845
batch 160 loss: 0.00028824418550357225
batch 165 loss: 0.0002884021494537592
batch 170 loss: 0.00028891615802422165
batch 175 loss: 0.0002865437651053071
batch 180 loss: 0.000285844987956807
batch 185 loss: 0.00028673542547039685
batch 190 loss: 0.0002872736949939281
batch 195 loss: 0.00028718768153339623
batch 200 loss: 0.0002867062750738114
batch 205 loss: 0.00028678037342615425
batch 210 loss: 0.000285779288969934
batch 215 loss: 0.00028690106119029225
batch 220 loss: 0.00028543263906612994
batch 225 loss: 0.0002882554312236607
batch 230 loss: 0.0002878326748032123
batch 235 loss: 0.00028711342019960284
batch 240 loss: 0.0002887968730647117
Training Loss: 0.0002875559297535801
Validation Loss: 0.00022939498643002784
Epoch 78:
batch 5 loss: 0.000287626771023497
batch 10 loss: 0.00029430727008730175
batch 15 loss: 0.00029364738729782404
batch 20 loss: 0.00029158699326217177
batch 25 loss: 0.00028723826399073004
batch 30 loss: 0.0002898238075431436
batch 35 loss: 0.00028748007607646284
batch 40 loss: 0.0002891626674681902
batch 45 loss: 0.00029179053381085397
batch 50 loss: 0.00028714591171592475
batch 55 loss: 0.000288260035449639
batch 60 loss: 0.0002865081652998924
batch 65 loss: 0.00028810048825107516
batch 70 loss: 0.00028675785288214686
batch 75 loss: 0.00028505208902060983
batch 80 loss: 0.0002852298493962735
batch 85 loss: 0.00028852806426584723
batch 90 loss: 0.0002881464664824307
batch 95 loss: 0.00028595355688594283
batch 100 loss: 0.00028670234605669974
batch 105 loss: 0.0002874115889426321
batch 110 loss: 0.00028769213240593673
batch 115 loss: 0.0002889715076889843
batch 120 loss: 0.00028597444179467857
batch 125 loss: 0.0002883912879042327
batch 130 loss: 0.00028665596037171783
batch 135 loss: 0.00028527652611956
batch 140 loss: 0.00028565799002535643
batch 145 loss: 0.0002880850632209331
batch 150 loss: 0.00028950205887667835
batch 155 loss: 0.0002873758261557668
batch 160 loss: 0.0002874373807571828
batch 165 loss: 0.00028834634576924145
batch 170 loss: 0.0002883115957956761
batch 175 loss: 0.00028746254392899575
batch 180 loss: 0.0002867494884412736
batch 185 loss: 0.0002870286349207163
batch 190 loss: 0.0002854673424735665
batch 195 loss: 0.00028704790165647867
batch 200 loss: 0.00028771312790922823
batch 205 loss: 0.0002863583795260638
batch 210 loss: 0.00028462300542742014
batch 215 loss: 0.0002863616799004376
batch 220 loss: 0.0002861013577785343
batch 225 loss: 0.00028614006005227565
batch 230 loss: 0.00028414762346073985
batch 235 loss: 0.00028684832504950465
batch 240 loss: 0.0002854031277820468
Training Loss: 0.00028753314375838576
Validation Loss: 0.00022399185036192648
Epoch 79:
batch 5 loss: 0.0003349590580910444
batch 10 loss: 0.0004444297926966101
batch 15 loss: 0.0005016328941565007
batch 20 loss: 0.00045205592759884895
batch 25 loss: 0.00041541277896612884
batch 30 loss: 0.0003896739333868027
batch 35 loss: 0.00036604051711037756
batch 40 loss: 0.00035364528303034605
batch 45 loss: 0.0003411134355701506
batch 50 loss: 0.0003295984759461135
batch 55 loss: 0.00032607453758828344
batch 60 loss: 0.00032064306433312597
batch 65 loss: 0.0003153591591399163
batch 70 loss: 0.00031456310534849763
batch 75 loss: 0.0003107665746938437
batch 80 loss: 0.00030890643829479815
batch 85 loss: 0.00030668200342915953
batch 90 loss: 0.0003038052702322602
batch 95 loss: 0.0003033600049093366
batch 100 loss: 0.0003012434986885637
batch 105 loss: 0.00029979937244206667
batch 110 loss: 0.0002986829320434481
batch 115 loss: 0.000297520199092105
batch 120 loss: 0.00029625606257468464
batch 125 loss: 0.0002989731845445931
batch 130 loss: 0.00029543719138018786
batch 135 loss: 0.00029497744399122896
batch 140 loss: 0.0002953203278593719
batch 145 loss: 0.0002940352482255548
batch 150 loss: 0.00029591216589324175
batch 155 loss: 0.0002931454742792994
batch 160 loss: 0.0002932587522082031
batch 165 loss: 0.00029454793548211455
batch 170 loss: 0.0002927277877461165
batch 175 loss: 0.000291606254177168
batch 180 loss: 0.0002919880033005029
batch 185 loss: 0.00029021216905675826
batch 190 loss: 0.0002915141580160707
batch 195 loss: 0.00029214697424322366
batch 200 loss: 0.00029216069378890097
batch 205 loss: 0.0002911522053182125
batch 210 loss: 0.0002906329755205661
batch 215 loss: 0.0002889304945711046
batch 220 loss: 0.00028805636102333663
batch 225 loss: 0.0002889689581934363
batch 230 loss: 0.0002875422709621489
batch 235 loss: 0.00028600783552974464
batch 240 loss: 0.0002860261593014002
Training Loss: 0.00031744802799948957
Validation Loss: 0.00025198748286735885
Epoch 80:
batch 5 loss: 0.0002979950746521354
batch 10 loss: 0.0003209359478205442
batch 15 loss: 0.000313382112653926
batch 20 loss: 0.0003064779215492308
batch 25 loss: 0.00029863862437196076
batch 30 loss: 0.0002946675813291222
batch 35 loss: 0.0002930198214016855
batch 40 loss: 0.00029118030215613544
batch 45 loss: 0.0002876195881981403
batch 50 loss: 0.0002887396141886711
batch 55 loss: 0.00028810575604438783
batch 60 loss: 0.0002875449659768492
batch 65 loss: 0.0002872253593523055
batch 70 loss: 0.0002877544902730733
batch 75 loss: 0.0002856338396668434
batch 80 loss: 0.00028409177903085945
batch 85 loss: 0.0002846496528945863
batch 90 loss: 0.0002831550198607147
batch 95 loss: 0.00028428224031813444
batch 100 loss: 0.00028496519080363215
batch 105 loss: 0.00028562603401951494
batch 110 loss: 0.0002847406023647636
batch 115 loss: 0.00028689721948467196
batch 120 loss: 0.00028862281469628216
batch 125 loss: 0.00028762519359588624
batch 130 loss: 0.00028670633910223844
batch 135 loss: 0.00028716829838231205
batch 140 loss: 0.0002862511959392577
batch 145 loss: 0.0002843529742676765
batch 150 loss: 0.0002859820902813226
batch 155 loss: 0.00028595341136679054
batch 160 loss: 0.00028372936067171394
batch 165 loss: 0.00028385291807353497
batch 170 loss: 0.0002835531486198306
batch 175 loss: 0.00028098748880438506
batch 180 loss: 0.0002822840237058699
batch 185 loss: 0.00028168766875751315
batch 190 loss: 0.0002839034248609096
batch 195 loss: 0.0002805715368594974
batch 200 loss: 0.00028240171377547085
batch 205 loss: 0.00028284472064115106
batch 210 loss: 0.00028397025889717045
batch 215 loss: 0.00028194834594614805
batch 220 loss: 0.00028159536886960266
batch 225 loss: 0.0002848918142262846
batch 230 loss: 0.0002827547665219754
batch 235 loss: 0.00028375540277920664
batch 240 loss: 0.0002840106084477156
Training Loss: 0.0002876819505521174
Validation Loss: 0.0002363839853690782
Epoch 81:
batch 5 loss: 0.0002857059938833117
batch 10 loss: 0.00028322040452621877
batch 15 loss: 0.00028620894881896674
batch 20 loss: 0.0002899840648751706
batch 25 loss: 0.00028696346562355756
batch 30 loss: 0.000284575525438413
batch 35 loss: 0.00028383801109157505
batch 40 loss: 0.0002856911101844162
batch 45 loss: 0.00028312242357060314
batch 50 loss: 0.0002827822987455875
batch 55 loss: 0.0002826230018399656
batch 60 loss: 0.00028237359947524965
batch 65 loss: 0.0002829800418112427
batch 70 loss: 0.0002821788482833654
batch 75 loss: 0.0002796152257360518
batch 80 loss: 0.0002813467523083091
batch 85 loss: 0.0002822368580382317
batch 90 loss: 0.00028094935696572066
batch 95 loss: 0.0002834779501426965
batch 100 loss: 0.0002832180820405483
batch 105 loss: 0.0002821186266373843
batch 110 loss: 0.00028062303317710757
batch 115 loss: 0.00027895448147319257
batch 120 loss: 0.0002792498737107962
batch 125 loss: 0.0002788689162116498
batch 130 loss: 0.0002824464754667133
batch 135 loss: 0.00028322312282398344
batch 140 loss: 0.00028281792183406653
batch 145 loss: 0.0002802234434057027
batch 150 loss: 0.00028101418283768
batch 155 loss: 0.0002793136634863913
batch 160 loss: 0.0002817710512317717
batch 165 loss: 0.0002822599024511874
batch 170 loss: 0.00028294292860664427
batch 175 loss: 0.00028189742006361483
batch 180 loss: 0.00028101265197619794
batch 185 loss: 0.00027946482296101747
batch 190 loss: 0.00028087512473575773
batch 195 loss: 0.000282087828963995
batch 200 loss: 0.00028060710174031555
batch 205 loss: 0.00027940428699366746
batch 210 loss: 0.0002794873609673232
batch 215 loss: 0.00027895650709979235
batch 220 loss: 0.00028217313229106367
batch 225 loss: 0.0002805185969918966
batch 230 loss: 0.00027913812664337456
batch 235 loss: 0.00027998493751510976
batch 240 loss: 0.00027925257454626263
Training Loss: 0.0002819537512550596
Validation Loss: 0.00024832022560682766
Epoch 82:
batch 5 loss: 0.0002809651312418282
batch 10 loss: 0.00027952418895438313
batch 15 loss: 0.0002801152877509594
batch 20 loss: 0.0002782297611702234
batch 25 loss: 0.00027900070999749006
batch 30 loss: 0.00027952836244367064
batch 35 loss: 0.0002775633183773607
batch 40 loss: 0.00027818437665700914
batch 45 loss: 0.0002767899539321661
batch 50 loss: 0.0002767784229945391
batch 55 loss: 0.0002785002288874239
batch 60 loss: 0.0002763979020528495
batch 65 loss: 0.0002780728449579328
batch 70 loss: 0.00027849988546222446
batch 75 loss: 0.00028004879713989795
batch 80 loss: 0.00027930661453865466
batch 85 loss: 0.0002785347984172404
batch 90 loss: 0.0002809208119288087
batch 95 loss: 0.0002787578327115625
batch 100 loss: 0.00027705449028871956
batch 105 loss: 0.0002756134257651865
batch 110 loss: 0.0002751828404143453
batch 115 loss: 0.00027558914734981954
batch 120 loss: 0.000276278133969754
batch 125 loss: 0.0002756663190666586
batch 130 loss: 0.00027529053040780126
batch 135 loss: 0.0002765500859823078
batch 140 loss: 0.0002784507058095187
batch 145 loss: 0.0002782900934107602
batch 150 loss: 0.00027704014792107046
batch 155 loss: 0.00027719693607650695
batch 160 loss: 0.0002782776311505586
batch 165 loss: 0.0002785923948977143
batch 170 loss: 0.00027815664070658387
batch 175 loss: 0.0002770804683677852
batch 180 loss: 0.00027629791875369845
batch 185 loss: 0.00027681038482114674
batch 190 loss: 0.0002766046265605837
batch 195 loss: 0.0002777115383651108
batch 200 loss: 0.00028148281271569433
batch 205 loss: 0.00028128515114076433
batch 210 loss: 0.00028309819754213095
batch 215 loss: 0.00027942333254031836
batch 220 loss: 0.0002773279440589249
batch 225 loss: 0.0002745575737208128
batch 230 loss: 0.00027580061578191817
batch 235 loss: 0.0002756685600616038
batch 240 loss: 0.0002746888902038336
Training Loss: 0.000277849724322247
Validation Loss: 0.00023545292278868147
Epoch 83:
batch 5 loss: 0.0002745832258369774
batch 10 loss: 0.00027344779809936883
batch 15 loss: 0.00027425673906691375
batch 20 loss: 0.00027302829548716547
batch 25 loss: 0.0002741807897109538
batch 30 loss: 0.00027327702846378086
batch 35 loss: 0.00027418400277383624
batch 40 loss: 0.00027281921938993037
batch 45 loss: 0.00027343708206899463
batch 50 loss: 0.0002741760981734842
batch 55 loss: 0.00027324698166921737
batch 60 loss: 0.0002738780225627124
batch 65 loss: 0.0002754158456809819
batch 70 loss: 0.0002734725712798536
batch 75 loss: 0.0002728963561821729
batch 80 loss: 0.0002736471884418279
batch 85 loss: 0.0002729534113314003
batch 90 loss: 0.00027289101271890106
batch 95 loss: 0.0002747285587247461
batch 100 loss: 0.00027450051275081935
batch 105 loss: 0.0002731055428739637
batch 110 loss: 0.0002733183791860938
batch 115 loss: 0.0002763438154943287
batch 120 loss: 0.00027380246901884673
batch 125 loss: 0.0002733634959440678
batch 130 loss: 0.0002734711917582899
batch 135 loss: 0.0002737656235694885
batch 140 loss: 0.0002733985369559377
batch 145 loss: 0.0002734017092734575
batch 150 loss: 0.00027349636075086893
batch 155 loss: 0.000272236333694309
batch 160 loss: 0.0002732541935984045
batch 165 loss: 0.0002720762859098613
batch 170 loss: 0.0002740992757026106
batch 175 loss: 0.00027305218973197045
batch 180 loss: 0.00027440349804237486
batch 185 loss: 0.00027450153138488533
batch 190 loss: 0.0002732554916292429
batch 195 loss: 0.00027444709558039905
batch 200 loss: 0.00027323460089974106
batch 205 loss: 0.00027345233247615396
batch 210 loss: 0.000272613822016865
batch 215 loss: 0.00027194207068532706
batch 220 loss: 0.00027440579724498094
batch 225 loss: 0.0002732487744651735
batch 230 loss: 0.0002736120310146362
batch 235 loss: 0.00027279137284494934
batch 240 loss: 0.00027391702169552443
Training Loss: 0.00027360482466368314
Validation Loss: 0.00022135157196316867
Epoch 84:
batch 5 loss: 0.00027267070254310966
batch 10 loss: 0.0002733758185058832
batch 15 loss: 0.0002729628817178309
batch 20 loss: 0.0002719393989536911
batch 25 loss: 0.0002713593130465597
batch 30 loss: 0.00027015218511223794
batch 35 loss: 0.00027090050862170755
batch 40 loss: 0.00027176245930604637
batch 45 loss: 0.0002695258299354464
batch 50 loss: 0.00027223622892051934
batch 55 loss: 0.0002720409887842834
batch 60 loss: 0.00027241611387580634
batch 65 loss: 0.00027100523584522307
batch 70 loss: 0.00027152510010637344
batch 75 loss: 0.00027265886310487983
batch 80 loss: 0.0002712281187996268
batch 85 loss: 0.00027118668076582254
batch 90 loss: 0.00027063097804784774
batch 95 loss: 0.00027076537953689693
batch 100 loss: 0.00026989543111994864
batch 105 loss: 0.000271031551528722
batch 110 loss: 0.000269616098375991
batch 115 loss: 0.000272144575137645
batch 120 loss: 0.00027007285389117895
batch 125 loss: 0.0002696123265195638
batch 130 loss: 0.00026983486022800205
batch 135 loss: 0.0002715139067731798
batch 140 loss: 0.00027116016717627646
batch 145 loss: 0.00027049354393966497
batch 150 loss: 0.00027180674951523545
batch 155 loss: 0.0002687290543690324
batch 160 loss: 0.0002706222352571785
batch 165 loss: 0.0002696929615922272
batch 170 loss: 0.0002712517103645951
batch 175 loss: 0.0002710616041440517
batch 180 loss: 0.000269538740394637
batch 185 loss: 0.0002705883176531643
batch 190 loss: 0.00027015446103177964
batch 195 loss: 0.0002708032028749585
batch 200 loss: 0.0002705151215195656
batch 205 loss: 0.000270018435548991
batch 210 loss: 0.000271158356918022
batch 215 loss: 0.00027188162202946843
batch 220 loss: 0.00027033323422074316
batch 225 loss: 0.00026976820663549006
batch 230 loss: 0.0002698184398468584
batch 235 loss: 0.0002708702173549682
batch 240 loss: 0.0002706630912143737
Training Loss: 0.00027093737213969386
Validation Loss: 0.0002215375076048076
Epoch 85:
batch 5 loss: 0.00026921049575321374
batch 10 loss: 0.0002694166440051049
batch 15 loss: 0.0002710921922698617
batch 20 loss: 0.00026966363075189295
batch 25 loss: 0.0002704626473132521
batch 30 loss: 0.0002709467429667711
batch 35 loss: 0.0002698345633689314
batch 40 loss: 0.0002693486399948597
batch 45 loss: 0.0002685679122805595
batch 50 loss: 0.00026899251388385893
batch 55 loss: 0.0002702930651139468
batch 60 loss: 0.0002705196966417134
batch 65 loss: 0.0002708851359784603
batch 70 loss: 0.0002695623901672661
batch 75 loss: 0.0002703807840589434
batch 80 loss: 0.0002691768575459719
batch 85 loss: 0.00027052276418544353
batch 90 loss: 0.00026854274328798057
batch 95 loss: 0.00026892375899478793
batch 100 loss: 0.0002699350123293698
batch 105 loss: 0.0002678790013305843
batch 110 loss: 0.000269582070177421
batch 115 loss: 0.000268187775509432
batch 120 loss: 0.000266693189041689
batch 125 loss: 0.00026878000353462993
batch 130 loss: 0.00026895867777056994
batch 135 loss: 0.00026846779510378835
batch 140 loss: 0.0002678822202142328
batch 145 loss: 0.0002697294170502573
batch 150 loss: 0.0002684037084691226
batch 155 loss: 0.0002688651788048446
batch 160 loss: 0.000270995672326535
batch 165 loss: 0.0002696151263080537
batch 170 loss: 0.000269573915284127
batch 175 loss: 0.00026822792133316395
batch 180 loss: 0.00027061643777415156
batch 185 loss: 0.0002698996860999614
batch 190 loss: 0.00027037711115553977
batch 195 loss: 0.00027133359690196813
batch 200 loss: 0.00026884129038080574
batch 205 loss: 0.0002689654298592359
batch 210 loss: 0.0002696389623451978
batch 215 loss: 0.00026920901727862657
batch 220 loss: 0.0002679869532585144
batch 225 loss: 0.00027003483264707027
batch 230 loss: 0.0002688627748284489
batch 235 loss: 0.0002699139411561191
batch 240 loss: 0.0002696991548873484
Training Loss: 0.00026944789691090896
Validation Loss: 0.00021500003203982486
Epoch 86:
batch 5 loss: 0.0002686945837922394
batch 10 loss: 0.00026786465314216913
batch 15 loss: 0.0002692711655981839
batch 20 loss: 0.00026949410093948247
batch 25 loss: 0.00027020688285119834
batch 30 loss: 0.0002698850876186043
batch 35 loss: 0.00026784012443386017
batch 40 loss: 0.0002683874510694295
batch 45 loss: 0.0002704120066482574
batch 50 loss: 0.0002685154729988426
batch 55 loss: 0.000269941269652918
batch 60 loss: 0.0002707829466089606
batch 65 loss: 0.0002691949426662177
batch 70 loss: 0.0002685135754290968
batch 75 loss: 0.0002677411597687751
batch 80 loss: 0.00026898233918473127
batch 85 loss: 0.000270289956824854
batch 90 loss: 0.0002683446218725294
batch 95 loss: 0.00026832332368940113
batch 100 loss: 0.0002685763698536903
batch 105 loss: 0.0002695491013582796
batch 110 loss: 0.000270439573796466
batch 115 loss: 0.0002678516902960837
batch 120 loss: 0.00026881095254793763
batch 125 loss: 0.0002697310177609324
batch 130 loss: 0.0002694595837965608
batch 135 loss: 0.00026982014533132314
batch 140 loss: 0.0002685804152861238
batch 145 loss: 0.00026967398007400335
batch 150 loss: 0.0002698264783248305
batch 155 loss: 0.00026897459174506365
batch 160 loss: 0.00027131475508213043
batch 165 loss: 0.00026904052356258035
batch 170 loss: 0.00027028737240470947
batch 175 loss: 0.00026941769174300135
batch 180 loss: 0.0002701786404941231
batch 185 loss: 0.0002693156769964844
batch 190 loss: 0.0002695542818401009
batch 195 loss: 0.00026880879886448383
batch 200 loss: 0.0002686561900191009
batch 205 loss: 0.0002700119744986296
batch 210 loss: 0.0002690090914256871
batch 215 loss: 0.00026772247510962186
batch 220 loss: 0.0002695776813197881
batch 225 loss: 0.0002692222245968878
batch 230 loss: 0.0002696419192943722
batch 235 loss: 0.00026888735592365263
batch 240 loss: 0.0002689522225409746
Training Loss: 0.00026924121751411195
Validation Loss: 0.00021463338416651822
Epoch 87:
batch 5 loss: 0.0002726628154050559
batch 10 loss: 0.0002724565099924803
batch 15 loss: 0.0002707478473894298
batch 20 loss: 0.0002705833525396883
batch 25 loss: 0.00026963662821799517
batch 30 loss: 0.00027006633463315665
batch 35 loss: 0.00026826499379239976
batch 40 loss: 0.0002683890168555081
batch 45 loss: 0.0002699523232877254
batch 50 loss: 0.00026847947156056763
batch 55 loss: 0.0002689052140340209
batch 60 loss: 0.000270348705817014
batch 65 loss: 0.00027001461712643503
batch 70 loss: 0.00026998380781151354
batch 75 loss: 0.00027032496873289345
batch 80 loss: 0.0002693979709874839
batch 85 loss: 0.00026811720454134047
batch 90 loss: 0.0002690687542781234
batch 95 loss: 0.00027073228266090156
batch 100 loss: 0.0002687188214622438
batch 105 loss: 0.0002670394314918667
batch 110 loss: 0.0002677061187569052
batch 115 loss: 0.0002710833679884672
batch 120 loss: 0.0002678779710549861
batch 125 loss: 0.00026824945234693587
batch 130 loss: 0.0002686013176571578
batch 135 loss: 0.00026862555532716217
batch 140 loss: 0.00026857526390813293
batch 145 loss: 0.0002696170995477587
batch 150 loss: 0.00026939508970826866
batch 155 loss: 0.00026953995111398397
batch 160 loss: 0.0002697679854463786
batch 165 loss: 0.00026861787773668766
batch 170 loss: 0.00026817292091436685
batch 175 loss: 0.00026922313845716416
batch 180 loss: 0.00026921603130176664
batch 185 loss: 0.00026957171503454446
batch 190 loss: 0.00026750777033157647
batch 195 loss: 0.00026807623216882346
batch 200 loss: 0.00026881064986810087
batch 205 loss: 0.0002694501308724284
batch 210 loss: 0.0002693947637453675
batch 215 loss: 0.0002688614069484174
batch 220 loss: 0.0002677973126992583
batch 225 loss: 0.0002684050239622593
batch 230 loss: 0.0002681170823052526
batch 235 loss: 0.0002694224996957928
batch 240 loss: 0.00026814597658813
Training Loss: 0.0002692025162104983
Validation Loss: 0.00020850167250803983
Epoch 88:
batch 5 loss: 0.00027382993139326575
batch 10 loss: 0.0004445491300430149
batch 15 loss: 0.00045959075214341283
batch 20 loss: 0.00042574200197122993
batch 25 loss: 0.0004028626659419388
batch 30 loss: 0.00038294949918054043
batch 35 loss: 0.00036704419762827455
batch 40 loss: 0.0003573670517653227
batch 45 loss: 0.0003469511982984841
batch 50 loss: 0.00033793537877500055
batch 55 loss: 0.0003337425587233156
batch 60 loss: 0.00032655257382430136
batch 65 loss: 0.00032278416329063476
batch 70 loss: 0.0003203878295607865
batch 75 loss: 0.00031689575989730657
batch 80 loss: 0.0003158133360557258
batch 85 loss: 0.0003159566374961287
batch 90 loss: 0.00031136201578192414
batch 95 loss: 0.000309880031272769
batch 100 loss: 0.0003081157570704818
batch 105 loss: 0.0003080367750953883
batch 110 loss: 0.00030581792816519737
batch 115 loss: 0.00030455803498625756
batch 120 loss: 0.00030377256334759297
batch 125 loss: 0.00030208208481781186
batch 130 loss: 0.0002999665040988475
batch 135 loss: 0.0002996825147420168
batch 140 loss: 0.00030081630684435367
batch 145 loss: 0.0002988684515003115
batch 150 loss: 0.00029634752427227796
batch 155 loss: 0.0002973336260765791
batch 160 loss: 0.0002959197328891605
batch 165 loss: 0.0002958580094855279
batch 170 loss: 0.00029431740986183284
batch 175 loss: 0.0002942113555036485
batch 180 loss: 0.0002952695358544588
batch 185 loss: 0.00029323456110432746
batch 190 loss: 0.0002927723980974406
batch 195 loss: 0.0002915188786573708
batch 200 loss: 0.00029263904434628785
batch 205 loss: 0.0002910901268478483
batch 210 loss: 0.0002905201050452888
batch 215 loss: 0.00029037066269665956
batch 220 loss: 0.0002903220127336681
batch 225 loss: 0.0002884799148887396
batch 230 loss: 0.00028959909686818717
batch 235 loss: 0.00028952584252692757
batch 240 loss: 0.0002881092194002122
Training Loss: 0.0003179448477264183
Validation Loss: 0.0003357754981455704
Epoch 89:
batch 5 loss: 0.00031089723343029617
batch 10 loss: 0.000340327707817778
batch 15 loss: 0.00032147422898560763
batch 20 loss: 0.0003097182605415583
batch 25 loss: 0.0003033356333617121
batch 30 loss: 0.0002974380331579596
batch 35 loss: 0.00029619233100675046
batch 40 loss: 0.0002945358457509428
batch 45 loss: 0.0002913004718720913
batch 50 loss: 0.0002913342555984855
batch 55 loss: 0.0002894005796406418
batch 60 loss: 0.00028975335881114005
batch 65 loss: 0.00028863227926194667
batch 70 loss: 0.00028775432147085664
batch 75 loss: 0.00028689602622762324
batch 80 loss: 0.0002893451484851539
batch 85 loss: 0.0002861785877030343
batch 90 loss: 0.00028733105282299223
batch 95 loss: 0.0002865656861104071
batch 100 loss: 0.00028619515942409637
batch 105 loss: 0.00028544693486765027
batch 110 loss: 0.000285145896486938
batch 115 loss: 0.000285864039324224
batch 120 loss: 0.00028562525985762475
batch 125 loss: 0.0002858029154594988
batch 130 loss: 0.0002846413350198418
batch 135 loss: 0.0002863790141418576
batch 140 loss: 0.00028485136572271587
batch 145 loss: 0.00028604905237443744
batch 150 loss: 0.00028492623823694885
batch 155 loss: 0.00028581272927112876
batch 160 loss: 0.0002857153653167188
batch 165 loss: 0.00028407653444446624
batch 170 loss: 0.00028398912982083855
batch 175 loss: 0.00028547546826303006
batch 180 loss: 0.000284960784483701
batch 185 loss: 0.0002864835609216243
batch 190 loss: 0.00028608861612156034
batch 195 loss: 0.00028555807075463234
batch 200 loss: 0.00028402861789800227
batch 205 loss: 0.00028466126532293855
batch 210 loss: 0.00028289724141359327
batch 215 loss: 0.0002839814871549606
batch 220 loss: 0.0002831258636433631
batch 225 loss: 0.00028478075983002783
batch 230 loss: 0.0002825348172336817
batch 235 loss: 0.00028368314378894864
batch 240 loss: 0.00028381444280967116
Training Loss: 0.0002898126281555354
Validation Loss: 0.00021961190504953264
Epoch 90:
batch 5 loss: 0.00030966741614975036
batch 10 loss: 0.0004936231533065438
batch 15 loss: 0.0005585740436799824
batch 20 loss: 0.0005575853167101741
batch 25 loss: 0.0005577772972173989
batch 30 loss: 0.0005576825235038996
batch 35 loss: 0.0005576866678893566
batch 40 loss: 0.0005576880881562829
batch 45 loss: 0.0005577550153248012
batch 50 loss: 0.0005576331517659127
batch 55 loss: 0.0005575644434429705
batch 60 loss: 0.0005577330477535725
batch 65 loss: 0.0005576229537837208
batch 70 loss: 0.0005575999151915312
batch 75 loss: 0.0005577386589720845
batch 80 loss: 0.0005577022559009493
batch 85 loss: 0.0005576610914431512
batch 90 loss: 0.0005577225703746081
batch 95 loss: 0.0005577358650043606
batch 100 loss: 0.0005576660507358611
batch 105 loss: 0.0005576952942647039
batch 110 loss: 0.0005577267380431295
batch 115 loss: 0.0005576383555307984
batch 120 loss: 0.0005576397525146604
batch 125 loss: 0.0005576787516474724
batch 130 loss: 0.000557734863832593
batch 135 loss: 0.0005576499155722558
batch 140 loss: 0.00055762022966519
batch 145 loss: 0.0005577034433372318
batch 150 loss: 0.0005577567731961608
batch 155 loss: 0.000557731743901968
batch 160 loss: 0.0005577008705586195
batch 165 loss: 0.0005576339783146978
batch 170 loss: 0.0005577323958277702
batch 175 loss: 0.0005576370167545974
batch 180 loss: 0.0005577303352765739
batch 185 loss: 0.000557699182536453
batch 190 loss: 0.0005575863178819418
batch 195 loss: 0.0005577832111157477
batch 200 loss: 0.0005576343275606633
batch 205 loss: 0.0005575857125222683
batch 210 loss: 0.0005577023955993354
batch 215 loss: 0.0005577735370025039
batch 220 loss: 0.0005576887866482139
batch 225 loss: 0.000557695422321558
batch 230 loss: 0.0005577329313382507
batch 235 loss: 0.0005577015574090183
batch 240 loss: 0.0005576326744630933
Training Loss: 0.0005512009591863413
Validation Loss: 0.0005576931609539316
Epoch 91:
batch 5 loss: 0.0005577050615102053
batch 10 loss: 0.0005575492512434721
batch 15 loss: 0.0005576673895120621
batch 20 loss: 0.0005577335134148598
batch 25 loss: 0.0005575835122726858
batch 30 loss: 0.0005576674710027873
batch 35 loss: 0.0005577130592428148
batch 40 loss: 0.000557805725838989
batch 45 loss: 0.0005576563882641495
batch 50 loss: 0.00055754886707291
batch 55 loss: 0.0005577079020440579
batch 60 loss: 0.0005577279138378799
batch 65 loss: 0.0005576665978878736
batch 70 loss: 0.0005576546653173863
batch 75 loss: 0.0005577985080890358
batch 80 loss: 0.0005577287869527936
batch 85 loss: 0.000557697145268321
batch 90 loss: 0.000557767937425524
batch 95 loss: 0.0005576915456913412
batch 100 loss: 0.000557592127006501
batch 105 loss: 0.0005575881572440266
batch 110 loss: 0.0005577009986154735
batch 115 loss: 0.0005576767842285335
batch 120 loss: 0.0005576301366090775
batch 125 loss: 0.0005576767493039369
batch 130 loss: 0.0005576492985710502
batch 135 loss: 0.0005577534320764244
batch 140 loss: 0.0005576792638748885
batch 145 loss: 0.0005576050723902881
batch 150 loss: 0.000557721988297999
batch 155 loss: 0.0005576040945015848
batch 160 loss: 0.0005576883093453943
batch 165 loss: 0.0005577142466790975
batch 170 loss: 0.0005575977033004164
batch 175 loss: 0.0005577375181019306
batch 180 loss: 0.0005577751086093486
batch 185 loss: 0.0005576602765358984
batch 190 loss: 0.0005576585535891354
batch 195 loss: 0.0005576844210736454
batch 200 loss: 0.0005577032105065882
batch 205 loss: 0.0005577053758315742
batch 210 loss: 0.0005577432573772966
batch 215 loss: 0.0005576266325078904
batch 220 loss: 0.0005576758179813623
batch 225 loss: 0.0005576862255111337
batch 230 loss: 0.0005577264237217605
batch 235 loss: 0.0005577723262831569
batch 240 loss: 0.0005576880648732185
Training Loss: 0.0005576831836757872
Validation Loss: 0.0005577113304752856
Epoch 92:
batch 5 loss: 0.0005575031973421574
batch 10 loss: 0.0005575883551500738
batch 15 loss: 0.0005577445030212402
batch 20 loss: 0.0005575786461122334
batch 25 loss: 0.0005576037801802158
batch 30 loss: 0.0005574746523052454
batch 35 loss: 0.0005570242065005004
batch 40 loss: 0.0005560085875913501
batch 45 loss: 0.0005555977113544941
batch 50 loss: 0.0005577980889938771
batch 55 loss: 0.0005576839321292937
batch 60 loss: 0.0005577841773629188
batch 65 loss: 0.0005577578675001859
batch 70 loss: 0.0005577516742050648
batch 75 loss: 0.0005576536990702152
batch 80 loss: 0.0005577734438702465
batch 85 loss: 0.0005576415453106165
batch 90 loss: 0.0005575631046667695
batch 95 loss: 0.0005576197290793061
batch 100 loss: 0.000557809486053884
batch 105 loss: 0.0005577681586146355
batch 110 loss: 0.0005577659350819886
batch 115 loss: 0.0005576332448981702
batch 120 loss: 0.0005576303345151245
batch 125 loss: 0.0005576807889156044
batch 130 loss: 0.0005576469586230815
batch 135 loss: 0.0005577287287451327
batch 140 loss: 0.0005576923140324652
batch 145 loss: 0.0005576464696787298
batch 150 loss: 0.0005576320341788233
batch 155 loss: 0.0005576920928433537
batch 160 loss: 0.0005576866329647601
batch 165 loss: 0.0005576987750828266
batch 170 loss: 0.0005577048170380295
batch 175 loss: 0.000557611626572907
batch 180 loss: 0.0005577533156611025
batch 185 loss: 0.0005577457719482482
batch 190 loss: 0.0005576467490755021
batch 195 loss: 0.0005577143630944193
batch 200 loss: 0.0005576653056778014
batch 205 loss: 0.000557783548720181
batch 210 loss: 0.0005576397641561925
batch 215 loss: 0.0005575879826210439
batch 220 loss: 0.0005577594158239663
batch 225 loss: 0.0005576581577770412
batch 230 loss: 0.0005576628027483821
batch 235 loss: 0.0005577286356128752
batch 240 loss: 0.0005576639086939394
Training Loss: 0.0005575872712749212
Validation Loss: 0.0005576929775997997
Epoch 93:
batch 5 loss: 0.000557759846560657
batch 10 loss: 0.000557697773911059
batch 15 loss: 0.0005576056428253651
batch 20 loss: 0.0005577549571171402
batch 25 loss: 0.000557586969807744
batch 30 loss: 0.0005577225470915437
batch 35 loss: 0.0005576596828177572
batch 40 loss: 0.0005577376810833812
batch 45 loss: 0.0005578225012868643
batch 50 loss: 0.0005577327217906713
batch 55 loss: 0.0005576233728788793
batch 60 loss: 0.0005577249568887055
batch 65 loss: 0.0005577031755819917
batch 70 loss: 0.0005576556082814932
batch 75 loss: 0.0005576860276050866
batch 80 loss: 0.0005576930241659283
batch 85 loss: 0.0005576041759923101
batch 90 loss: 0.0005577584030106664
batch 95 loss: 0.0005576482275500893
batch 100 loss: 0.0005578081123530865
batch 105 loss: 0.0005576745606958866
batch 110 loss: 0.0005577155388891697
batch 115 loss: 0.0005577351781539619
batch 120 loss: 0.0005576149909757077
batch 125 loss: 0.0005577556439675391
batch 130 loss: 0.0005576911964453757
batch 135 loss: 0.0005576751544140279
batch 140 loss: 0.0005576234078034758
batch 145 loss: 0.0005576410098001361
batch 150 loss: 0.0005576673313044012
batch 155 loss: 0.0005577631294727325
batch 160 loss: 0.0005576981115154922
batch 165 loss: 0.0005576320458203554
batch 170 loss: 0.0005577902775257826
batch 175 loss: 0.0005577226169407367
batch 180 loss: 0.0005576458643190563
batch 185 loss: 0.0005576638621278107
batch 190 loss: 0.0005577653995715081
batch 195 loss: 0.0005576543160714209
batch 200 loss: 0.0005576523486524821
batch 205 loss: 0.0005576189374551177
batch 210 loss: 0.0005576172261498868
batch 215 loss: 0.0005576626630499959
batch 220 loss: 0.0005576138733886183
batch 225 loss: 0.0005576878087595105
batch 230 loss: 0.0005576330702751874
batch 235 loss: 0.0005575885763391853
batch 240 loss: 0.0005575940362177789
Training Loss: 0.0005576829913479742
Validation Loss: 0.0005576930096140131
Epoch 94:
batch 5 loss: 0.000557644385844469
batch 10 loss: 0.0005577161209657788
batch 15 loss: 0.0005576177616603672
batch 20 loss: 0.0005577572388574481
batch 25 loss: 0.0005577353993430733
batch 30 loss: 0.0005576019058935345
batch 35 loss: 0.0005577100906521082
batch 40 loss: 0.0005576209397986532
batch 45 loss: 0.0005577003932558
batch 50 loss: 0.000557734805624932
batch 55 loss: 0.0005576755735091865
batch 60 loss: 0.0005576852941885591
batch 65 loss: 0.0005576371215283871
batch 70 loss: 0.000557684397790581
batch 75 loss: 0.0005577822448685765
batch 80 loss: 0.0005576746421866119
batch 85 loss: 0.0005576858413405717
batch 90 loss: 0.0005576118361204863
batch 95 loss: 0.0005575699382461607
batch 100 loss: 0.0005577108822762966
batch 105 loss: 0.0005576768075115979
batch 110 loss: 0.0005577129544690251
batch 115 loss: 0.0005577926407568157
batch 120 loss: 0.0005576213938184082
batch 125 loss: 0.0005575023824349046
batch 130 loss: 0.0005576992058195174
batch 135 loss: 0.0005576682859100401
batch 140 loss: 0.0005577287753112614
batch 145 loss: 0.0005577801377512515
batch 150 loss: 0.0005576776340603829
batch 155 loss: 0.0005576874827966094
batch 160 loss: 0.0005576703348197043
batch 165 loss: 0.0005576516850851476
batch 170 loss: 0.0005577367963269352
batch 175 loss: 0.0005576691241003573
batch 180 loss: 0.0005577798234298825
batch 185 loss: 0.0005576602881774307
batch 190 loss: 0.0005577191826887429
batch 195 loss: 0.0005577044212259352
batch 200 loss: 0.0005577128846198321
batch 205 loss: 0.0005576653988100588
batch 210 loss: 0.0005576531868427992
batch 215 loss: 0.0005577312083914876
batch 220 loss: 0.0005576210911385715
batch 225 loss: 0.0005577005678787828
batch 230 loss: 0.0005576357361860573
batch 235 loss: 0.0005577439093030989
batch 240 loss: 0.000557621056213975
Training Loss: 0.0005576829418714624
Validation Loss: 0.0005576927680522204
Epoch 95:
batch 5 loss: 0.0005577076342888176
batch 10 loss: 0.000557714409660548
batch 15 loss: 0.0005576684954576195
batch 20 loss: 0.0005577494273893535
batch 25 loss: 0.0005576185998506844
batch 30 loss: 0.0005576440365985036
batch 35 loss: 0.0005576415103860199
batch 40 loss: 0.0005576920928433537
batch 45 loss: 0.0005577303352765739
batch 50 loss: 0.000557780684903264
batch 55 loss: 0.0005577707896009087
batch 60 loss: 0.0005576600786298513
batch 65 loss: 0.0005576289026066661
batch 70 loss: 0.00055774754146114
batch 75 loss: 0.0005576172727160156
batch 80 loss: 0.0005576168419793248
batch 85 loss: 0.0005576390773057938
batch 90 loss: 0.000557702302467078
batch 95 loss: 0.0005577425472438335
batch 100 loss: 0.0005577584728598594
batch 105 loss: 0.0005575948511250317
batch 110 loss: 0.0005576898111030459
batch 115 loss: 0.0005576755735091865
batch 120 loss: 0.000557705806568265
batch 125 loss: 0.0005577459931373596
batch 130 loss: 0.0005575777380727231
batch 135 loss: 0.0005576963420026004
batch 140 loss: 0.0005575624410994351
batch 145 loss: 0.0005577682750299573
batch 150 loss: 0.00055769287282601
batch 155 loss: 0.0005576598807238043
batch 160 loss: 0.0005577259697020053
batch 165 loss: 0.0005576008697971702
batch 170 loss: 0.0005576722323894501
batch 175 loss: 0.0005575965158641338
batch 180 loss: 0.0005577794858254492
batch 185 loss: 0.0005576153285801411
batch 190 loss: 0.000557743723038584
batch 195 loss: 0.0005576455616392196
batch 200 loss: 0.000557578809093684
batch 205 loss: 0.00055769516620785
batch 210 loss: 0.0005576954805292189
batch 215 loss: 0.000557704211678356
batch 220 loss: 0.0005577564937993884
batch 225 loss: 0.0005576575640588999
batch 230 loss: 0.0005575650371611119
batch 235 loss: 0.0005577360163442791
batch 240 loss: 0.0005578067852184176
Training Loss: 0.0005576828310343748
Validation Loss: 0.0005576924779840434
Epoch 96:
batch 5 loss: 0.0005575352115556598
batch 10 loss: 0.0005577758303843439
batch 15 loss: 0.0005575518705882132
batch 20 loss: 0.000557606783695519
batch 25 loss: 0.0005576314288191497
batch 30 loss: 0.000557744549587369
batch 35 loss: 0.000557726004626602
batch 40 loss: 0.0005576532799750567
batch 45 loss: 0.000557699438650161
batch 50 loss: 0.0005577056668698788
batch 55 loss: 0.0005577198113314808
batch 60 loss: 0.0005577724776230752
batch 65 loss: 0.0005576136289164424
batch 70 loss: 0.0005576898111030459
batch 75 loss: 0.0005576646886765957
batch 80 loss: 0.0005577303352765739
batch 85 loss: 0.0005577148869633675
batch 90 loss: 0.0005576993804425001
batch 95 loss: 0.0005576868890784681
batch 100 loss: 0.0005576223367825151
batch 105 loss: 0.0005576891591772438
batch 110 loss: 0.0005576868075877428
batch 115 loss: 0.0005576508468948304
batch 120 loss: 0.0005576608586125076
batch 125 loss: 0.0005577535019256174
batch 130 loss: 0.0005576573545113206
batch 135 loss: 0.0005576096125878393
batch 140 loss: 0.0005576918949373067
batch 145 loss: 0.0005576821626164019
batch 150 loss: 0.0005577461910434067
batch 155 loss: 0.0005577473668381572
batch 160 loss: 0.0005577575066126883
batch 165 loss: 0.0005577970645390451
batch 170 loss: 0.0005577434320002794
batch 175 loss: 0.0005577602772973478
batch 180 loss: 0.000557597354054451
batch 185 loss: 0.0005575957708060742
batch 190 loss: 0.0005576440715231001
batch 195 loss: 0.0005576607305556536
batch 200 loss: 0.0005576391122303903
batch 205 loss: 0.0005577563191764056
batch 210 loss: 0.0005576596595346928
batch 215 loss: 0.0005577222327701747
batch 220 loss: 0.0005576177383773029
batch 225 loss: 0.0005577336763963103
batch 230 loss: 0.0005575865972787142
batch 235 loss: 0.0005577321979217231
batch 240 loss: 0.0005576515803113579
Training Loss: 0.0005576828206055022
Validation Loss: 0.0005576924469399576
Epoch 97:
batch 5 loss: 0.0005576671333983541
batch 10 loss: 0.0005576646886765957
batch 15 loss: 0.0005576904048211872
batch 20 loss: 0.0005577599280513823
batch 25 loss: 0.000557619531173259
batch 30 loss: 0.0005576357129029929
batch 35 loss: 0.0005577071919105947
batch 40 loss: 0.000557672360446304
batch 45 loss: 0.0005576393799856305
batch 50 loss: 0.0005577810807153583
batch 55 loss: 0.0005577425705268979
batch 60 loss: 0.0005576694617047906
batch 65 loss: 0.0005578021402470768
batch 70 loss: 0.0005576982046477496
batch 75 loss: 0.0005575991701334715
batch 80 loss: 0.0005577593226917088
batch 85 loss: 0.0005577763309702277
batch 90 loss: 0.0005575652234256267
batch 95 loss: 0.000557716388721019
batch 100 loss: 0.0005576032330282032
batch 105 loss: 0.0005575658171437681
batch 110 loss: 0.0005577108007855713
batch 115 loss: 0.0005576384137384593
batch 120 loss: 0.0005575913353823125
batch 125 loss: 0.0005576653173193335
batch 130 loss: 0.0005577084608376026
batch 135 loss: 0.0005577040719799697
batch 140 loss: 0.0005577056319452823
batch 145 loss: 0.0005576138850301504
batch 150 loss: 0.0005576350959017873
batch 155 loss: 0.0005576296243816614
batch 160 loss: 0.0005577067262493074
batch 165 loss: 0.0005575612070970237
batch 170 loss: 0.0005577619886025786
batch 175 loss: 0.0005577071569859982
batch 180 loss: 0.0005577038624323905
batch 185 loss: 0.000557674199808389
batch 190 loss: 0.0005577530479058624
batch 195 loss: 0.0005576297640800476
batch 200 loss: 0.000557674013543874
batch 205 loss: 0.0005576284951530397
batch 210 loss: 0.0005577837582677603
batch 215 loss: 0.0005577427567914128
batch 220 loss: 0.0005576966446824372
batch 225 loss: 0.0005576356314122676
batch 230 loss: 0.0005577185656875372
batch 235 loss: 0.0005577681818976999
batch 240 loss: 0.0005576921976171434
Training Loss: 0.0005576828356424812
Validation Loss: 0.0005576924818645542
Epoch 98:
batch 5 loss: 0.0005576623021624983
batch 10 loss: 0.0005575168645009399
batch 15 loss: 0.0005576349096372724
batch 20 loss: 0.0005576127558015286
batch 25 loss: 0.0005577502539381385
batch 30 loss: 0.0005576638621278107
batch 35 loss: 0.0005577817559242248
batch 40 loss: 0.0005577187053859234
batch 45 loss: 0.0005576340481638908
batch 50 loss: 0.0005576623487286269
batch 55 loss: 0.0005575874354690313
batch 60 loss: 0.0005576163181103766
batch 65 loss: 0.0005576585652306675
batch 70 loss: 0.0005577255273237824
batch 75 loss: 0.0005575894261710346
batch 80 loss: 0.0005577444331720472
batch 85 loss: 0.0005577709525823593
batch 90 loss: 0.0005577264470048249
batch 95 loss: 0.0005577364354394376
batch 100 loss: 0.0005577188218012452
batch 105 loss: 0.0005577043630182743
batch 110 loss: 0.0005575966089963913
batch 115 loss: 0.0005576709401793778
batch 120 loss: 0.0005576554918661714
batch 125 loss: 0.0005576042109169066
batch 130 loss: 0.000557656167075038
batch 135 loss: 0.0005576080409809947
batch 140 loss: 0.0005577386589720845
batch 145 loss: 0.0005577602423727512
batch 150 loss: 0.0005575940827839077
batch 155 loss: 0.0005576845142059028
batch 160 loss: 0.0005577973905019462
batch 165 loss: 0.0005576748051680624
batch 170 loss: 0.0005577440024353564
batch 175 loss: 0.0005577198229730129
batch 180 loss: 0.0005576900090090931
batch 185 loss: 0.0005577248404733837
batch 190 loss: 0.0005577125935815275
batch 195 loss: 0.0005577506497502327
batch 200 loss: 0.000557725306134671
batch 205 loss: 0.0005577399861067533
batch 210 loss: 0.0005576578783802688
batch 215 loss: 0.0005577182630077005
batch 220 loss: 0.0005576738389208913
batch 225 loss: 0.0005576321040280163
batch 230 loss: 0.000557702174410224
batch 235 loss: 0.0005577265401370823
batch 240 loss: 0.0005576040945015848
Training Loss: 0.0005576829122825681
Validation Loss: 0.0005576928602143501
Epoch 99:
batch 5 loss: 0.0005577116156928241
batch 10 loss: 0.0005575886927545071
batch 15 loss: 0.0005575899849645793
batch 20 loss: 0.0005576937110163271
batch 25 loss: 0.0005577205563895404
batch 30 loss: 0.0005576613591983914
batch 35 loss: 0.0005576464580371975
batch 40 loss: 0.0005577466101385653
batch 45 loss: 0.0005576719413511455
batch 50 loss: 0.0005575585528276861
batch 55 loss: 0.0005576565046794713
batch 60 loss: 0.0005576313706114888
batch 65 loss: 0.0005576884024776519
batch 70 loss: 0.0005576998926699161
batch 75 loss: 0.0005576299969106913
batch 80 loss: 0.0005576430237852037
batch 85 loss: 0.0005576178664341569
batch 90 loss: 0.0005577311618253589
batch 95 loss: 0.0005577151547186077
batch 100 loss: 0.0005577278439886868
batch 105 loss: 0.0005577456089667976
batch 110 loss: 0.0005577536299824715
batch 115 loss: 0.0005576485535129904
batch 120 loss: 0.0005575636983849108
batch 125 loss: 0.0005576954688876867
batch 130 loss: 0.000557664968073368
batch 135 loss: 0.000557725050020963
batch 140 loss: 0.0005576577153988182
batch 145 loss: 0.0005576766445301474
batch 150 loss: 0.0005576863884925842
batch 155 loss: 0.0005577175645157695
batch 160 loss: 0.0005578021751716733
batch 165 loss: 0.0005576709634624421
batch 170 loss: 0.0005577102303504944
batch 175 loss: 0.0005578056559897959
batch 180 loss: 0.0005577399744652212
batch 185 loss: 0.0005577034899033606
batch 190 loss: 0.0005577093455940485
batch 195 loss: 0.0005576132098212838
batch 200 loss: 0.0005577521049417555
batch 205 loss: 0.0005577044095844031
batch 210 loss: 0.0005576368770562112
batch 215 loss: 0.0005576360854320228
batch 220 loss: 0.0005576577503234148
batch 225 loss: 0.0005576879251748323
batch 230 loss: 0.0005576876807026565
batch 235 loss: 0.0005577326519414783
batch 240 loss: 0.0005576746189035475
Training Loss: 0.0005576831487511905
Validation Loss: 0.0005576932220719754
Epoch 100:
batch 5 loss: 0.0005576248979195953
batch 10 loss: 0.0005576317547820508
batch 15 loss: 0.0005576570518314838
batch 20 loss: 0.0005576767842285335
batch 25 loss: 0.0005576700554229319
batch 30 loss: 0.0005577269708737731
batch 35 loss: 0.0005577355506829918
batch 40 loss: 0.0005576723022386431
batch 45 loss: 0.000557705934625119
batch 50 loss: 0.0005575672490522266
batch 55 loss: 0.0005576878087595105
batch 60 loss: 0.0005577477742917836
batch 65 loss: 0.0005577544681727887
batch 70 loss: 0.0005575923016294837
batch 75 loss: 0.0005577478557825088
batch 80 loss: 0.000557660183403641
batch 85 loss: 0.0005576194846071303
batch 90 loss: 0.0005576372728683055
batch 95 loss: 0.0005576864583417773
batch 100 loss: 0.0005577111733146012
batch 105 loss: 0.0005576210678555071
batch 110 loss: 0.0005576126161031425
batch 115 loss: 0.0005577433272264898
batch 120 loss: 0.0005576324881985783
batch 125 loss: 0.0005576166091486812
batch 130 loss: 0.0005576716153882444
batch 135 loss: 0.0005577325937338173
batch 140 loss: 0.0005576328607276082
batch 145 loss: 0.0005576571682468056
batch 150 loss: 0.0005577297764830291
batch 155 loss: 0.0005576471332460642
batch 160 loss: 0.0005577464820817113
batch 165 loss: 0.0005577531061135233
batch 170 loss: 0.0005577050731517374
batch 175 loss: 0.0005577227100729942
batch 180 loss: 0.0005578581825830042
batch 185 loss: 0.0005577112664468586
batch 190 loss: 0.0005577243398874998
batch 195 loss: 0.0005577206378802657
batch 200 loss: 0.0005576631636358797
batch 205 loss: 0.0005575902294367551
batch 210 loss: 0.0005576226627454162
batch 215 loss: 0.0005576894502155483
batch 220 loss: 0.0005576958530582488
batch 225 loss: 0.0005577576230280101
batch 230 loss: 0.0005576702882535755
batch 235 loss: 0.0005576501367613673
batch 240 loss: 0.0005577001837082207
Training Loss: 0.0005576831662134888
Validation Loss: 0.000557692473133405

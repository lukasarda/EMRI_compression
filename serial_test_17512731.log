****************************************************************
*                      SLURM Batch System                      *
*           IN2P3 Computing Centre, Villeurbanne FR            *
****************************************************************
* Date:                 Sun Jun 30 13:34:16 CEST 2024
* Job name:             600
* Job id:               17512731
* User:                 lkarda
* Account:              lisaf
* Submit host:          ccahm001
* Partition:            gpu
* Quality of service:   gpu
* Nodelist:             ccwgslurm0104
****************************************************************
no change     /sps/lisaf/lkarda/miniconda3/condabin/conda
no change     /sps/lisaf/lkarda/miniconda3/bin/conda
no change     /sps/lisaf/lkarda/miniconda3/bin/conda-env
no change     /sps/lisaf/lkarda/miniconda3/bin/activate
no change     /sps/lisaf/lkarda/miniconda3/bin/deactivate
no change     /sps/lisaf/lkarda/miniconda3/etc/profile.d/conda.sh
no change     /sps/lisaf/lkarda/miniconda3/etc/fish/conf.d/conda.fish
no change     /sps/lisaf/lkarda/miniconda3/shell/condabin/Conda.psm1
no change     /sps/lisaf/lkarda/miniconda3/shell/condabin/conda-hook.ps1
no change     /sps/lisaf/lkarda/miniconda3/lib/python3.12/site-packages/xontrib/conda.xsh
no change     /sps/lisaf/lkarda/miniconda3/etc/profile.d/conda.csh
no change     /pbs/home/l/lkarda/.bashrc
No action taken.
AE_net
# of epochs: 100
# of samples: 24000
Batchsize: 100
# of batches: 240
# of nodes in bottleneck 600
20240630_133449
Epoch 1:
batch 5 loss: 0.015307190734893084
batch 10 loss: 0.002998759876936674
batch 15 loss: 0.0019781077746301888
batch 20 loss: 0.0014656815677881242
batch 25 loss: 0.0013036662247031927
batch 30 loss: 0.001075752917677164
batch 35 loss: 0.0009353839675895869
batch 40 loss: 0.0008245988166891039
batch 45 loss: 0.0007435236359015108
batch 50 loss: 0.0006920965737663209
batch 55 loss: 0.0007784508401528001
batch 60 loss: 0.0007218953454867005
batch 65 loss: 0.0006521723233163356
batch 70 loss: 0.0006480810814537108
batch 75 loss: 0.0006461075507104396
batch 80 loss: 0.0006434112088754773
batch 85 loss: 0.0006388646783307194
batch 90 loss: 0.0006640074076130986
batch 95 loss: 0.0007923689088784158
batch 100 loss: 0.0006692848401144147
batch 105 loss: 0.0006421437254175543
batch 110 loss: 0.0006399741512723267
batch 115 loss: 0.0006389801856130362
batch 120 loss: 0.0006379404570907354
batch 125 loss: 0.0006366042536683381
batch 130 loss: 0.0006353584583848714
batch 135 loss: 0.0006337291561067104
batch 140 loss: 0.0006318963714875281
batch 145 loss: 0.0006300962646491826
batch 150 loss: 0.0006275099236518145
batch 155 loss: 0.0006248500430956483
batch 160 loss: 0.0006233368534594774
batch 165 loss: 0.0009676355752162635
batch 170 loss: 0.0007028330815955997
batch 175 loss: 0.0006347273476421833
batch 180 loss: 0.0006309989024884999
batch 185 loss: 0.0006294348859228194
batch 190 loss: 0.0006272871280089021
batch 195 loss: 0.0006228569312952459
batch 200 loss: 0.000621957506518811
batch 205 loss: 0.0006203821045346558
batch 210 loss: 0.0006188895436935127
batch 215 loss: 0.000617676239926368
batch 220 loss: 0.0006163771962746978
batch 225 loss: 0.0006151962443254888
batch 230 loss: 0.0006138909957371652
batch 235 loss: 0.0006118927267380059
batch 240 loss: 0.0006094704032875598
Training Loss: 0.001086319436096043
Validation Loss: 0.0005954404225728164
Epoch 2:
batch 5 loss: 0.0006066879839636385
batch 10 loss: 0.0006748188869096338
batch 15 loss: 0.0006292016129009426
batch 20 loss: 0.0006136841257102787
batch 25 loss: 0.0006126096937805414
batch 30 loss: 0.0006118394783698022
batch 35 loss: 0.0006111807655543089
batch 40 loss: 0.0006098635494709015
batch 45 loss: 0.0006083608022890985
batch 50 loss: 0.0006050905329175293
batch 55 loss: 0.0006043156841769815
batch 60 loss: 0.0006026447168551386
batch 65 loss: 0.0006017345120199024
batch 70 loss: 0.000600942550227046
batch 75 loss: 0.000600283476524055
batch 80 loss: 0.0005997644155286252
batch 85 loss: 0.0005992048885673284
batch 90 loss: 0.0005985550000332296
batch 95 loss: 0.0005980266025289894
batch 100 loss: 0.0005978432833217085
batch 105 loss: 0.0005974672269076109
batch 110 loss: 0.0005970299593172967
batch 115 loss: 0.0005968064069747925
batch 120 loss: 0.0005963645991869271
batch 125 loss: 0.000596177694387734
batch 130 loss: 0.0005955354892648757
batch 135 loss: 0.0005948964273557067
batch 140 loss: 0.0005944055854342877
batch 145 loss: 0.0005938697955571115
batch 150 loss: 0.0005933527485467493
batch 155 loss: 0.000591948814690113
batch 160 loss: 0.0006476148264482617
batch 165 loss: 0.0007077819085679948
batch 170 loss: 0.0006083136540837586
batch 175 loss: 0.0006008043768815696
batch 180 loss: 0.000601237511727959
batch 185 loss: 0.0006011361023411155
batch 190 loss: 0.0006009005126543343
batch 195 loss: 0.0006005218136124312
batch 200 loss: 0.0006001227651722729
batch 205 loss: 0.0005997072323225439
batch 210 loss: 0.0005992557271383703
batch 215 loss: 0.0005985103547573089
batch 220 loss: 0.0005977871478535235
batch 225 loss: 0.0005975175648927688
batch 230 loss: 0.0005966619122773409
batch 235 loss: 0.0005993506405502558
batch 240 loss: 0.0005967264529317618
Training Loss: 0.0006060095377809679
Validation Loss: 0.0006160578748676925
Epoch 3:
batch 5 loss: 0.0005961693590506911
batch 10 loss: 0.0005956471664831043
batch 15 loss: 0.0005951241124421358
batch 20 loss: 0.0005945532815530896
batch 25 loss: 0.0005940950242802501
batch 30 loss: 0.0005935932975262403
batch 35 loss: 0.0005931760068051517
batch 40 loss: 0.000592600426170975
batch 45 loss: 0.0005922358250245452
batch 50 loss: 0.0005918872775509953
batch 55 loss: 0.0005913553875871002
batch 60 loss: 0.0005911280401051045
batch 65 loss: 0.0005906267208047212
batch 70 loss: 0.0005900951102375985
batch 75 loss: 0.0005894380155950785
batch 80 loss: 0.000588883284945041
batch 85 loss: 0.0005875257542356848
batch 90 loss: 0.0005860631004907191
batch 95 loss: 0.000585211836732924
batch 100 loss: 0.0005846819025464356
batch 105 loss: 0.000583642697893083
batch 110 loss: 0.0005817918456159533
batch 115 loss: 0.0005807634210214019
batch 120 loss: 0.0005791244679130614
batch 125 loss: 0.0005773863755166531
batch 130 loss: 0.0005790432798676193
batch 135 loss: 0.0005838104756549
batch 140 loss: 0.0005805707070976496
batch 145 loss: 0.0005792770069092512
batch 150 loss: 0.0005776725360192358
batch 155 loss: 0.0005754511686973274
batch 160 loss: 0.000573685416020453
batch 165 loss: 0.0005728401592932642
batch 170 loss: 0.0005722021451219916
batch 175 loss: 0.0005717403837479651
batch 180 loss: 0.0005714013823308051
batch 185 loss: 0.0005711599136702716
batch 190 loss: 0.000570826034527272
batch 195 loss: 0.0005706364754587412
batch 200 loss: 0.0005705406423658132
batch 205 loss: 0.0009703841176815331
batch 210 loss: 0.0008747764630243182
batch 215 loss: 0.0006795599474571645
batch 220 loss: 0.0006582132424227894
batch 225 loss: 0.0006293580518104136
batch 230 loss: 0.0006074119242839515
batch 235 loss: 0.0005960262031294405
batch 240 loss: 0.0005938116228207946
Training Loss: 0.0006032749799487647
Validation Loss: 0.0005843885553379854
Epoch 4:
batch 5 loss: 0.0005914705689065158
batch 10 loss: 0.0005887321662157774
batch 15 loss: 0.0005867381230928003
batch 20 loss: 0.0005845795501954853
batch 25 loss: 0.0005838171346113086
batch 30 loss: 0.000582921551540494
batch 35 loss: 0.0005820872029289603
batch 40 loss: 0.0005816306103952229
batch 45 loss: 0.0005811194772832095
batch 50 loss: 0.0005804981803521514
batch 55 loss: 0.0005799823673442006
batch 60 loss: 0.0005793413147330284
batch 65 loss: 0.0005789832095615566
batch 70 loss: 0.0005784388165920972
batch 75 loss: 0.0005781810148619115
batch 80 loss: 0.0005775762721896172
batch 85 loss: 0.0005771007621660828
batch 90 loss: 0.0005766723188571632
batch 95 loss: 0.0005762144923210144
batch 100 loss: 0.0005758529296144843
batch 105 loss: 0.0005758825456723571
batch 110 loss: 0.0005752922734245658
batch 115 loss: 0.0005748306284658611
batch 120 loss: 0.0005745316739194095
batch 125 loss: 0.0005739865824580193
batch 130 loss: 0.0005737186875194311
batch 135 loss: 0.0005732055637054145
batch 140 loss: 0.0005726559786126018
batch 145 loss: 0.0005721953464671969
batch 150 loss: 0.0005717069725506008
batch 155 loss: 0.0005713861435651779
batch 160 loss: 0.0005708184558898211
batch 165 loss: 0.0005705245770514011
batch 170 loss: 0.0005701749934814871
batch 175 loss: 0.0005698742810636759
batch 180 loss: 0.0005695216124877334
batch 185 loss: 0.0005692381062544882
batch 190 loss: 0.000568892469163984
batch 195 loss: 0.0005685653304681182
batch 200 loss: 0.0005683167604729533
batch 205 loss: 0.0005681047448888421
batch 210 loss: 0.0005677398992702364
batch 215 loss: 0.0005675459047779441
batch 220 loss: 0.0005677992943674326
batch 225 loss: 0.0005676524597220123
batch 230 loss: 0.0005674448912031949
batch 235 loss: 0.000567077484447509
batch 240 loss: 0.0005667179939337075
Training Loss: 0.0005749445774805887
Validation Loss: 0.0005645199678838253
Epoch 5:
batch 5 loss: 0.000566812523175031
batch 10 loss: 0.0005667104269377887
batch 15 loss: 0.0005663203308358788
batch 20 loss: 0.0005661627161316574
batch 25 loss: 0.0005659534013830126
batch 30 loss: 0.0005659282207489014
batch 35 loss: 0.0005658005131408573
batch 40 loss: 0.0005656128050759435
batch 45 loss: 0.0005656333989463747
batch 50 loss: 0.0005655606742948294
batch 55 loss: 0.0005654679494909942
batch 60 loss: 0.000565307168290019
batch 65 loss: 0.000565172778442502
batch 70 loss: 0.0005651101237162948
batch 75 loss: 0.0005652843043208122
batch 80 loss: 0.000564935733564198
batch 85 loss: 0.0005649667466059328
batch 90 loss: 0.000564950646366924
batch 95 loss: 0.0005648068035952747
batch 100 loss: 0.0005646441015414894
batch 105 loss: 0.0005647043930366635
batch 110 loss: 0.000564723927527666
batch 115 loss: 0.0005646835081279278
batch 120 loss: 0.0005645698751322925
batch 125 loss: 0.0005645356955938041
batch 130 loss: 0.000564478407613933
batch 135 loss: 0.0005645303288474679
batch 140 loss: 0.0005643061478622258
batch 145 loss: 0.0005642952048219741
batch 150 loss: 0.0005642823060043156
batch 155 loss: 0.000564283225685358
batch 160 loss: 0.0005644212011247874
batch 165 loss: 0.0005643366486765445
batch 170 loss: 0.0005641527939587831
batch 175 loss: 0.0005641416646540165
batch 180 loss: 0.0005640888120979071
batch 185 loss: 0.0005640144110657275
batch 190 loss: 0.000563989591319114
batch 195 loss: 0.000563946389593184
batch 200 loss: 0.0005640909657813609
batch 205 loss: 0.0005638313945382833
batch 210 loss: 0.0005640248185954988
batch 215 loss: 0.0005645353929139673
batch 220 loss: 0.0005638847593218088
batch 225 loss: 0.0005639083799906075
batch 230 loss: 0.0005640476243570447
batch 235 loss: 0.0005638159927912056
batch 240 loss: 0.0005636137793771923
Training Loss: 0.0005647787293128204
Validation Loss: 0.000563680564907069
Epoch 6:
batch 5 loss: 0.0005637754453346133
batch 10 loss: 0.0005635876674205065
batch 15 loss: 0.0005635467707179487
batch 20 loss: 0.0005634561879560351
batch 25 loss: 0.0005635614041239023
batch 30 loss: 0.0005633392138406634
batch 35 loss: 0.0005634384113363921
batch 40 loss: 0.0005635882378555834
batch 45 loss: 0.000563364289700985
batch 50 loss: 0.0005635042325593531
batch 55 loss: 0.000563426164444536
batch 60 loss: 0.0005633269553072751
batch 65 loss: 0.0005634096683934331
batch 70 loss: 0.0005631897365674376
batch 75 loss: 0.0005634189583361149
batch 80 loss: 0.0005635080742649734
batch 85 loss: 0.0005637049558572471
batch 90 loss: 0.0005642027826979756
batch 95 loss: 0.0024135926039889457
batch 100 loss: 0.0007104860036633909
batch 105 loss: 0.0006244842661544681
batch 110 loss: 0.0006187206017784774
batch 115 loss: 0.0006119350204244256
batch 120 loss: 0.0006077022291719914
batch 125 loss: 0.0006048569339327514
batch 130 loss: 0.0006022999528795481
batch 135 loss: 0.000598960358183831
batch 140 loss: 0.0005978399887681008
batch 145 loss: 0.0005962566589005292
batch 150 loss: 0.0005954642314463854
batch 155 loss: 0.0005949294427409768
batch 160 loss: 0.0005944114294834435
batch 165 loss: 0.0005941038485616446
batch 170 loss: 0.000593735312577337
batch 175 loss: 0.0005934138549491763
batch 180 loss: 0.0005931594991125166
batch 185 loss: 0.0005927759339101613
batch 190 loss: 0.0005927719990722835
batch 195 loss: 0.0005924854543991387
batch 200 loss: 0.0005921694682911038
batch 205 loss: 0.0005920552648603916
batch 210 loss: 0.0005917213158681989
batch 215 loss: 0.0005915662157349288
batch 220 loss: 0.0005913434084504843
batch 225 loss: 0.0005911238724365831
batch 230 loss: 0.0005908242659643292
batch 235 loss: 0.0005906325532123446
batch 240 loss: 0.0005903841112740338
Training Loss: 0.0006247824011855603
Validation Loss: 0.0005836593317023168
Epoch 7:
batch 5 loss: 0.0005901569733396172
batch 10 loss: 0.0005899991258047522
batch 15 loss: 0.0005895505659282207
batch 20 loss: 0.000589469016995281
batch 25 loss: 0.0005891320877708494
batch 30 loss: 0.000588775856886059
batch 35 loss: 0.0005883570993319154
batch 40 loss: 0.0005880287499167025
batch 45 loss: 0.000587600702419877
batch 50 loss: 0.0005871299770660698
batch 55 loss: 0.0005866297404281795
batch 60 loss: 0.0005858731456100941
batch 65 loss: 0.0005851945956237614
batch 70 loss: 0.0005845046020112932
batch 75 loss: 0.0005839345511049032
batch 80 loss: 0.0005831515998579561
batch 85 loss: 0.0005825193366035819
batch 90 loss: 0.0005815859418362379
batch 95 loss: 0.0005802138010039925
batch 100 loss: 0.0005800498882308602
batch 105 loss: 0.0005802693776786327
batch 110 loss: 0.000579918606672436
batch 115 loss: 0.000579708581790328
batch 120 loss: 0.000579578650649637
batch 125 loss: 0.0005793203134089708
batch 130 loss: 0.0005791342933662236
batch 135 loss: 0.0005789337214082479
batch 140 loss: 0.0005786892957985401
batch 145 loss: 0.0005782316555269062
batch 150 loss: 0.0005774455261416733
batch 155 loss: 0.000577146396972239
batch 160 loss: 0.000576704740524292
batch 165 loss: 0.0005760405212640763
batch 170 loss: 0.0005751747637987136
batch 175 loss: 0.0005741539062000811
batch 180 loss: 0.0005732340971007944
batch 185 loss: 0.0005726899253204465
batch 190 loss: 0.0005715480074286461
batch 195 loss: 0.0005708445329219103
batch 200 loss: 0.0005702876253053546
batch 205 loss: 0.0005697407759726048
batch 210 loss: 0.0005694649531506002
batch 215 loss: 0.0005691797356121242
batch 220 loss: 0.0005688593722879886
batch 225 loss: 0.0005686640040948987
batch 230 loss: 0.0005684210103936493
batch 235 loss: 0.0005684706731699408
batch 240 loss: 0.0005683450261130929
Training Loss: 0.0005792095301634012
Validation Loss: 0.0005684447571790467
Epoch 8:
batch 5 loss: 0.0005682473536580801
batch 10 loss: 0.000568190694320947
batch 15 loss: 0.0005680978414602577
batch 20 loss: 0.0005680076079443097
batch 25 loss: 0.0005680086673237383
batch 30 loss: 0.0005679104593582452
batch 35 loss: 0.000567968504037708
batch 40 loss: 0.0005680306814610959
batch 45 loss: 0.0005679620313458145
batch 50 loss: 0.0005679461522959173
batch 55 loss: 0.0005679303081706166
batch 60 loss: 0.0005678915767930448
batch 65 loss: 0.0005679331952705979
batch 70 loss: 0.0005677929031662643
batch 75 loss: 0.0005677692359313368
batch 80 loss: 0.0005678149638697505
batch 85 loss: 0.0005678149522282183
batch 90 loss: 0.0005678376764990389
batch 95 loss: 0.0005676991655491293
batch 100 loss: 0.0005677504814229906
batch 105 loss: 0.0005675403750501573
batch 110 loss: 0.0005676554748788476
batch 115 loss: 0.0005677306675352156
batch 120 loss: 0.0005676975823007524
batch 125 loss: 0.0005675801774486899
batch 130 loss: 0.0005676658125594259
batch 135 loss: 0.0005676101427525282
batch 140 loss: 0.0005675434600561857
batch 145 loss: 0.0005676306900568306
batch 150 loss: 0.0005675635416992009
batch 155 loss: 0.0005675421794876456
batch 160 loss: 0.0005674859741702676
batch 165 loss: 0.0005674330750480294
batch 170 loss: 0.0005673831095919013
batch 175 loss: 0.0005674868589267135
batch 180 loss: 0.0005674574756994843
batch 185 loss: 0.0005674829939380288
batch 190 loss: 0.000567436998244375
batch 195 loss: 0.0005674517480656505
batch 200 loss: 0.0005674012238159776
batch 205 loss: 0.0005673632258549333
batch 210 loss: 0.0005672576604411006
batch 215 loss: 0.000567381305154413
batch 220 loss: 0.0005673319101333618
batch 225 loss: 0.0005672513507306576
batch 230 loss: 0.0005672943312674761
batch 235 loss: 0.000567279732786119
batch 240 loss: 0.0005672202329151333
Training Loss: 0.0005676617450565876
Validation Loss: 0.0005669866203485678
Epoch 9:
batch 5 loss: 0.0005671368329785764
batch 10 loss: 0.0005668919300660491
batch 15 loss: 0.0005671050865203142
batch 20 loss: 0.00056714101228863
batch 25 loss: 0.0005670855636708439
batch 30 loss: 0.0005670594866387546
batch 35 loss: 0.000567021977622062
batch 40 loss: 0.0005670301732607185
batch 45 loss: 0.0005670055048540235
batch 50 loss: 0.0005670757032930851
batch 55 loss: 0.0005669912323355674
batch 60 loss: 0.0005669824313372374
batch 65 loss: 0.0005670153419487179
batch 70 loss: 0.0005669926293194294
batch 75 loss: 0.0005668407073244452
batch 80 loss: 0.0005669306148774922
batch 85 loss: 0.000566875806543976
batch 90 loss: 0.000566908752080053
batch 95 loss: 0.0005668904981575906
batch 100 loss: 0.0005668608006089926
batch 105 loss: 0.0005668540252372622
batch 110 loss: 0.0005668578553013504
batch 115 loss: 0.0005667911376804113
batch 120 loss: 0.0005667381454259157
batch 125 loss: 0.0005666998447850346
batch 130 loss: 0.0005666814045980573
batch 135 loss: 0.000566635699942708
batch 140 loss: 0.0005665053729899227
batch 145 loss: 0.0005666022538207471
batch 150 loss: 0.0005665272823534906
batch 155 loss: 0.0005664421827532351
batch 160 loss: 0.0005665483302436769
batch 165 loss: 0.0005663798423483968
batch 170 loss: 0.0005664895637892186
batch 175 loss: 0.0005664891563355922
batch 180 loss: 0.0005661620059981942
batch 185 loss: 0.0005662096780724823
batch 190 loss: 0.0005661818315275014
batch 195 loss: 0.0005663175834342837
batch 200 loss: 0.0005662805633619428
batch 205 loss: 0.0005662018433213234
batch 210 loss: 0.0005662549869157374
batch 215 loss: 0.0005661893752403558
batch 220 loss: 0.0005662634153850377
batch 225 loss: 0.0005661399802193046
batch 230 loss: 0.00056621233234182
batch 235 loss: 0.0005660820985212922
batch 240 loss: 0.0005661395727656782
Training Loss: 0.0005666608218840944
Validation Loss: 0.0005658406832177812
Epoch 10:
batch 5 loss: 0.0005658695823512972
batch 10 loss: 0.0005659452523104847
batch 15 loss: 0.0005658977199345828
batch 20 loss: 0.0005656638066284358
batch 25 loss: 0.0005658842506818474
batch 30 loss: 0.0005657467874698341
batch 35 loss: 0.0005656646681018174
batch 40 loss: 0.0005656675901263952
batch 45 loss: 0.0005655771470628679
batch 50 loss: 0.0005655077286064625
batch 55 loss: 0.0005654732114635408
batch 60 loss: 0.0005654452019371092
batch 65 loss: 0.0005654069827869534
batch 70 loss: 0.0005652946070767939
batch 75 loss: 0.0005652287858538329
batch 80 loss: 0.000565206934697926
batch 85 loss: 0.0005651610321365297
batch 90 loss: 0.0005651978310197592
batch 95 loss: 0.0005650224862620235
batch 100 loss: 0.0005650690640322864
batch 105 loss: 0.0005649250000715256
batch 110 loss: 0.0005650803563185036
batch 115 loss: 0.0005650113918818534
batch 120 loss: 0.000564879656303674
batch 125 loss: 0.0005649817758239806
batch 130 loss: 0.0005649340455420315
batch 135 loss: 0.0005648796213790774
batch 140 loss: 0.0005649212747812271
batch 145 loss: 0.0005648910067975521
batch 150 loss: 0.0005648374790325761
batch 155 loss: 0.0005647386540658772
batch 160 loss: 0.000564773939549923
batch 165 loss: 0.0005646562203764915
batch 170 loss: 0.0005646750330924987
batch 175 loss: 0.000564599980134517
batch 180 loss: 0.0005645953700877726
batch 185 loss: 0.000564485474023968
batch 190 loss: 0.0005645279656164348
batch 195 loss: 0.0005644042743369937
batch 200 loss: 0.0005644102348014712
batch 205 loss: 0.000564520328771323
batch 210 loss: 0.000564683135598898
batch 215 loss: 0.0005664021940901875
batch 220 loss: 0.000567223085090518
batch 225 loss: 0.0005665866308845579
batch 230 loss: 0.0005659447750076651
batch 235 loss: 0.0005654540727846324
batch 240 loss: 0.0005652047460898757
Training Loss: 0.0005652324665182581
Validation Loss: 0.0005645759471614534
Epoch 11:
batch 5 loss: 0.0005649989936500788
batch 10 loss: 0.0005648283869959414
batch 15 loss: 0.0005645376397296787
batch 20 loss: 0.000564599281642586
batch 25 loss: 0.0005645402241498231
batch 30 loss: 0.0005644585471600294
batch 35 loss: 0.0005644247285090387
batch 40 loss: 0.0005643710261210799
batch 45 loss: 0.0005643495242111385
batch 50 loss: 0.0005642504780553282
batch 55 loss: 0.0005642177420668304
batch 60 loss: 0.000564256263896823
batch 65 loss: 0.0005642279516905546
batch 70 loss: 0.0005640051211230456
batch 75 loss: 0.0005640294286422432
batch 80 loss: 0.000563949509523809
batch 85 loss: 0.0005640921648591757
batch 90 loss: 0.0005638344795443117
batch 95 loss: 0.0005639328272081911
batch 100 loss: 0.0005638760514557362
batch 105 loss: 0.0005639128503389657
batch 110 loss: 0.0005639265757054091
batch 115 loss: 0.0005638090660795569
batch 120 loss: 0.0005638001253828407
batch 125 loss: 0.0005640392075292767
batch 130 loss: 0.0005803136271424591
batch 135 loss: 0.0005738551146350801
batch 140 loss: 0.0005739993182942271
batch 145 loss: 0.0005738161853514612
batch 150 loss: 0.0005733413388952612
batch 155 loss: 0.000572176929563284
batch 160 loss: 0.0005716460291296244
batch 165 loss: 0.0005714610801078379
batch 170 loss: 0.000571163441054523
batch 175 loss: 0.0005705697112716734
batch 180 loss: 0.0005698265857063233
batch 185 loss: 0.0005694503430277109
batch 190 loss: 0.0005700198817066848
batch 195 loss: 0.0005690430873073638
batch 200 loss: 0.0005694357212632894
batch 205 loss: 0.0005698856781236828
batch 210 loss: 0.0005691373255103827
batch 215 loss: 0.0005701620364561677
batch 220 loss: 0.0005693086539395153
batch 225 loss: 0.0005690585356205701
batch 230 loss: 0.000568679056596011
batch 235 loss: 0.0005685889162123203
batch 240 loss: 0.0005680661415681243
Training Loss: 0.0005674640194532306
Validation Loss: 0.0005684005077152203
Epoch 12:
batch 5 loss: 0.0005678798072040081
batch 10 loss: 0.0005677451961673796
batch 15 loss: 0.0005673740874044597
batch 20 loss: 0.0005672208964824677
batch 25 loss: 0.0005675591644831001
batch 30 loss: 0.0005674075451679528
batch 35 loss: 0.0005674307118169964
batch 40 loss: 0.0005674747982993722
batch 45 loss: 0.0005673512583598495
batch 50 loss: 0.0005674317944794893
batch 55 loss: 0.000567589490674436
batch 60 loss: 0.0005674928077496588
batch 65 loss: 0.0005673998617567122
batch 70 loss: 0.0005673573352396489
batch 75 loss: 0.0005672841449268162
batch 80 loss: 0.0005672560073435307
batch 85 loss: 0.0005672025494277477
batch 90 loss: 0.0005671037710271776
batch 95 loss: 0.0005671894759871066
batch 100 loss: 0.0005671092774718999
batch 105 loss: 0.0005671479622833431
batch 110 loss: 0.0005670398939400911
batch 115 loss: 0.0005669822450727225
batch 120 loss: 0.0005669624544680119
batch 125 loss: 0.0005669453297741711
batch 130 loss: 0.0005668645724654197
batch 135 loss: 0.0005668861092999577
batch 140 loss: 0.0005667151999659836
batch 145 loss: 0.0005667727207764983
batch 150 loss: 0.0005667298450134694
batch 155 loss: 0.0005668346537277102
batch 160 loss: 0.0005666388897225261
batch 165 loss: 0.0005665411590598524
batch 170 loss: 0.0005666096578352154
batch 175 loss: 0.0005666638724505901
batch 180 loss: 0.0005666434299200773
batch 185 loss: 0.0005664830445311963
batch 190 loss: 0.000566568598151207
batch 195 loss: 0.0005664354423061014
batch 200 loss: 0.000566420960240066
batch 205 loss: 0.0005663151503540575
batch 210 loss: 0.0005663921125233174
batch 215 loss: 0.0005662845796905458
batch 220 loss: 0.0005661930539645254
batch 225 loss: 0.0005660929484292865
batch 230 loss: 0.0005661653121933341
batch 235 loss: 0.0005659722490236163
batch 240 loss: 0.0005660154740326107
Training Loss: 0.0005669203521392774
Validation Loss: 0.0005659054741651441
Epoch 13:
batch 5 loss: 0.0005659098271280528
batch 10 loss: 0.0005657895468175411
batch 15 loss: 0.0005657834582962096
batch 20 loss: 0.0005658364738337695
batch 25 loss: 0.0005656353547237814
batch 30 loss: 0.000565778894815594
batch 35 loss: 0.0005657707923091948
batch 40 loss: 0.0005657411646097898
batch 45 loss: 0.0005657201982103288
batch 50 loss: 0.0005655709770508111
batch 55 loss: 0.0005655284388922155
batch 60 loss: 0.0005655300221405924
batch 65 loss: 0.0005655967630445957
batch 70 loss: 0.0005656698485836387
batch 75 loss: 0.0005654406268149614
batch 80 loss: 0.0005658185575157404
batch 85 loss: 0.0005661306204274297
batch 90 loss: 0.0005660959170199931
batch 95 loss: 0.0005664537777192891
batch 100 loss: 0.0005661409581080079
batch 105 loss: 0.0005658063688315451
batch 110 loss: 0.000566128978971392
batch 115 loss: 0.0005657401285134256
batch 120 loss: 0.0005658416543155908
batch 125 loss: 0.0005655481130816042
batch 130 loss: 0.0005657633999362587
batch 135 loss: 0.000565906020347029
batch 140 loss: 0.0005650410545058549
batch 145 loss: 0.0005648693535476923
batch 150 loss: 0.0005646952311508357
batch 155 loss: 0.0005648129270412027
batch 160 loss: 0.0005650448612868786
batch 165 loss: 0.0005646559409797191
batch 170 loss: 0.000564295263029635
batch 175 loss: 0.0005644291872158646
batch 180 loss: 0.0005644970224238932
batch 185 loss: 0.0005642818985506892
batch 190 loss: 0.0005644095130264759
batch 195 loss: 0.0005647791665978729
batch 200 loss: 0.0005646738456562162
batch 205 loss: 0.0005650391452945769
batch 210 loss: 0.0005652744672261179
batch 215 loss: 0.0005648711230605841
batch 220 loss: 0.0005650627543218433
batch 225 loss: 0.000564386835321784
batch 230 loss: 0.0005643440526910126
batch 235 loss: 0.0005636715563014149
batch 240 loss: 0.0005632631713524461
Training Loss: 0.0005652724010966873
Validation Loss: 0.000563218051684089
Epoch 14:
batch 5 loss: 0.0005629434599541128
batch 10 loss: 0.0005631117499433457
batch 15 loss: 0.0005629780353046954
batch 20 loss: 0.0005631826468743383
batch 25 loss: 0.0005632929154671728
batch 30 loss: 0.0005637839203700423
batch 35 loss: 0.0005633697845041751
batch 40 loss: 0.0005631702719256282
batch 45 loss: 0.0005632107728160918
batch 50 loss: 0.000563182367477566
batch 55 loss: 0.0005630951258353889
batch 60 loss: 0.000563253287691623
batch 65 loss: 0.0005628895596601069
batch 70 loss: 0.0005629562423564493
batch 75 loss: 0.0005626872181892395
batch 80 loss: 0.0005634529050439596
batch 85 loss: 0.0005629690480418503
batch 90 loss: 0.0005625160643830896
batch 95 loss: 0.0005622562486678362
batch 100 loss: 0.0005623913486488164
batch 105 loss: 0.000562603515572846
batch 110 loss: 0.0005621500429697334
batch 115 loss: 0.0005625934340059757
batch 120 loss: 0.0005664599593728781
batch 125 loss: 0.0006145401974208653
batch 130 loss: 0.0006948499940335751
batch 135 loss: 0.0005915927467867732
batch 140 loss: 0.0005816885037347675
batch 145 loss: 0.0005804586806334555
batch 150 loss: 0.0005790108698420227
batch 155 loss: 0.0005784878041595221
batch 160 loss: 0.0005784094799309969
batch 165 loss: 0.0005776797188445926
batch 170 loss: 0.0005773206474259495
batch 175 loss: 0.000576729525346309
batch 180 loss: 0.0005742658628150821
batch 185 loss: 0.0005734696984291077
batch 190 loss: 0.0005732173565775156
batch 195 loss: 0.0005725010647438467
batch 200 loss: 0.0005724269081838429
batch 205 loss: 0.000570669921580702
batch 210 loss: 0.0005692549049854279
batch 215 loss: 0.0005680346628651022
batch 220 loss: 0.0005678941612131894
batch 225 loss: 0.0005678453715518117
batch 230 loss: 0.0005677051492966711
batch 235 loss: 0.0005677168839611114
batch 240 loss: 0.0005680658970959485
Training Loss: 0.0005720486653444823
Validation Loss: 0.0005662560220419739
Epoch 15:
batch 5 loss: 0.0005665509845130146
batch 10 loss: 0.0005665125325322151
batch 15 loss: 0.0005651816143654286
batch 20 loss: 0.0005646948236972093
batch 25 loss: 0.000564582017250359
batch 30 loss: 0.000564832508098334
batch 35 loss: 0.000564742018468678
batch 40 loss: 0.0005643014330416918
batch 45 loss: 0.0005644219694659114
batch 50 loss: 0.0005641313269734383
batch 55 loss: 0.0005641996627673507
batch 60 loss: 0.0005637802649289369
batch 65 loss: 0.000563746562693268
batch 70 loss: 0.0005637189373373985
batch 75 loss: 0.0005639312090352178
batch 80 loss: 0.0005642355070449411
batch 85 loss: 0.0005641730851493776
batch 90 loss: 0.0005641675321385265
batch 95 loss: 0.000564505800139159
batch 100 loss: 0.0005641040159389376
batch 105 loss: 0.0005645887460559607
batch 110 loss: 0.0005646713310852647
batch 115 loss: 0.0005646381760016084
batch 120 loss: 0.0005643649608828127
batch 125 loss: 0.0005647465121001005
batch 130 loss: 0.0005643750191666186
batch 135 loss: 0.0005642910837195814
batch 140 loss: 0.0005641287774778902
batch 145 loss: 0.0005641767056658864
batch 150 loss: 0.0005644175340421498
batch 155 loss: 0.0005645699682645499
batch 160 loss: 0.0005642389762215317
batch 165 loss: 0.000563955761026591
batch 170 loss: 0.0005643370328471065
batch 175 loss: 0.0005648687714710831
batch 180 loss: 0.0005639625596813858
batch 185 loss: 0.0005642510717734694
batch 190 loss: 0.0005635905545204878
batch 195 loss: 0.0005636670626699925
batch 200 loss: 0.0005633181775920093
batch 205 loss: 0.0005634984234347939
batch 210 loss: 0.0005633619264699518
batch 215 loss: 0.0005629901657812298
batch 220 loss: 0.0005628190818242728
batch 225 loss: 0.0005633455002680421
batch 230 loss: 0.0005629008286632597
batch 235 loss: 0.0005629460327327251
batch 240 loss: 0.000562704773619771
Training Loss: 0.0005641716525133234
Validation Loss: 0.0005625551178430518
Epoch 16:
batch 5 loss: 0.0005627862410619855
batch 10 loss: 0.0005630227620713413
batch 15 loss: 0.0005628244485706091
batch 20 loss: 0.0005624530720524489
batch 25 loss: 0.0005622905446216464
batch 30 loss: 0.0005623767618089914
batch 35 loss: 0.0005628407234326005
batch 40 loss: 0.0005634229048155249
batch 45 loss: 0.0005641100811772049
batch 50 loss: 0.0005634436383843422
batch 55 loss: 0.0005637527559883892
batch 60 loss: 0.000562738161534071
batch 65 loss: 0.0005625798366963863
batch 70 loss: 0.0005622984608635306
batch 75 loss: 0.0005622654687613248
batch 80 loss: 0.0005621938151307404
batch 85 loss: 0.0005622968776151538
batch 90 loss: 0.000562546425499022
batch 95 loss: 0.0005630713887512684
batch 100 loss: 0.0005632527754642069
batch 105 loss: 0.0005626664380542934
batch 110 loss: 0.0005626383353956044
batch 115 loss: 0.0005625361809507012
batch 120 loss: 0.0005621068296022714
batch 125 loss: 0.0005621339660137892
batch 130 loss: 0.0005619049770757556
batch 135 loss: 0.0005619848729111254
batch 140 loss: 0.000561933615244925
batch 145 loss: 0.0005616665701381862
batch 150 loss: 0.0005616069305688143
batch 155 loss: 0.0005619961768388749
batch 160 loss: 0.0005621037795208395
batch 165 loss: 0.0005619584931991995
batch 170 loss: 0.0005623790551908314
batch 175 loss: 0.0005619707982987166
batch 180 loss: 0.0005615956848487258
batch 185 loss: 0.0005619547213427722
batch 190 loss: 0.0005618005874566734
batch 195 loss: 0.0005617227521724999
batch 200 loss: 0.0005617124959826469
batch 205 loss: 0.0005625308025628328
batch 210 loss: 0.0005640166462399065
batch 215 loss: 0.0005642102099955082
batch 220 loss: 0.0005639289855025708
batch 225 loss: 0.0005634408793412149
batch 230 loss: 0.0005629495135508478
batch 235 loss: 0.0005627349251881242
batch 240 loss: 0.0005625227466225624
Training Loss: 0.0005625682315439917
Validation Loss: 0.00057151870666227
Epoch 17:
batch 5 loss: 0.0005619985517114401
batch 10 loss: 0.0005620941170491278
batch 15 loss: 0.0005620455485768616
batch 20 loss: 0.0005619901814498008
batch 25 loss: 0.0005614216206595302
batch 30 loss: 0.0005614510271698236
batch 35 loss: 0.000561731238849461
batch 40 loss: 0.0005614170455373824
batch 45 loss: 0.0005613197223283351
batch 50 loss: 0.0005611972417682409
batch 55 loss: 0.0005611190223135054
batch 60 loss: 0.0005611528409644962
batch 65 loss: 0.0005612676381133497
batch 70 loss: 0.0005610830150544644
batch 75 loss: 0.0005612073699012398
batch 80 loss: 0.0005613044602796435
batch 85 loss: 0.0005612967652268708
batch 90 loss: 0.0005609957966953516
batch 95 loss: 0.0005609151674434542
batch 100 loss: 0.0005609138053841889
batch 105 loss: 0.0005608389736153185
batch 110 loss: 0.0005608241655863822
batch 115 loss: 0.0005608123145066201
batch 120 loss: 0.0005607736646197736
batch 125 loss: 0.0005607364233583212
batch 130 loss: 0.0005610452615655958
batch 135 loss: 0.0005612534587271512
batch 140 loss: 0.000561091466806829
batch 145 loss: 0.0005611927132122219
batch 150 loss: 0.0005610349006019532
batch 155 loss: 0.0005608692998066544
batch 160 loss: 0.0005611590459011495
batch 165 loss: 0.000561008823569864
batch 170 loss: 0.0005609144689515233
batch 175 loss: 0.0005608363775536418
batch 180 loss: 0.0005607548635452985
batch 185 loss: 0.0005606930353678763
batch 190 loss: 0.0005607074708677828
batch 195 loss: 0.0005609239568002522
batch 200 loss: 0.0005606962600722909
batch 205 loss: 0.0008888825075700879
batch 210 loss: 0.0005895458278246223
batch 215 loss: 0.0005911270389333367
batch 220 loss: 0.0005947147961705923
batch 225 loss: 0.0005958755617029964
batch 230 loss: 0.000592403148766607
batch 235 loss: 0.0005860650679096579
batch 240 loss: 0.0005806195084005594
Training Loss: 0.0005721942203914902
Validation Loss: 0.0005797738839949791
Epoch 18:
batch 5 loss: 0.0005766856949776411
batch 10 loss: 0.000573073560371995
batch 15 loss: 0.0005714684375561774
batch 20 loss: 0.0005694592022337019
batch 25 loss: 0.0005681491340510548
batch 30 loss: 0.0005670459591783583
batch 35 loss: 0.0005660561728291214
batch 40 loss: 0.000565366621594876
batch 45 loss: 0.0005648088059388101
batch 50 loss: 0.000565144163556397
batch 55 loss: 0.0005653075757436454
batch 60 loss: 0.0005650290520861744
batch 65 loss: 0.0005646143574267626
batch 70 loss: 0.0005643900134600699
batch 75 loss: 0.000564437301363796
batch 80 loss: 0.0005653067491948605
batch 85 loss: 0.000565393443685025
batch 90 loss: 0.0005656557623296976
batch 95 loss: 0.0005654322449117899
batch 100 loss: 0.0005654743174090982
batch 105 loss: 0.0005657993024215102
batch 110 loss: 0.0005655121640302241
batch 115 loss: 0.0005656495341099799
batch 120 loss: 0.0005659815738908947
batch 125 loss: 0.0005662505282089114
batch 130 loss: 0.000567149359267205
batch 135 loss: 0.0005660964641720056
batch 140 loss: 0.0005666892626322806
batch 145 loss: 0.0005661058705300093
batch 150 loss: 0.0005655884626321495
batch 155 loss: 0.0005662194220349192
batch 160 loss: 0.0005664095398969949
batch 165 loss: 0.0005653744330629707
batch 170 loss: 0.000565208529587835
batch 175 loss: 0.0005652609514072537
batch 180 loss: 0.0005650646868161857
batch 185 loss: 0.0005652963067404926
batch 190 loss: 0.0005666128592565656
batch 195 loss: 0.0005656046327203512
batch 200 loss: 0.0005650186212733388
batch 205 loss: 0.0005648176302202046
batch 210 loss: 0.0005653260392136872
batch 215 loss: 0.0005653984961099922
batch 220 loss: 0.0005652932799421251
batch 225 loss: 0.0005644166609272361
batch 230 loss: 0.0005641864379867911
batch 235 loss: 0.000564913940615952
batch 240 loss: 0.0005653472733683884
Training Loss: 0.000566143559020323
Validation Loss: 0.0005644853643995399
Epoch 19:
batch 5 loss: 0.0005653026048094035
batch 10 loss: 0.0005656468914821744
batch 15 loss: 0.0005656032357364893
batch 20 loss: 0.0005664008087478579
batch 25 loss: 0.0005660010618157684
batch 30 loss: 0.0005656916531734168
batch 35 loss: 0.0005649289698339999
batch 40 loss: 0.000564594438765198
batch 45 loss: 0.0005646170233376324
batch 50 loss: 0.0005647599115036428
batch 55 loss: 0.0005643730284646154
batch 60 loss: 0.0005641229567117989
batch 65 loss: 0.0005640020594000816
batch 70 loss: 0.0005637989612296224
batch 75 loss: 0.0005640621297061443
batch 80 loss: 0.000564378360286355
batch 85 loss: 0.0005649648606777191
batch 90 loss: 0.0005650240113027394
batch 95 loss: 0.0005643419222906232
batch 100 loss: 0.0005644472083076834
batch 105 loss: 0.000564820971339941
batch 110 loss: 0.0005646159406751394
batch 115 loss: 0.0005651074578054249
batch 120 loss: 0.0005652949796058238
batch 125 loss: 0.0005653824424371124
batch 130 loss: 0.0005651981104165315
batch 135 loss: 0.0005652695312164724
batch 140 loss: 0.0005647864658385515
batch 145 loss: 0.0005646285018883646
batch 150 loss: 0.0005645661964081228
batch 155 loss: 0.0005644545890390873
batch 160 loss: 0.0005646721110679209
batch 165 loss: 0.0005657422821968794
batch 170 loss: 0.0005655678221955895
batch 175 loss: 0.0005650743143633008
batch 180 loss: 0.0005645008408464491
batch 185 loss: 0.0005642054486088455
batch 190 loss: 0.000564388174097985
batch 195 loss: 0.0005644842283800244
batch 200 loss: 0.0005647472687996923
batch 205 loss: 0.0005635753157548606
batch 210 loss: 0.0005639362731017173
batch 215 loss: 0.0005632970714941621
batch 220 loss: 0.0005631344625726342
batch 225 loss: 0.0005628742976114154
batch 230 loss: 0.0005626819329336286
batch 235 loss: 0.0005627963808365166
batch 240 loss: 0.0005626423633657395
Training Loss: 0.0005645730806766853
Validation Loss: 0.000562084760167636
Epoch 20:
batch 5 loss: 0.0005625218618661165
batch 10 loss: 0.0005627378122881055
batch 15 loss: 0.0005630812025628984
batch 20 loss: 0.0005628958577290177
batch 25 loss: 0.0005630544503219426
batch 30 loss: 0.0005635908106341958
batch 35 loss: 0.0005629322491586209
batch 40 loss: 0.0005627587786875665
batch 45 loss: 0.0005624373443424702
batch 50 loss: 0.0005627678357996047
batch 55 loss: 0.0005632815416902303
batch 60 loss: 0.0005637409049086273
batch 65 loss: 0.000563279737252742
batch 70 loss: 0.0005637050839141011
batch 75 loss: 0.0005633799592033029
batch 80 loss: 0.0005637443857267499
batch 85 loss: 0.0005640062503516674
batch 90 loss: 0.0005631247535347938
batch 95 loss: 0.0005629114108160138
batch 100 loss: 0.0005630421685054899
batch 105 loss: 0.000562713632825762
batch 110 loss: 0.0005625426187179982
batch 115 loss: 0.000562210800126195
batch 120 loss: 0.0005620903219096362
batch 125 loss: 0.0005617847200483084
batch 130 loss: 0.0005620987270958721
batch 135 loss: 0.0005619418923743069
batch 140 loss: 0.0005619388772174716
batch 145 loss: 0.0005622582044452429
batch 150 loss: 0.0005632216576486826
batch 155 loss: 0.0005629538442008198
batch 160 loss: 0.000562575040385127
batch 165 loss: 0.0005619699251838029
batch 170 loss: 0.000562163011636585
batch 175 loss: 0.0005623274832032621
batch 180 loss: 0.0005620071082375943
batch 185 loss: 0.000561878178268671
batch 190 loss: 0.0005619288189336657
batch 195 loss: 0.0005620625102892518
batch 200 loss: 0.000562189833726734
batch 205 loss: 0.0005619099130854011
batch 210 loss: 0.0005619319388642907
batch 215 loss: 0.0005619784467853605
batch 220 loss: 0.0005618989118374885
batch 225 loss: 0.0005619796691462397
batch 230 loss: 0.0005618355353362858
batch 235 loss: 0.0005616213660687208
batch 240 loss: 0.0005614296416752041
Training Loss: 0.0005625507714285049
Validation Loss: 0.0005611329562574004
Epoch 21:
batch 5 loss: 0.000561351515352726
batch 10 loss: 0.000561280851252377
batch 15 loss: 0.0005610644351691007
batch 20 loss: 0.0005612582666799426
batch 25 loss: 0.0005613076966255904
batch 30 loss: 0.0005612320965155959
batch 35 loss: 0.0005611983826383949
batch 40 loss: 0.0005618324968963862
batch 45 loss: 0.0005616431939415633
batch 50 loss: 0.0005616212845779955
batch 55 loss: 0.0005613530171103776
batch 60 loss: 0.0005612025852315128
batch 65 loss: 0.0005611525382846593
batch 70 loss: 0.0005612305365502834
batch 75 loss: 0.0005608903476968408
batch 80 loss: 0.0005606761900708079
batch 85 loss: 0.0005610616761259734
batch 90 loss: 0.0005610232008621096
batch 95 loss: 0.0005608828505501151
batch 100 loss: 0.0005605272599495947
batch 105 loss: 0.0005608942010439932
batch 110 loss: 0.0005613328656181693
batch 115 loss: 0.0005611417349427938
batch 120 loss: 0.0005611018394120037
batch 125 loss: 0.0005610910244286061
batch 130 loss: 0.0005609143758192658
batch 135 loss: 0.0005612009554170072
batch 140 loss: 0.000561002385802567
batch 145 loss: 0.0005610078456811607
batch 150 loss: 0.000560935668181628
batch 155 loss: 0.0005608464009128511
batch 160 loss: 0.0005609128973446786
batch 165 loss: 0.0005603996920399368
batch 170 loss: 0.0005606706836260855
batch 175 loss: 0.0005604518461041153
batch 180 loss: 0.00056036472087726
batch 185 loss: 0.0005603968049399555
batch 190 loss: 0.0005611350992694497
batch 195 loss: 0.0005609594634734094
batch 200 loss: 0.0005607321159914136
batch 205 loss: 0.0005607758066616952
batch 210 loss: 0.0005606526858173311
batch 215 loss: 0.0005604743724688888
batch 220 loss: 0.000560412066988647
batch 225 loss: 0.0005606891005299986
batch 230 loss: 0.0005605397396720946
batch 235 loss: 0.0005607707891613245
batch 240 loss: 0.0005608862731605769
Training Loss: 0.0005609684141139345
Validation Loss: 0.0005605185840977355
Epoch 22:
batch 5 loss: 0.0005607198923826218
batch 10 loss: 0.0005605556187219917
batch 15 loss: 0.0005605118698440492
batch 20 loss: 0.0005606004036962986
batch 25 loss: 0.0005602482007816434
batch 30 loss: 0.0005602681310847401
batch 35 loss: 0.0005604986450634897
batch 40 loss: 0.0005607191123999655
batch 45 loss: 0.0005605363170616328
batch 50 loss: 0.0005607533850707114
batch 55 loss: 0.0005606699269264936
batch 60 loss: 0.0005605508573353291
batch 65 loss: 0.0005606423364952207
batch 70 loss: 0.0005607567960396409
batch 75 loss: 0.0005604846752248705
batch 80 loss: 0.0005603719968348741
batch 85 loss: 0.0005601592827588319
batch 90 loss: 0.0005601229262538254
batch 95 loss: 0.0005606729304417968
batch 100 loss: 0.0005602916586212814
batch 105 loss: 0.0005601443001069129
batch 110 loss: 0.0005601866985671222
batch 115 loss: 0.0005600797710940241
batch 120 loss: 0.0005601722630672156
batch 125 loss: 0.0005599548108875752
batch 130 loss: 0.0005603042198345065
batch 135 loss: 0.0005601309821940958
batch 140 loss: 0.0005600767792202533
batch 145 loss: 0.0005601929617114366
batch 150 loss: 0.0005601309589110315
batch 155 loss: 0.0005605204030871391
batch 160 loss: 0.0005601942655630409
batch 165 loss: 0.0005600036005489528
batch 170 loss: 0.0005603560362942517
batch 175 loss: 0.0005605995655059814
batch 180 loss: 0.0005601018085144461
batch 185 loss: 0.0005597866373136639
batch 190 loss: 0.0005598120391368866
batch 195 loss: 0.0005599690251983702
batch 200 loss: 0.0005599729600362479
batch 205 loss: 0.0005598270450718701
batch 210 loss: 0.0005600274191237987
batch 215 loss: 0.0005605294951237738
batch 220 loss: 0.0005603541736491025
batch 225 loss: 0.0005600680713541805
batch 230 loss: 0.0005599809694103897
batch 235 loss: 0.0005597774987109005
batch 240 loss: 0.0005599594209343195
Training Loss: 0.000560278107150225
Validation Loss: 0.0005598344888615732
Epoch 23:
batch 5 loss: 0.0005596746108494699
batch 10 loss: 0.0005597089766524732
batch 15 loss: 0.000559726229403168
batch 20 loss: 0.0005597400129772722
batch 25 loss: 0.0005596300004981458
batch 30 loss: 0.0005600014701485634
batch 35 loss: 0.0005597667070105672
batch 40 loss: 0.0005598913063295186
batch 45 loss: 0.0005600379081442952
batch 50 loss: 0.0005599984433501959
batch 55 loss: 0.0005599018535576761
batch 60 loss: 0.0005598662653937935
batch 65 loss: 0.0005597246112301945
batch 70 loss: 0.0005596657516434789
batch 75 loss: 0.0005597379291430116
batch 80 loss: 0.0005598783493041993
batch 85 loss: 0.000559877185150981
batch 90 loss: 0.000559986277949065
batch 95 loss: 0.0005599307245574891
batch 100 loss: 0.0005597198149189353
batch 105 loss: 0.000559712084941566
batch 110 loss: 0.0005596701405011118
batch 115 loss: 0.0005596666596829891
batch 120 loss: 0.0005595843656919896
batch 125 loss: 0.0005595454829744994
batch 130 loss: 0.0005595514085143805
batch 135 loss: 0.000559728208463639
batch 140 loss: 0.0005596301169134676
batch 145 loss: 0.0005595978815108538
batch 150 loss: 0.0005596574046649039
batch 155 loss: 0.0005596054368652403
batch 160 loss: 0.0005599779426120222
batch 165 loss: 0.0005598381743766367
batch 170 loss: 0.0005595677881501615
batch 175 loss: 0.0005599288851954043
batch 180 loss: 0.0005599164054729044
batch 185 loss: 0.0005598973133601248
batch 190 loss: 0.000559758476447314
batch 195 loss: 0.0005597764742560684
batch 200 loss: 0.0005597542622126639
batch 205 loss: 0.000559753633569926
batch 210 loss: 0.00055967983789742
batch 215 loss: 0.0005595463328063488
batch 220 loss: 0.0005596969043835997
batch 225 loss: 0.0005598489195108413
batch 230 loss: 0.0005596679518930614
batch 235 loss: 0.0005595616879872978
batch 240 loss: 0.0005596023169346154
Training Loss: 0.0005597538942917406
Validation Loss: 0.0005597564595518634
Epoch 24:
batch 5 loss: 0.0005598534597083926
batch 10 loss: 0.000559844053350389
batch 15 loss: 0.000559645181056112
batch 20 loss: 0.0005594035494141281
batch 25 loss: 0.0005596923874691129
batch 30 loss: 0.000559589359909296
batch 35 loss: 0.0005598966032266617
batch 40 loss: 0.0005597048322670162
batch 45 loss: 0.0005597685463726521
batch 50 loss: 0.0005597093026153743
batch 55 loss: 0.0005595647729933262
batch 60 loss: 0.0005594513262622058
batch 65 loss: 0.0005594975780695676
batch 70 loss: 0.0005595750757493078
batch 75 loss: 0.0005594450514763594
batch 80 loss: 0.0005595786031335592
batch 85 loss: 0.0005596145056188107
batch 90 loss: 0.0005594295915216207
batch 95 loss: 0.0005595728289335966
batch 100 loss: 0.0005595692549832165
batch 105 loss: 0.0005595350870862603
batch 110 loss: 0.0005595911061391234
batch 115 loss: 0.0005594780668616295
batch 120 loss: 0.0005598908173851669
batch 125 loss: 0.0005598669173195958
batch 130 loss: 0.0005596784641966224
batch 135 loss: 0.0005596351344138384
batch 140 loss: 0.0005595210008323192
batch 145 loss: 0.0005594291375018656
batch 150 loss: 0.0005593093228526413
batch 155 loss: 0.0005594702088274062
batch 160 loss: 0.0005592033499851823
batch 165 loss: 0.0005593621172010899
batch 170 loss: 0.0005594712216407061
batch 175 loss: 0.0005595299182459712
batch 180 loss: 0.0005594271002337337
batch 185 loss: 0.0005594430025666952
batch 190 loss: 0.0005595444235950708
batch 195 loss: 0.0005594416288658977
batch 200 loss: 0.0005593151669017971
batch 205 loss: 0.0005595958791673183
batch 210 loss: 0.0005594346672296524
batch 215 loss: 0.0005594110349193216
batch 220 loss: 0.0005593645968474448
batch 225 loss: 0.0005596189759671689
batch 230 loss: 0.0005667459685355425
batch 235 loss: 0.0005751906894147397
batch 240 loss: 0.0005761014763265848
Training Loss: 0.0005603752571914811
Validation Loss: 0.007399755367077887
Epoch 25:
batch 5 loss: 0.0005746872513554991
batch 10 loss: 0.0005745621514506638
batch 15 loss: 0.0005704332957975567
batch 20 loss: 0.0005684311618097126
batch 25 loss: 0.0005666170734912157
batch 30 loss: 0.000565345014911145
batch 35 loss: 0.0005639050039462745
batch 40 loss: 0.0005629268591292203
batch 45 loss: 0.0005623290082439781
batch 50 loss: 0.0005617400747723877
batch 55 loss: 0.00056141969980672
batch 60 loss: 0.0005611934582702815
batch 65 loss: 0.0005609106970950961
batch 70 loss: 0.0005608992185443639
batch 75 loss: 0.0005606736522167921
batch 80 loss: 0.0005607691709883511
batch 85 loss: 0.0005605958867818117
batch 90 loss: 0.0005606371210888028
batch 95 loss: 0.0005605704034678638
batch 100 loss: 0.000560546584893018
batch 105 loss: 0.000560431950725615
batch 110 loss: 0.0005602539516985416
batch 115 loss: 0.000560322729870677
batch 120 loss: 0.0005602357210591436
batch 125 loss: 0.0005602734978310764
batch 130 loss: 0.0005602616933174431
batch 135 loss: 0.0005602021468803286
batch 140 loss: 0.0005602406221441924
batch 145 loss: 0.0005602585035376251
batch 150 loss: 0.0005602838937193155
batch 155 loss: 0.0005604674690403045
batch 160 loss: 0.0005602675373665988
batch 165 loss: 0.0005604258622042835
batch 170 loss: 0.0005603293655440211
batch 175 loss: 0.0005603666068054736
batch 180 loss: 0.0005604889942333102
batch 185 loss: 0.0005603670259006321
batch 190 loss: 0.0005603187484666706
batch 195 loss: 0.0005603093304671347
batch 200 loss: 0.0005603784578852355
batch 205 loss: 0.0005602640216238796
batch 210 loss: 0.0005602498888038099
batch 215 loss: 0.0005603030207566917
batch 220 loss: 0.0005600994918495417
batch 225 loss: 0.0005599537398666143
batch 230 loss: 0.0005601009237580001
batch 235 loss: 0.0005600281874649227
batch 240 loss: 0.000560045544989407
Training Loss: 0.0005618067024139843
Validation Loss: 0.0005598718077332402
Epoch 26:
batch 5 loss: 0.0005598753574304283
batch 10 loss: 0.0005597168928943574
batch 15 loss: 0.0005598839605227112
batch 20 loss: 0.0005598966032266617
batch 25 loss: 0.000559948617592454
batch 30 loss: 0.0005597948096692562
batch 35 loss: 0.0005598530173301697
batch 40 loss: 0.0005596410366706551
batch 45 loss: 0.0005597277078777552
batch 50 loss: 0.0005596275441348553
batch 55 loss: 0.0005595606518909336
batch 60 loss: 0.0005594927119091153
batch 65 loss: 0.0005594981485046446
batch 70 loss: 0.000559465994592756
batch 75 loss: 0.0005593070527538657
batch 80 loss: 0.0005592674599029124
batch 85 loss: 0.0005592269590124488
batch 90 loss: 0.0005591671797446907
batch 95 loss: 0.0005589267238974571
batch 100 loss: 0.0005588195170275867
batch 105 loss: 0.0005587104824371636
batch 110 loss: 0.0005584759870544076
batch 115 loss: 0.0005580509779974819
batch 120 loss: 0.000557582126930356
batch 125 loss: 0.0005576835246756673
batch 130 loss: 0.0005577719421125948
batch 135 loss: 0.0005576444556936622
batch 140 loss: 0.0005575863993726671
batch 145 loss: 0.0005577309872023761
batch 150 loss: 0.0005577352945692837
batch 155 loss: 0.0005576647352427244
batch 160 loss: 0.0005577114410698414
batch 165 loss: 0.0005578074255026877
batch 170 loss: 0.000557652406860143
batch 175 loss: 0.0005576070281676949
batch 180 loss: 0.0005577167845331133
batch 185 loss: 0.0005576661555096507
batch 190 loss: 0.000557742896489799
batch 195 loss: 0.0005576410447247326
batch 200 loss: 0.0005578042473644018
batch 205 loss: 0.0005577075993642211
batch 210 loss: 0.0005575554445385933
batch 215 loss: 0.0005577306030318141
batch 220 loss: 0.0005576350726187229
batch 225 loss: 0.0005576814874075353
batch 230 loss: 0.00055760646937415
batch 235 loss: 0.0005576335592195391
batch 240 loss: 0.0005575932678766549
Training Loss: 0.0005584964123651541
Validation Loss: 0.0005576934316195547
Epoch 27:
batch 5 loss: 0.0005575897172093392
batch 10 loss: 0.0005779183702543378
batch 15 loss: 0.0011675366433337331
batch 20 loss: 0.0006136997020803392
batch 25 loss: 0.0005996711202897132
batch 30 loss: 0.0005915689165703952
batch 35 loss: 0.0005850650952197612
batch 40 loss: 0.0005809637950733304
batch 45 loss: 0.0005772211821749807
batch 50 loss: 0.0005751464050263166
batch 55 loss: 0.0005729648866690696
batch 60 loss: 0.0005721696536056698
batch 65 loss: 0.0005714715574868023
batch 70 loss: 0.0005705397808924318
batch 75 loss: 0.0005700045381672681
batch 80 loss: 0.0005694996099919081
batch 85 loss: 0.0005693911458365619
batch 90 loss: 0.0005689456476829946
batch 95 loss: 0.0005686936434358359
batch 100 loss: 0.0005684472387656569
batch 105 loss: 0.0005681495531462133
batch 110 loss: 0.00056798264849931
batch 115 loss: 0.0005678748362697661
batch 120 loss: 0.0005676615750417113
batch 125 loss: 0.0005675933323800563
batch 130 loss: 0.0005674138781614601
batch 135 loss: 0.0005670997430570424
batch 140 loss: 0.0005669956561177969
batch 145 loss: 0.0005668451078236103
batch 150 loss: 0.0005667358171194791
batch 155 loss: 0.0005665964097715914
batch 160 loss: 0.0005663679679855704
batch 165 loss: 0.0005662002018652857
batch 170 loss: 0.0005659727961756289
batch 175 loss: 0.0005657845293171703
batch 180 loss: 0.0005657302914187312
batch 185 loss: 0.0005655266111716628
batch 190 loss: 0.0005652411608025431
batch 195 loss: 0.0005653236526995898
batch 200 loss: 0.0005654491018503904
batch 205 loss: 0.0005658356356434524
batch 210 loss: 0.0005656208842992783
batch 215 loss: 0.0005652879714034498
batch 220 loss: 0.0005650384118780494
batch 225 loss: 0.0005648355465382338
batch 230 loss: 0.0005647611455060541
batch 235 loss: 0.0005645605851896107
batch 240 loss: 0.0005643807002343237
Training Loss: 0.0005829453000236148
Validation Loss: 0.0005645142771148433
Epoch 28:
batch 5 loss: 0.0005643009790219367
batch 10 loss: 0.0005643876851536333
batch 15 loss: 0.0005770148593001068
batch 20 loss: 0.000568936753552407
batch 25 loss: 0.0005686081945896149
batch 30 loss: 0.0005676017608493567
batch 35 loss: 0.0005670018377713859
batch 40 loss: 0.0005664928117766977
batch 45 loss: 0.0005662030773237348
batch 50 loss: 0.0005660319584421813
batch 55 loss: 0.0005658605950884521
batch 60 loss: 0.0005655742017552257
batch 65 loss: 0.0005655433516949416
batch 70 loss: 0.0005653669475577771
batch 75 loss: 0.0005652921856381
batch 80 loss: 0.0005652373773045837
batch 85 loss: 0.0005651590065099299
batch 90 loss: 0.0005650658160448075
batch 95 loss: 0.0005648747901432216
batch 100 loss: 0.0005648215999826788
batch 105 loss: 0.0005646683624945581
batch 110 loss: 0.0005646688165143132
batch 115 loss: 0.0005646426347084343
batch 120 loss: 0.0005644230521284043
batch 125 loss: 0.0005645248456858099
batch 130 loss: 0.0005644438322633504
batch 135 loss: 0.0005643034121021629
batch 140 loss: 0.0005643084179610014
batch 145 loss: 0.0005642160074785351
batch 150 loss: 0.0005640382412821054
batch 155 loss: 0.0005641275667585433
batch 160 loss: 0.0005640991497784853
batch 165 loss: 0.0005638578091748059
batch 170 loss: 0.0005638925707899034
batch 175 loss: 0.0005637828959152103
batch 180 loss: 0.0005637389491312206
batch 185 loss: 0.0005638592061586678
batch 190 loss: 0.000563533790409565
batch 195 loss: 0.0005636872607283294
batch 200 loss: 0.0005641051568090916
batch 205 loss: 0.0005644809920340776
batch 210 loss: 0.0005640955292619765
batch 215 loss: 0.000563798169605434
batch 220 loss: 0.0005635151057504118
batch 225 loss: 0.0005635981564410031
batch 230 loss: 0.000563410425093025
batch 235 loss: 0.0005633051856420934
batch 240 loss: 0.0005632486892864109
Training Loss: 0.0005650364587684938
Validation Loss: 0.0005632362512794013
Epoch 29:
batch 5 loss: 0.0005634903674945236
batch 10 loss: 0.0005637101596221328
batch 15 loss: 0.0005637184716761112
batch 20 loss: 0.0005634642904624343
batch 25 loss: 0.0005633549066260457
batch 30 loss: 0.000563197664450854
batch 35 loss: 0.0005631552776321769
batch 40 loss: 0.0005629424820654094
batch 45 loss: 0.000562849489506334
batch 50 loss: 0.0005628213868476451
batch 55 loss: 0.0005628868704661727
batch 60 loss: 0.0005626837257295847
batch 65 loss: 0.0005628081737086177
batch 70 loss: 0.0005626545287668705
batch 75 loss: 0.0005626811413094402
batch 80 loss: 0.0005626670666970312
batch 85 loss: 0.0005625704303383827
batch 90 loss: 0.0005624573095701635
batch 95 loss: 0.0005623403121717274
batch 100 loss: 0.000562374119181186
batch 105 loss: 0.0005738490261137485
batch 110 loss: 0.0005659099784679711
batch 115 loss: 0.0005659579881466925
batch 120 loss: 0.0005656472640112042
batch 125 loss: 0.0005654311971738935
batch 130 loss: 0.0005651809624396265
batch 135 loss: 0.0005650335922837257
batch 140 loss: 0.0005648926482535899
batch 145 loss: 0.0005647089332342148
batch 150 loss: 0.0005646687583066523
batch 155 loss: 0.0005645924946293234
batch 160 loss: 0.0005645800032652914
batch 165 loss: 0.0005645882803946734
batch 170 loss: 0.0005645235651172698
batch 175 loss: 0.0005644418066367507
batch 180 loss: 0.0005644424352794885
batch 185 loss: 0.0005642762640491128
batch 190 loss: 0.0005643397569656372
batch 195 loss: 0.00056430947734043
batch 200 loss: 0.0005643170559778809
batch 205 loss: 0.0005643078358843923
batch 210 loss: 0.00056426040828228
batch 215 loss: 0.0005641837837174535
batch 220 loss: 0.0005641763331368565
batch 225 loss: 0.0005641747731715441
batch 230 loss: 0.000564211024902761
batch 235 loss: 0.0005641298135742545
batch 240 loss: 0.0005643516662530601
Training Loss: 0.000564131568777763
Validation Loss: 0.0005644424304288502
Epoch 30:
batch 5 loss: 0.0005644805496558547
batch 10 loss: 0.000564068672247231
batch 15 loss: 0.0005640904302708805
batch 20 loss: 0.0005640885327011346
batch 25 loss: 0.0005642637610435486
batch 30 loss: 0.0005641453783027828
batch 35 loss: 0.0005641421535983682
batch 40 loss: 0.0005642589996568859
batch 45 loss: 0.0005641849711537361
batch 50 loss: 0.0005641704425215721
batch 55 loss: 0.0005641374504193663
batch 60 loss: 0.0005640205228701234
batch 65 loss: 0.0005642306874506176
batch 70 loss: 0.0005641146213747561
batch 75 loss: 0.0005638886359520257
batch 80 loss: 0.0005640526418574154
batch 85 loss: 0.0005640329560264945
batch 90 loss: 0.0005640391842462123
batch 95 loss: 0.0005639722687192262
batch 100 loss: 0.0005638791364617646
batch 105 loss: 0.0005638807779178023
batch 110 loss: 0.0005638734437525272
batch 115 loss: 0.0005638572387397289
batch 120 loss: 0.0005638421862386167
batch 125 loss: 0.0005638485075905919
batch 130 loss: 0.0005637176451273263
batch 135 loss: 0.0005637083551846445
batch 140 loss: 0.0005636448157019913
batch 145 loss: 0.000563510658685118
batch 150 loss: 0.0005635211360640824
batch 155 loss: 0.0005635603331029416
batch 160 loss: 0.0005635375040583312
batch 165 loss: 0.0005634673521853984
batch 170 loss: 0.0005634873639792203
batch 175 loss: 0.0005632482818327845
batch 180 loss: 0.0005634156172163784
batch 185 loss: 0.0005631976528093219
batch 190 loss: 0.0005631231004372239
batch 195 loss: 0.0005630798754282295
batch 200 loss: 0.0005631931009702385
batch 205 loss: 0.0005631483043543994
batch 210 loss: 0.000563078245613724
batch 215 loss: 0.0005630762665532529
batch 220 loss: 0.0005630198982544243
batch 225 loss: 0.0005629526334814727
batch 230 loss: 0.0005628896411508322
batch 235 loss: 0.0005628200946375727
batch 240 loss: 0.0005628004320897162
Training Loss: 0.0005636825512434977
Validation Loss: 0.0005627650709357113
Epoch 31:
batch 5 loss: 0.0005626086960546673
batch 10 loss: 0.0005625696736387909
batch 15 loss: 0.0005626122350804508
batch 20 loss: 0.0005625374265946448
batch 25 loss: 0.0005625546560622752
batch 30 loss: 0.0005625319085083902
batch 35 loss: 0.0005626083351671695
batch 40 loss: 0.0005625615827739239
batch 45 loss: 0.0005624378100037575
batch 50 loss: 0.0005624176119454205
batch 55 loss: 0.0005624040961265564
batch 60 loss: 0.0005622932803817093
batch 65 loss: 0.0005622225347906351
batch 70 loss: 0.0005622996017336845
batch 75 loss: 0.0005622133146971464
batch 80 loss: 0.0005621391348540783
batch 85 loss: 0.000562125607393682
batch 90 loss: 0.0005620318814180791
batch 95 loss: 0.0005620820797048509
batch 100 loss: 0.0005619493080303073
batch 105 loss: 0.000561915582511574
batch 110 loss: 0.0005618628696538508
batch 115 loss: 0.0005618457333184778
batch 120 loss: 0.0005618176655843854
batch 125 loss: 0.0005615742760710418
batch 130 loss: 0.0005616913549602032
batch 135 loss: 0.0005616956274025142
batch 140 loss: 0.0005615209462121129
batch 145 loss: 0.0005613809335045516
batch 150 loss: 0.0005615163478069008
batch 155 loss: 0.0005614061956293881
batch 160 loss: 0.0005613702116534114
batch 165 loss: 0.0005613433080725372
batch 170 loss: 0.0005610974621959031
batch 175 loss: 0.0005610808962956071
batch 180 loss: 0.0005611017812043428
batch 185 loss: 0.0005610525258816779
batch 190 loss: 0.000560968485660851
batch 195 loss: 0.0005610142834484577
batch 200 loss: 0.00056083103409037
batch 205 loss: 0.0005608948646113277
batch 210 loss: 0.000560982758179307
batch 215 loss: 0.0005607066908851266
batch 220 loss: 0.0005612685694359243
batch 225 loss: 0.000562245782930404
batch 230 loss: 0.0005617118207737803
batch 235 loss: 0.0005612581735476851
batch 240 loss: 0.0005613282090052962
Training Loss: 0.0005617851076143173
Validation Loss: 0.000561236353435864
Epoch 32:
batch 5 loss: 0.0005612412816844881
batch 10 loss: 0.0005609435378573835
batch 15 loss: 0.0005610176129266619
batch 20 loss: 0.0005606667720712722
batch 25 loss: 0.000560556969139725
batch 30 loss: 0.000560525362379849
batch 35 loss: 0.0005605207523331046
batch 40 loss: 0.0005606463411822916
batch 45 loss: 0.0005606390186585486
batch 50 loss: 0.0005607111495919525
batch 55 loss: 0.0005605088081210852
batch 60 loss: 0.0005603515077382326
batch 65 loss: 0.0005603593308478594
batch 70 loss: 0.0005603930796496571
batch 75 loss: 0.0005602200399152935
batch 80 loss: 0.000560285511892289
batch 85 loss: 0.0005602486780844629
batch 90 loss: 0.0005603172350674868
batch 95 loss: 0.0005604208912700414
batch 100 loss: 0.0005602060817182064
batch 105 loss: 0.0005609116400592029
batch 110 loss: 0.0005607226863503456
batch 115 loss: 0.0005609001847915352
batch 120 loss: 0.0005609621526673436
batch 125 loss: 0.0005609956686384975
batch 130 loss: 0.0005607749917544425
batch 135 loss: 0.0005605521728284657
batch 140 loss: 0.0005603951751254499
batch 145 loss: 0.000560207455419004
batch 150 loss: 0.0005602934514172375
batch 155 loss: 0.000560279143974185
batch 160 loss: 0.0005601767916232347
batch 165 loss: 0.0005600940901786089
batch 170 loss: 0.0005600507836788892
batch 175 loss: 0.0005600584670901298
batch 180 loss: 0.0005600246367976069
batch 185 loss: 0.0005600718199275434
batch 190 loss: 0.0005600494449026882
batch 195 loss: 0.0005601853248663246
batch 200 loss: 0.0005601250100880861
batch 205 loss: 0.0005600883741863072
batch 210 loss: 0.0005600533215329051
batch 215 loss: 0.0005600572796538473
batch 220 loss: 0.0005600087344646454
batch 225 loss: 0.0005600864300504327
batch 230 loss: 0.0005601581069640815
batch 235 loss: 0.0005600743228569627
batch 240 loss: 0.0005601310636848212
Training Loss: 0.0005604014309938066
Validation Loss: 0.0005600248997022088
Epoch 33:
batch 5 loss: 0.0005599870928563178
batch 10 loss: 0.0005600250908173621
batch 15 loss: 0.0005600369069725275
batch 20 loss: 0.0005598366376943886
batch 25 loss: 0.0005599247175268829
batch 30 loss: 0.0005599155905656516
batch 35 loss: 0.0005599827971309423
batch 40 loss: 0.0005599891534075141
batch 45 loss: 0.0005600062198936939
batch 50 loss: 0.0005599729600362479
batch 55 loss: 0.0005601214477792382
batch 60 loss: 0.0005740041495300829
batch 65 loss: 0.0005667405319400131
batch 70 loss: 0.0005671736435033381
batch 75 loss: 0.0005666221724823118
batch 80 loss: 0.0005658611305989325
batch 85 loss: 0.000564989959821105
batch 90 loss: 0.0005643198965117335
batch 95 loss: 0.0005636973772197961
batch 100 loss: 0.0005626232014037669
batch 105 loss: 0.0005622894153930247
batch 110 loss: 0.0005619474221020937
batch 115 loss: 0.0005616802838630975
batch 120 loss: 0.0005615355796180666
batch 125 loss: 0.0005613168934360147
batch 130 loss: 0.0005612670560367405
batch 135 loss: 0.0005610473337583244
batch 140 loss: 0.0005610388005152344
batch 145 loss: 0.0005609966814517975
batch 150 loss: 0.0005609328392893076
batch 155 loss: 0.0005610215361230075
batch 160 loss: 0.0005608593579381705
batch 165 loss: 0.0005609528510831296
batch 170 loss: 0.0005609720014035702
batch 175 loss: 0.0005609144340269267
batch 180 loss: 0.0005610414547845722
batch 185 loss: 0.0005609924090094864
batch 190 loss: 0.0005609453190118074
batch 195 loss: 0.0005608582869172096
batch 200 loss: 0.0005608714651316405
batch 205 loss: 0.0005609343410469591
batch 210 loss: 0.0005609950283542275
batch 215 loss: 0.0005610478692688048
batch 220 loss: 0.0005608446197584271
batch 225 loss: 0.0005608314415439964
batch 230 loss: 0.0005609002429991961
batch 235 loss: 0.0005608956096693873
batch 240 loss: 0.0005607946543022991
Training Loss: 0.000561803248031841
Validation Loss: 0.0005607409839285538
Epoch 34:
batch 5 loss: 0.0005606886697933078
batch 10 loss: 0.0005606777733191848
batch 15 loss: 0.0005606610560789704
batch 20 loss: 0.0005606222315691411
batch 25 loss: 0.0005607096129097045
batch 30 loss: 0.0005606044898740948
batch 35 loss: 0.0005605972604826093
batch 40 loss: 0.0005606970633380115
batch 45 loss: 0.0005606366088613868
batch 50 loss: 0.0005606263293884695
batch 55 loss: 0.0005605819984339178
batch 60 loss: 0.0005606151418760419
batch 65 loss: 0.0005605692160315812
batch 70 loss: 0.0005605341866612434
batch 75 loss: 0.0005604487261734903
batch 80 loss: 0.0005604801350273192
batch 85 loss: 0.0005603872938081622
batch 90 loss: 0.0005604843725450336
batch 95 loss: 0.0005603476194664836
batch 100 loss: 0.0005603273515589535
batch 105 loss: 0.0005603308440186083
batch 110 loss: 0.0005602991441264749
batch 115 loss: 0.0005603644647635519
batch 120 loss: 0.0005602872930467129
batch 125 loss: 0.0005601771175861358
batch 130 loss: 0.0005602802033536136
batch 135 loss: 0.0005600190488621593
batch 140 loss: 0.000560200191102922
batch 145 loss: 0.0005601676763035357
batch 150 loss: 0.0005602005287073553
batch 155 loss: 0.0005600461270660162
batch 160 loss: 0.0005601361626759171
batch 165 loss: 0.0005601184209808707
batch 170 loss: 0.0005599642521701753
batch 175 loss: 0.0005600235890597105
batch 180 loss: 0.0005600079079158604
batch 185 loss: 0.0005599953001365066
batch 190 loss: 0.0005600114353001117
batch 195 loss: 0.0005598799325525761
batch 200 loss: 0.0005600338219664991
batch 205 loss: 0.0005599181167781353
batch 210 loss: 0.0005599202704615891
batch 215 loss: 0.0005597474286332726
batch 220 loss: 0.0005598830990493298
batch 225 loss: 0.0005598315387032926
batch 230 loss: 0.0005597999668680131
batch 235 loss: 0.0005598483490757644
batch 240 loss: 0.0005599069874733687
Training Loss: 0.0005602645074153163
Validation Loss: 0.0005597234451367209
Epoch 35:
batch 5 loss: 0.0005596248665824533
batch 10 loss: 0.0005597614450380206
batch 15 loss: 0.0005597910028882324
batch 20 loss: 0.000559839338529855
batch 25 loss: 0.0005598324700258672
batch 30 loss: 0.0005597631796263158
batch 35 loss: 0.0005598138435743749
batch 40 loss: 0.0005597047973424196
batch 45 loss: 0.0005598074523732067
batch 50 loss: 0.0005598606425337493
batch 55 loss: 0.0005597781273536384
batch 60 loss: 0.0005597013980150223
batch 65 loss: 0.0005595927592366934
batch 70 loss: 0.000559564575087279
batch 75 loss: 0.0005596129922196269
batch 80 loss: 0.0005594942136667669
batch 85 loss: 0.0005594736663624644
batch 90 loss: 0.0005594198708422482
batch 95 loss: 0.0005594218382611871
batch 100 loss: 0.0005594980902969837
batch 105 loss: 0.0005595666472800076
batch 110 loss: 0.0005594847141765058
batch 115 loss: 0.0005595858441665768
batch 120 loss: 0.0005596884060651064
batch 125 loss: 0.0005595813388936221
batch 130 loss: 0.0005596124217845499
batch 135 loss: 0.0005594730726443231
batch 140 loss: 0.0005595433060079813
batch 145 loss: 0.0005595803144387901
batch 150 loss: 0.0005595078459009528
batch 155 loss: 0.0005595203838311136
batch 160 loss: 0.0005595710244961083
batch 165 loss: 0.0005595766007900238
batch 170 loss: 0.000559405074454844
batch 175 loss: 0.0005594801856204868
batch 180 loss: 0.0005595169495791197
batch 185 loss: 0.0005594035959802568
batch 190 loss: 0.000559386343229562
batch 195 loss: 0.0005593534093350172
batch 200 loss: 0.0005595028167590498
batch 205 loss: 0.000559549406170845
batch 210 loss: 0.0005593892419710755
batch 215 loss: 0.0005593864480033517
batch 220 loss: 0.0005593161680735647
batch 225 loss: 0.0005593982758000493
batch 230 loss: 0.0005595365189947187
batch 235 loss: 0.0005594320129603148
batch 240 loss: 0.0005594457616098225
Training Loss: 0.0005595656395598781
Validation Loss: 0.0005592923417376976
Epoch 36:
batch 5 loss: 0.0005592210334725678
batch 10 loss: 0.0005592845380306243
batch 15 loss: 0.0005591150256805122
batch 20 loss: 0.0005593122565187514
batch 25 loss: 0.0005592815112322568
batch 30 loss: 0.0005592522211372852
batch 35 loss: 0.0005593979731202126
batch 40 loss: 0.0005593231762759387
batch 45 loss: 0.0005593562149442732
batch 50 loss: 0.0005593268782831728
batch 55 loss: 0.0005592959118075669
batch 60 loss: 0.000559257052373141
batch 65 loss: 0.0005591870052739978
batch 70 loss: 0.0005592399160377681
batch 75 loss: 0.0005593104055151343
batch 80 loss: 0.0005593018839135766
batch 85 loss: 0.000559240800794214
batch 90 loss: 0.0005593466572463513
batch 95 loss: 0.0005592956556938588
batch 100 loss: 0.0005593014298938215
batch 105 loss: 0.0005592137924395502
batch 110 loss: 0.0005591826047748327
batch 115 loss: 0.0005592015571892261
batch 120 loss: 0.0005592326400801539
batch 125 loss: 0.0005592837813310325
batch 130 loss: 0.0005591199034824968
batch 135 loss: 0.0005592248169705271
batch 140 loss: 0.0005592249101027847
batch 145 loss: 0.0005591594846919179
batch 150 loss: 0.0005592734552919865
batch 155 loss: 0.0005592619185335934
batch 160 loss: 0.0005592701490968466
batch 165 loss: 0.0005591204972006381
batch 170 loss: 0.0005593098234385252
batch 175 loss: 0.0005591052700765431
batch 180 loss: 0.0005594254471361637
batch 185 loss: 0.0005591275054030121
batch 190 loss: 0.0005592550383880735
batch 195 loss: 0.0005592429079115391
batch 200 loss: 0.0005592889967374504
batch 205 loss: 0.000559272977989167
batch 210 loss: 0.0005592466332018375
batch 215 loss: 0.0005592436878941953
batch 220 loss: 0.0005591421737335623
batch 225 loss: 0.0005592475295998156
batch 230 loss: 0.0005591929191723465
batch 235 loss: 0.0005591790191829205
batch 240 loss: 0.0005592166795395315
Training Loss: 0.0005592482014132353
Validation Loss: 0.0005591285143358012
Epoch 37:
batch 5 loss: 0.0005591229535639286
batch 10 loss: 0.0005589414271526038
batch 15 loss: 0.0005590181797742843
batch 20 loss: 0.0005591632565483451
batch 25 loss: 0.0005591016379185021
batch 30 loss: 0.0005590967950411141
batch 35 loss: 0.0005591106601059437
batch 40 loss: 0.0005590900545939803
batch 45 loss: 0.0005592136643826961
batch 50 loss: 0.0005591697758063674
batch 55 loss: 0.0005590157117694617
batch 60 loss: 0.0005590229178778827
batch 65 loss: 0.0005592124536633492
batch 70 loss: 0.0005590649670921266
batch 75 loss: 0.0005590000888332725
batch 80 loss: 0.0005591411492787302
batch 85 loss: 0.0005590878776274621
batch 90 loss: 0.0005590648157522083
batch 95 loss: 0.0005589668056927621
batch 100 loss: 0.000559003185480833
batch 105 loss: 0.0005591851659119129
batch 110 loss: 0.0005592064117081463
batch 115 loss: 0.000559128588065505
batch 120 loss: 0.0005591600318439304
batch 125 loss: 0.0005589678068645299
batch 130 loss: 0.0005590411834418774
batch 135 loss: 0.0005590538610704243
batch 140 loss: 0.0005590353859588504
batch 145 loss: 0.0005591146531514823
batch 150 loss: 0.0005590166547335684
batch 155 loss: 0.0005589946755208075
batch 160 loss: 0.0005589500535279513
batch 165 loss: 0.0005589728942140936
batch 170 loss: 0.0005590841290540993
batch 175 loss: 0.0005591140245087445
batch 180 loss: 0.0005589902284555137
batch 185 loss: 0.0005589326727204024
batch 190 loss: 0.0005589756881818175
batch 195 loss: 0.0005588655243627727
batch 200 loss: 0.0005588437896221876
batch 205 loss: 0.0005587759427726269
batch 210 loss: 0.000558967050164938
batch 215 loss: 0.0005591707304120064
batch 220 loss: 0.0005592681700363755
batch 225 loss: 0.0005592713830992579
batch 230 loss: 0.0005589669337496162
batch 235 loss: 0.000559071998577565
batch 240 loss: 0.0005592192406766117
Training Loss: 0.0005590615260492389
Validation Loss: 0.0005593035360410189
Epoch 38:
batch 5 loss: 0.0005592055851593614
batch 10 loss: 0.0005591147462837398
batch 15 loss: 0.0005590838729403913
batch 20 loss: 0.0005589946638792753
batch 25 loss: 0.000559010193683207
batch 30 loss: 0.0005589617881923914
batch 35 loss: 0.0005588909611105919
batch 40 loss: 0.0005587718449532985
batch 45 loss: 0.0005587146733887494
batch 50 loss: 0.0005586842657066881
batch 55 loss: 0.000558710121549666
batch 60 loss: 0.0005586090614087879
batch 65 loss: 0.0005586055107414722
batch 70 loss: 0.0005587307154200971
batch 75 loss: 0.0005585077917203308
batch 80 loss: 0.0005586135899648071
batch 85 loss: 0.0005586376995779574
batch 90 loss: 0.0005586558603681624
batch 95 loss: 0.0005587210180237889
batch 100 loss: 0.0005586315295659005
batch 105 loss: 0.0005585546488873661
batch 110 loss: 0.0005586148472502828
batch 115 loss: 0.0005586922983638942
batch 120 loss: 0.0005586984101682901
batch 125 loss: 0.0005585878156125545
batch 130 loss: 0.0005586080718785524
batch 135 loss: 0.0005586185958236456
batch 140 loss: 0.0005586853018030524
batch 145 loss: 0.0005586430896073579
batch 150 loss: 0.0005586255574598908
batch 155 loss: 0.0005585555336438119
batch 160 loss: 0.000558557384647429
batch 165 loss: 0.0005585985141806305
batch 170 loss: 0.0005586592480540276
batch 175 loss: 0.0005584343569353222
batch 180 loss: 0.0005585392587818206
batch 185 loss: 0.0005585470702499151
batch 190 loss: 0.0005585299688391388
batch 195 loss: 0.0005584857310168446
batch 200 loss: 0.0005586528452113271
batch 205 loss: 0.0005657490459270775
batch 210 loss: 0.0005656570661813021
batch 215 loss: 0.0005687033990398049
batch 220 loss: 0.0005673455772921443
batch 225 loss: 0.0005674229934811593
batch 230 loss: 0.0005660147638991475
batch 235 loss: 0.0005645964061841369
batch 240 loss: 0.0005640138406306505
Training Loss: 0.0005599426486393593
Validation Loss: 0.00529408196453005
Epoch 39:
batch 5 loss: 0.0005628917831927537
batch 10 loss: 0.0005619991454295814
batch 15 loss: 0.0005614462075755
batch 20 loss: 0.0005610695807263255
batch 25 loss: 0.0005609006737358868
batch 30 loss: 0.0005606961436569691
batch 35 loss: 0.0005606221151538193
batch 40 loss: 0.0005605533602647484
batch 45 loss: 0.0005605346756055951
batch 50 loss: 0.0005604465259239078
batch 55 loss: 0.0005603611469268798
batch 60 loss: 0.0005602990859188139
batch 65 loss: 0.0005602761404588819
batch 70 loss: 0.0005602727294899523
batch 75 loss: 0.0005602366174571217
batch 80 loss: 0.0005602797958999872
batch 85 loss: 0.0005602372460998595
batch 90 loss: 0.0005600357777439058
batch 95 loss: 0.0005602249410003423
batch 100 loss: 0.0005600396660156548
batch 105 loss: 0.000559987232554704
batch 110 loss: 0.0005600713426247239
batch 115 loss: 0.0005600444274023175
batch 120 loss: 0.0005599665921181441
batch 125 loss: 0.000560080714058131
batch 130 loss: 0.0005598589312285184
batch 135 loss: 0.0005600071744993329
batch 140 loss: 0.0005598433664999903
batch 145 loss: 0.0005597761948592961
batch 150 loss: 0.0005597386276349426
batch 155 loss: 0.0005597022245638072
batch 160 loss: 0.0005597317242063582
batch 165 loss: 0.0005597056355327368
batch 170 loss: 0.0005596529110334814
batch 175 loss: 0.0005597569863311947
batch 180 loss: 0.0005597037845291198
batch 185 loss: 0.0005596369854174554
batch 190 loss: 0.0005596028408035636
batch 195 loss: 0.0005596434231847525
batch 200 loss: 0.0005595931899733842
batch 205 loss: 0.0005596522823907435
batch 210 loss: 0.0005595419555902481
batch 215 loss: 0.0005594680900685489
batch 220 loss: 0.0005595521884970367
batch 225 loss: 0.0005594599177129566
batch 230 loss: 0.0005594129324890673
batch 235 loss: 0.0005594417336396873
batch 240 loss: 0.0005594968562945724
Training Loss: 0.0005601157005003188
Validation Loss: 0.0005594307944799463
Epoch 40:
batch 5 loss: 0.0005593842943198979
batch 10 loss: 0.0005592480767518282
batch 15 loss: 0.00055930515518412
batch 20 loss: 0.0005592774250544608
batch 25 loss: 0.000559311592951417
batch 30 loss: 0.0005593509296886623
batch 35 loss: 0.0005593295441940427
batch 40 loss: 0.0005592518486082554
batch 45 loss: 0.0005591797060333192
batch 50 loss: 0.0005591460736468435
batch 55 loss: 0.0005591412307694554
batch 60 loss: 0.0005590251763351262
batch 65 loss: 0.0005591272609308362
batch 70 loss: 0.0005591690307483077
batch 75 loss: 0.0005590042448602617
batch 80 loss: 0.0005590251414105297
batch 85 loss: 0.0005590036162175238
batch 90 loss: 0.000558879051823169
batch 95 loss: 0.0005589367006905377
batch 100 loss: 0.000559179822448641
batch 105 loss: 0.0005594726884737611
batch 110 loss: 0.0005593406036496163
batch 115 loss: 0.0005593488458544016
batch 120 loss: 0.0005590261076577008
batch 125 loss: 0.0005591310327872634
batch 130 loss: 0.0005591180059127509
batch 135 loss: 0.0005590569111518562
batch 140 loss: 0.0005589770851656794
batch 145 loss: 0.0005588279804214835
batch 150 loss: 0.000558722740970552
batch 155 loss: 0.0005585669539868831
batch 160 loss: 0.0005584898870438337
batch 165 loss: 0.0005583940306678415
batch 170 loss: 0.0005584922735579311
batch 175 loss: 0.0005584477097727358
batch 180 loss: 0.0005583389778621495
batch 185 loss: 0.0005583712947554887
batch 190 loss: 0.0005583322956226767
batch 195 loss: 0.0005583001067861915
batch 200 loss: 0.0005584554746747017
batch 205 loss: 0.0005584808182902634
batch 210 loss: 0.00055802040733397
batch 215 loss: 0.0005576740833930672
batch 220 loss: 0.0005576088675297797
batch 225 loss: 0.0005576382973231375
batch 230 loss: 0.0005577453528530895
batch 235 loss: 0.0005577018018811941
batch 240 loss: 0.0005577363073825837
Training Loss: 0.0005587727680297879
Validation Loss: 0.0005576934257987886
Epoch 41:
batch 5 loss: 0.0005576766678132116
batch 10 loss: 0.000557667959947139
batch 15 loss: 0.0005577311967499554
batch 20 loss: 0.0005577284726314246
batch 25 loss: 0.0005576174589805305
batch 30 loss: 0.0005575808929279447
batch 35 loss: 0.0005576397408731282
batch 40 loss: 0.0005575848976150155
batch 45 loss: 0.0005576825118623674
batch 50 loss: 0.0005576984374783933
batch 55 loss: 0.0005577032221481204
batch 60 loss: 0.000557757040951401
batch 65 loss: 0.0005577088566496968
batch 70 loss: 0.00055763297714293
batch 75 loss: 0.0005577234318479895
batch 80 loss: 0.0005576630937866867
batch 85 loss: 0.0005576975992880762
batch 90 loss: 0.0005577055737376214
batch 95 loss: 0.0005577499396167696
batch 100 loss: 0.0005577236297540367
batch 105 loss: 0.0005576956202276051
batch 110 loss: 0.0005577434436418116
batch 115 loss: 0.0005576162482611835
batch 120 loss: 0.0005576939671300352
batch 125 loss: 0.0005576360854320228
batch 130 loss: 0.0005577258649282158
batch 135 loss: 0.0005576094961725175
batch 140 loss: 0.0005576629308052361
batch 145 loss: 0.000557596911676228
batch 150 loss: 0.0005576928029768169
batch 155 loss: 0.0005576721741817892
batch 160 loss: 0.0005577177391387523
batch 165 loss: 0.0005578750860877335
batch 170 loss: 0.0005575908231548965
batch 175 loss: 0.0005575965391471982
batch 180 loss: 0.000557649286929518
batch 185 loss: 0.0005577967502176761
batch 190 loss: 0.0005576657596975565
batch 195 loss: 0.0005576956318691373
batch 200 loss: 0.0005576577852480114
batch 205 loss: 0.0005577077041380108
batch 210 loss: 0.0005576627096161247
batch 215 loss: 0.0005576666560955345
batch 220 loss: 0.0005576836643740535
batch 225 loss: 0.0005576572031714023
batch 230 loss: 0.0005577177740633488
batch 235 loss: 0.0005577119765803218
batch 240 loss: 0.000557735818438232
Training Loss: 0.000557683501150071
Validation Loss: 0.00055769531269713
Epoch 42:
batch 5 loss: 0.0005575607530772686
batch 10 loss: 0.0005576784256845713
batch 15 loss: 0.0005576492054387927
batch 20 loss: 0.0005576553987339139
batch 25 loss: 0.000557718111667782
batch 30 loss: 0.0005577222211286426
batch 35 loss: 0.0005576323601417243
batch 40 loss: 0.000557657063473016
batch 45 loss: 0.0005576344323344528
batch 50 loss: 0.000557655212469399
batch 55 loss: 0.0005578327691182494
batch 60 loss: 0.0005577259464189411
batch 65 loss: 0.0005578097654506565
batch 70 loss: 0.000557651452254504
batch 75 loss: 0.0005577508360147476
batch 80 loss: 0.0005576516385190188
batch 85 loss: 0.0005577501608058811
batch 90 loss: 0.0005576818832196296
batch 95 loss: 0.0005576785071752966
batch 100 loss: 0.0005576965399086475
batch 105 loss: 0.0005577228497713804
batch 110 loss: 0.0005577243282459676
batch 115 loss: 0.0005576367257162929
batch 120 loss: 0.0005577116971835494
batch 125 loss: 0.0005577479489147664
batch 130 loss: 0.0005577141419053078
batch 135 loss: 0.0005576624185778201
batch 140 loss: 0.0005576219642534852
batch 145 loss: 0.000557633931748569
batch 150 loss: 0.0005576667143031954
batch 155 loss: 0.0005577810807153583
batch 160 loss: 0.0005576769704930485
batch 165 loss: 0.0005576843861490488
batch 170 loss: 0.0005576561205089092
batch 175 loss: 0.0005578570533543825
batch 180 loss: 0.0005575312883593142
batch 185 loss: 0.0005576702882535755
batch 190 loss: 0.0005576491355895996
batch 195 loss: 0.0005575226969085634
batch 200 loss: 0.000557666621170938
batch 205 loss: 0.0005578175419941545
batch 210 loss: 0.0005576779134571552
batch 215 loss: 0.0005575664923526347
batch 220 loss: 0.0005576492403633893
batch 225 loss: 0.0005577730480581522
batch 230 loss: 0.0005576186580583453
batch 235 loss: 0.0005576964351348579
batch 240 loss: 0.0005576790659688413
Training Loss: 0.0005576835300113695
Validation Loss: 0.0005576934713947897
Epoch 43:
batch 5 loss: 0.0005575875751674175
batch 10 loss: 0.0005577332689426839
batch 15 loss: 0.000557643675711006
batch 20 loss: 0.0005577141069807112
batch 25 loss: 0.0005576935480348765
batch 30 loss: 0.0005576246185228229
batch 35 loss: 0.000557630998082459
batch 40 loss: 0.0005577359581366182
batch 45 loss: 0.0005577633390203118
batch 50 loss: 0.0005576574010774493
batch 55 loss: 0.0005577148869633675
batch 60 loss: 0.0005575758987106383
batch 65 loss: 0.0005577725823968649
batch 70 loss: 0.0005576161667704583
batch 75 loss: 0.0005575756309553981
batch 80 loss: 0.0005576759693212807
batch 85 loss: 0.0005577218835242093
batch 90 loss: 0.0005577884963713587
batch 95 loss: 0.0005577785661444068
batch 100 loss: 0.000557668274268508
batch 105 loss: 0.0005577192758210003
batch 110 loss: 0.0005577076110057533
batch 115 loss: 0.0005577684845775366
batch 120 loss: 0.0005576418014243245
batch 125 loss: 0.0005576721858233213
batch 130 loss: 0.0005576775991357863
batch 135 loss: 0.0005576303461566568
batch 140 loss: 0.0005577156320214271
batch 145 loss: 0.0005577614065259695
batch 150 loss: 0.0005575463175773621
batch 155 loss: 0.0005577725474722684
batch 160 loss: 0.0005576751893386245
batch 165 loss: 0.0005577019532211125
batch 170 loss: 0.0005575844901613891
batch 175 loss: 0.0005576891475357115
batch 180 loss: 0.0005576600087806582
batch 185 loss: 0.00055775634245947
batch 190 loss: 0.0005577612086199224
batch 195 loss: 0.0005576110677793622
batch 200 loss: 0.0005576749565079809
batch 205 loss: 0.0005577441421337426
batch 210 loss: 0.0005576430121436715
batch 215 loss: 0.0005576463649049401
batch 220 loss: 0.0005577096133492887
batch 225 loss: 0.0005577377858571708
batch 230 loss: 0.0005576566676609218
batch 235 loss: 0.0005576001945883036
batch 240 loss: 0.0005576713941991329
Training Loss: 0.0005576835331642845
Validation Loss: 0.0005576938109394784
Epoch 44:
batch 5 loss: 0.0005575411021709442
batch 10 loss: 0.0005576004274189472
batch 15 loss: 0.0005575769348070026
batch 20 loss: 0.0005576303694397212
batch 25 loss: 0.0005577495670877397
batch 30 loss: 0.0005576630006544292
batch 35 loss: 0.000557759846560657
batch 40 loss: 0.0005577463423833251
batch 45 loss: 0.0005577542586252093
batch 50 loss: 0.0005576311610639096
batch 55 loss: 0.0005576477386057376
batch 60 loss: 0.0005577422445639968
batch 65 loss: 0.0005576441180892289
batch 70 loss: 0.0005576814408414065
batch 75 loss: 0.0005577295087277889
batch 80 loss: 0.0005577855044975877
batch 85 loss: 0.000557768065482378
batch 90 loss: 0.0005575825925916433
batch 95 loss: 0.0005576044903136789
batch 100 loss: 0.0005577952368184924
batch 105 loss: 0.0005577320116572082
batch 110 loss: 0.0005577944102697074
batch 115 loss: 0.0005576720810495317
batch 120 loss: 0.000557651137933135
batch 125 loss: 0.0005577196716330945
batch 130 loss: 0.0005576591123826802
batch 135 loss: 0.0005576279945671558
batch 140 loss: 0.0005577170406468213
batch 145 loss: 0.0005576691124588251
batch 150 loss: 0.0005576820229180157
batch 155 loss: 0.0005577489384450019
batch 160 loss: 0.0005577572388574481
batch 165 loss: 0.0005575582734309136
batch 170 loss: 0.0005577182397246361
batch 175 loss: 0.0005576131283305585
batch 180 loss: 0.000557687843684107
batch 185 loss: 0.0005577111267484724
batch 190 loss: 0.0005576222552917898
batch 195 loss: 0.0005577023723162711
batch 200 loss: 0.0005576299969106913
batch 205 loss: 0.0005577409407123924
batch 210 loss: 0.0005576613475568593
batch 215 loss: 0.0005576983792707324
batch 220 loss: 0.0005577745730988681
batch 225 loss: 0.0005576840951107443
batch 230 loss: 0.0005576331168413162
batch 235 loss: 0.0005577138741500676
batch 240 loss: 0.0005575932562351226
Training Loss: 0.0005576834904786665
Validation Loss: 0.0005576934228884057
Epoch 45:
batch 5 loss: 0.0005577083909884095
batch 10 loss: 0.000557585433125496
batch 15 loss: 0.0005576250259764493
batch 20 loss: 0.00055764737771824
batch 25 loss: 0.0005576309631578624
batch 30 loss: 0.0005576527444645762
batch 35 loss: 0.0005578199867159128
batch 40 loss: 0.0005576494382694364
batch 45 loss: 0.0005576955387368798
batch 50 loss: 0.0005576835246756673
batch 55 loss: 0.000557653745636344
batch 60 loss: 0.0005576884490437805
batch 65 loss: 0.0005577368196099996
batch 70 loss: 0.0005576558876782655
batch 75 loss: 0.0005576143390499056
batch 80 loss: 0.0005576722207479179
batch 85 loss: 0.0005576972151175141
batch 90 loss: 0.0005577309522777796
batch 95 loss: 0.0005575904506258667
batch 100 loss: 0.0005576470168307424
batch 105 loss: 0.0005576675524935126
batch 110 loss: 0.0005576910800300539
batch 115 loss: 0.0005575805786065757
batch 120 loss: 0.0005577526870183646
batch 125 loss: 0.000557693000882864
batch 130 loss: 0.0005578241078183054
batch 135 loss: 0.0005576669122092426
batch 140 loss: 0.0005576466792263091
batch 145 loss: 0.000557813176419586
batch 150 loss: 0.0005576710100285709
batch 155 loss: 0.0005576776107773185
batch 160 loss: 0.0010097206337377428
batch 165 loss: 0.0006511597312055528
batch 170 loss: 0.0005631030187942087
batch 175 loss: 0.0005579732591286301
batch 180 loss: 0.00055774754146114
batch 185 loss: 0.0005577763193286955
batch 190 loss: 0.000557765387929976
batch 195 loss: 0.0005577188450843096
batch 200 loss: 0.0005576749215833842
batch 205 loss: 0.0005577301955781877
batch 210 loss: 0.0005577552830800415
batch 215 loss: 0.0005576508236117661
batch 220 loss: 0.0005577474483288824
batch 225 loss: 0.0005576059222221375
batch 230 loss: 0.0005576545372605324
batch 235 loss: 0.0005576614290475846
batch 240 loss: 0.0005577647825703025
Training Loss: 0.0005691724999148088
Validation Loss: 0.0005576934102767458
Epoch 46:
batch 5 loss: 0.0005576659925282002
batch 10 loss: 0.0005576196359470487
batch 15 loss: 0.0005576704628765583
batch 20 loss: 0.000557708868291229
batch 25 loss: 0.0005577764590270817
batch 30 loss: 0.0005576733383350074
batch 35 loss: 0.0005577753647230566
batch 40 loss: 0.0005575642921030521
batch 45 loss: 0.0005576664232648909
batch 50 loss: 0.0005576404975727201
batch 55 loss: 0.0005576788447797298
batch 60 loss: 0.0005576704046688974
batch 65 loss: 0.0005576370051130653
batch 70 loss: 0.0005577398929744959
batch 75 loss: 0.0005577156087383627
batch 80 loss: 0.000557619531173259
batch 85 loss: 0.0005576916504651308
batch 90 loss: 0.0005578184500336647
batch 95 loss: 0.0005577507778070867
batch 100 loss: 0.0005577194271609188
batch 105 loss: 0.0005576326977461577
batch 110 loss: 0.0005575631395913661
batch 115 loss: 0.0005576618481427431
batch 120 loss: 0.0005577086936682463
batch 125 loss: 0.0005576809751801192
batch 130 loss: 0.0005575698218308389
batch 135 loss: 0.000557669613044709
batch 140 loss: 0.0005577763309702277
batch 145 loss: 0.0005577533156611025
batch 150 loss: 0.0005576361087150872
batch 155 loss: 0.0005577165982685983
batch 160 loss: 0.0005575863178819418
batch 165 loss: 0.0005577330477535725
batch 170 loss: 0.0005576324532739818
batch 175 loss: 0.0005577526870183646
batch 180 loss: 0.0005577399162575603
batch 185 loss: 0.0005576942232437432
batch 190 loss: 0.0005576915689744055
batch 195 loss: 0.0005576862837187946
batch 200 loss: 0.0005576896714046597
batch 205 loss: 0.0005577411968261004
batch 210 loss: 0.0005576362600550056
batch 215 loss: 0.0005577309057116508
batch 220 loss: 0.0005576226627454162
batch 225 loss: 0.0005576171563006938
batch 230 loss: 0.0005576504860073328
batch 235 loss: 0.0005576801137067378
batch 240 loss: 0.0005577460746280849
Training Loss: 0.0005576833978314728
Validation Loss: 0.0005576935664673026
Epoch 47:
batch 5 loss: 0.0005576699390076101
batch 10 loss: 0.0005575077375397086
batch 15 loss: 0.0005576679715886713
batch 20 loss: 0.0005576511728577315
batch 25 loss: 0.0005577137577347458
batch 30 loss: 0.0005575929535552859
batch 35 loss: 0.0005576665862463415
batch 40 loss: 0.0005577281815931201
batch 45 loss: 0.0005576318828389049
batch 50 loss: 0.0005577614880166948
batch 55 loss: 0.0005576911265961826
batch 60 loss: 0.0005576762952841819
batch 65 loss: 0.0005576214287430048
batch 70 loss: 0.0005576129420660436
batch 75 loss: 0.0005575933260843158
batch 80 loss: 0.0005577038391493261
batch 85 loss: 0.000557674653828144
batch 90 loss: 0.000557799288071692
batch 95 loss: 0.0005576085648499429
batch 100 loss: 0.0005576550262048841
batch 105 loss: 0.0005575497052632272
batch 110 loss: 0.0005577745847404003
batch 115 loss: 0.00055771708721295
batch 120 loss: 0.0005577740375883877
batch 125 loss: 0.0005576916970312596
batch 130 loss: 0.0005577717442065477
batch 135 loss: 0.0005576866446062922
batch 140 loss: 0.0005576522438786924
batch 145 loss: 0.0005576458876021207
batch 150 loss: 0.0005576104391366244
batch 155 loss: 0.0005576851428486407
batch 160 loss: 0.0005577153991907835
batch 165 loss: 0.0005578306154347956
batch 170 loss: 0.000557813246268779
batch 175 loss: 0.0005576609051786363
batch 180 loss: 0.0005576247232966125
batch 185 loss: 0.0005576956784352661
batch 190 loss: 0.0005576788680627942
batch 195 loss: 0.000557619147002697
batch 200 loss: 0.0005577037343755364
batch 205 loss: 0.0005577683099545538
batch 210 loss: 0.0005578481242991984
batch 215 loss: 0.0005576039664447307
batch 220 loss: 0.0005576909054070712
batch 225 loss: 0.0005575655493885278
batch 230 loss: 0.0005577315343543888
batch 235 loss: 0.0005576735828071832
batch 240 loss: 0.0005577913369052112
Training Loss: 0.0005576833958912175
Validation Loss: 0.0005576934151273841
Epoch 48:
batch 5 loss: 0.0005575952469371259
batch 10 loss: 0.000557681336067617
batch 15 loss: 0.0005576632334850729
batch 20 loss: 0.0005576362716965377
batch 25 loss: 0.0005577840958721936
batch 30 loss: 0.0005577705800533294
batch 35 loss: 0.000557607808150351
batch 40 loss: 0.0005577388335950672
batch 45 loss: 0.0005576186929829418
batch 50 loss: 0.0005576553754508496
batch 55 loss: 0.0005576561554335058
batch 60 loss: 0.0005576835712417961
batch 65 loss: 0.0005576935713179409
batch 70 loss: 0.0005576602648943663
batch 75 loss: 0.00055768828606233
batch 80 loss: 0.0005576914176344871
batch 85 loss: 0.0005577880539931357
batch 90 loss: 0.0005577224539592863
batch 95 loss: 0.0005577773903496563
batch 100 loss: 0.0005576888215728104
batch 105 loss: 0.0005576719646342099
batch 110 loss: 0.0005575676797889173
batch 115 loss: 0.0005576102994382381
batch 120 loss: 0.0005576419876888395
batch 125 loss: 0.0005577300791628659
batch 130 loss: 0.0005576706607826054
batch 135 loss: 0.0005576521973125637
batch 140 loss: 0.0005576672847382724
batch 145 loss: 0.0005577306728810072
batch 150 loss: 0.0005576722323894501
batch 155 loss: 0.0005576651426963508
batch 160 loss: 0.0005577130359597504
batch 165 loss: 0.0005577233270742
batch 170 loss: 0.0005576163763180375
batch 175 loss: 0.0005578026408329606
batch 180 loss: 0.0005576282390393316
batch 185 loss: 0.0005576954572461545
batch 190 loss: 0.0005577620235271752
batch 195 loss: 0.0005577022209763526
batch 200 loss: 0.0005576312658376991
batch 205 loss: 0.0005576871684752404
batch 210 loss: 0.0005576985771767795
batch 215 loss: 0.0005577290081419051
batch 220 loss: 0.0005577623494900763
batch 225 loss: 0.0005575662944465876
batch 230 loss: 0.0005576703930273652
batch 235 loss: 0.0005576449329964817
batch 240 loss: 0.0005576879368163646
Training Loss: 0.0005576833939509621
Validation Loss: 0.0005576934471415977
Epoch 49:
batch 5 loss: 0.0005577217554673553
batch 10 loss: 0.0005576982046477496
batch 15 loss: 0.0005577201256528497
batch 20 loss: 0.0005575723946094513
batch 25 loss: 0.0005576907773502171
batch 30 loss: 0.0005577039206400514
batch 35 loss: 0.0005576927680522204
batch 40 loss: 0.000557706446852535
batch 45 loss: 0.0005577422911301255
batch 50 loss: 0.0005576918134465814
batch 55 loss: 0.0005576699040830135
batch 60 loss: 0.0005575639195740222
batch 65 loss: 0.0005576667492277921
batch 70 loss: 0.0005578373675234616
batch 75 loss: 0.0005576355382800102
batch 80 loss: 0.000557537202257663
batch 85 loss: 0.0005577387986704707
batch 90 loss: 0.0005577290896326304
batch 95 loss: 0.0005575901828706265
batch 100 loss: 0.0005577705800533294
batch 105 loss: 0.0005575626972131431
batch 110 loss: 0.0005576324765570462
batch 115 loss: 0.0005578095326200128
batch 120 loss: 0.0005575836985372007
batch 125 loss: 0.0005576403811573983
batch 130 loss: 0.0005578082520514727
batch 135 loss: 0.0005577264470048249
batch 140 loss: 0.0005576424417085945
batch 145 loss: 0.0005577128380537033
batch 150 loss: 0.0005575778312049806
batch 155 loss: 0.0005576118128374219
batch 160 loss: 0.000557689182460308
batch 165 loss: 0.0005576785653829575
batch 170 loss: 0.0005577731877565384
batch 175 loss: 0.0005576983792707324
batch 180 loss: 0.000557702244259417
batch 185 loss: 0.0005577206611633301
batch 190 loss: 0.0005576324881985783
batch 195 loss: 0.0005576512776315212
batch 200 loss: 0.0005577506613917649
batch 205 loss: 0.0005576863652095199
batch 210 loss: 0.0005576973664574326
batch 215 loss: 0.000557704025413841
batch 220 loss: 0.0005576399504207075
batch 225 loss: 0.0005576472845859826
batch 230 loss: 0.0005577004747465252
batch 235 loss: 0.0005577652831561863
batch 240 loss: 0.000557677575852722
Training Loss: 0.0005576834002567921
Validation Loss: 0.0005576934170676395
Epoch 50:
batch 5 loss: 0.0005577960284426809
batch 10 loss: 0.0005577550502493978
batch 15 loss: 0.0005576707539148628
batch 20 loss: 0.0005577673786319792
batch 25 loss: 0.0005577674019150436
batch 30 loss: 0.00055774194188416
batch 35 loss: 0.000557627808302641
batch 40 loss: 0.0005575879942625761
batch 45 loss: 0.0005577116273343564
batch 50 loss: 0.0005577346077188849
batch 55 loss: 0.0005577441770583391
batch 60 loss: 0.0005576147348619997
batch 65 loss: 0.0005577642703428864
batch 70 loss: 0.0005577419069595635
batch 75 loss: 0.0005577692412771284
batch 80 loss: 0.0005576419644057751
batch 85 loss: 0.0005576544557698071
batch 90 loss: 0.0005576344556175172
batch 95 loss: 0.0005576360621489584
batch 100 loss: 0.0005576162948273122
batch 105 loss: 0.0005575984483584762
batch 110 loss: 0.000557609717361629
batch 115 loss: 0.0005576632684096694
batch 120 loss: 0.000557661207858473
batch 125 loss: 0.0005577525938861072
batch 130 loss: 0.0005577510222792625
batch 135 loss: 0.000557699054479599
batch 140 loss: 0.0005576269701123238
batch 145 loss: 0.0005576960742473602
batch 150 loss: 0.0005574940703809261
batch 155 loss: 0.0005576399504207075
batch 160 loss: 0.0005576548050157726
batch 165 loss: 0.0005577160278335214
batch 170 loss: 0.0005578181589953601
batch 175 loss: 0.0005576750729233027
batch 180 loss: 0.000557699566707015
batch 185 loss: 0.0005576196010224522
batch 190 loss: 0.0005577618605457247
batch 195 loss: 0.0005578078562393785
batch 200 loss: 0.0005575383896939456
batch 205 loss: 0.0005575938033871352
batch 210 loss: 0.0005576969939284027
batch 215 loss: 0.0005577120231464505
batch 220 loss: 0.0005576275521889329
batch 225 loss: 0.0005577982286922633
batch 230 loss: 0.0005575817660428584
batch 235 loss: 0.0005576837109401822
batch 240 loss: 0.0005576472263783217
Training Loss: 0.0005576833995291963
Validation Loss: 0.0005576934083364904
Epoch 51:
batch 5 loss: 0.0005577999283559621
batch 10 loss: 0.0005577563657425344
batch 15 loss: 0.0005576834199018776
batch 20 loss: 0.0005576620344072581
batch 25 loss: 0.0005576205207034945
batch 30 loss: 0.0005576733034104109
batch 35 loss: 0.0005577520234510303
batch 40 loss: 0.0005575476796366274
batch 45 loss: 0.0005576903698965907
batch 50 loss: 0.0005576754920184612
batch 55 loss: 0.0005577586474828422
batch 60 loss: 0.0005575606366619468
batch 65 loss: 0.0005576798575930297
batch 70 loss: 0.0005576354335062206
batch 75 loss: 0.0005575877032242716
batch 80 loss: 0.0005575731745921075
batch 85 loss: 0.0005576965282671154
batch 90 loss: 0.000557670183479786
batch 95 loss: 0.0005576386814936995
batch 100 loss: 0.0005575897521339357
batch 105 loss: 0.0005577801610343158
batch 110 loss: 0.0005577622447162867
batch 115 loss: 0.00055772690102458
batch 120 loss: 0.0005577380070462823
batch 125 loss: 0.0005576836760155856
batch 130 loss: 0.000557654700241983
batch 135 loss: 0.0005576645256951451
batch 140 loss: 0.0005577038857154549
batch 145 loss: 0.0005577165866270661
batch 150 loss: 0.0005577149684540927
batch 155 loss: 0.000557603279594332
batch 160 loss: 0.0005576059804297984
batch 165 loss: 0.0005576287279836833
batch 170 loss: 0.0005576904397457838
batch 175 loss: 0.0005577352712862194
batch 180 loss: 0.0005577499628998339
batch 185 loss: 0.0005576323135755956
batch 190 loss: 0.0005577555275522172
batch 195 loss: 0.0005577519070357085
batch 200 loss: 0.0005577202537097037
batch 205 loss: 0.000557708356063813
batch 210 loss: 0.0005577069125138224
batch 215 loss: 0.0005576950497925282
batch 220 loss: 0.0005576471332460642
batch 225 loss: 0.0005576737690716982
batch 230 loss: 0.0005578008946031332
batch 235 loss: 0.0005576605442911386
batch 240 loss: 0.0005576406139880419
Training Loss: 0.0005576834235398564
Validation Loss: 0.000557693424828661
Epoch 52:
batch 5 loss: 0.0005576886702328921
batch 10 loss: 0.0005577135016210377
batch 15 loss: 0.0005577807198278606
batch 20 loss: 0.0005576600204221904
batch 25 loss: 0.0005576619645580649
batch 30 loss: 0.0005576858413405717
batch 35 loss: 0.0005577185191214084
batch 40 loss: 0.0005576542112976313
batch 45 loss: 0.0005576595896854997
batch 50 loss: 0.0005578125827014446
batch 55 loss: 0.0005576572613790632
batch 60 loss: 0.0005576243740506471
batch 65 loss: 0.000557726842816919
batch 70 loss: 0.0005576613708399236
batch 75 loss: 0.0005577357951551676
batch 80 loss: 0.0005577564937993884
batch 85 loss: 0.0005576443392783404
batch 90 loss: 0.0005577544099651277
batch 95 loss: 0.0005576825351454318
batch 100 loss: 0.000557681149803102
batch 105 loss: 0.0005575991235673428
batch 110 loss: 0.0005576470517553389
batch 115 loss: 0.0005577760981395841
batch 120 loss: 0.000557710335124284
batch 125 loss: 0.0005576355499215424
batch 130 loss: 0.0005576829542405903
batch 135 loss: 0.0005576405092142522
batch 140 loss: 0.0005576094379648566
batch 145 loss: 0.0005576606723479927
batch 150 loss: 0.0005578228039667011
batch 155 loss: 0.0005576477502472699
batch 160 loss: 0.0005577256553806365
batch 165 loss: 0.0005576940486207605
batch 170 loss: 0.0005576582858338952
batch 175 loss: 0.0005576338153332472
batch 180 loss: 0.00055771772749722
batch 185 loss: 0.000557736272457987
batch 190 loss: 0.0005576028721407056
batch 195 loss: 0.0005577245145104825
batch 200 loss: 0.0005576809286139906
batch 205 loss: 0.00055778973037377
batch 210 loss: 0.0005576177150942385
batch 215 loss: 0.0005576481693424284
batch 220 loss: 0.000557682674843818
batch 225 loss: 0.0005575355375185609
batch 230 loss: 0.0005577055388130247
batch 235 loss: 0.0005577302537858487
batch 240 loss: 0.0005575277376919985
Training Loss: 0.000557683415778835
Validation Loss: 0.0005576934830363219
Epoch 53:
batch 5 loss: 0.0005576785886660218
batch 10 loss: 0.0005577231640927494
batch 15 loss: 0.0005576829193159938
batch 20 loss: 0.0005577544448897243
batch 25 loss: 0.0005576892523095012
batch 30 loss: 0.0005577019765041769
batch 35 loss: 0.0005576653871685267
batch 40 loss: 0.0005576956085860729
batch 45 loss: 0.0005576743045821786
batch 50 loss: 0.0005577224190346896
batch 55 loss: 0.0005577033967711032
batch 60 loss: 0.0005577487056143582
batch 65 loss: 0.000557605770882219
batch 70 loss: 0.0005577242234721779
batch 75 loss: 0.0005577346193604172
batch 80 loss: 0.0005576321738772095
batch 85 loss: 0.000557787879370153
batch 90 loss: 0.0005577309057116508
batch 95 loss: 0.000557649414986372
batch 100 loss: 0.0005576993222348392
batch 105 loss: 0.0005576058640144766
batch 110 loss: 0.0005576448864303529
batch 115 loss: 0.0005576683557592333
batch 120 loss: 0.0005577045609243214
batch 125 loss: 0.000557669042609632
batch 130 loss: 0.0005577355739660561
batch 135 loss: 0.0005576904630288481
batch 140 loss: 0.0005577566102147102
batch 145 loss: 0.0005576666677370668
batch 150 loss: 0.0005576346535235644
batch 155 loss: 0.0005577081581577658
batch 160 loss: 0.0005575968883931637
batch 165 loss: 0.000557808461599052
batch 170 loss: 0.0005576352938078344
batch 175 loss: 0.0005576839088462293
batch 180 loss: 0.0005576339550316334
batch 185 loss: 0.000557684781961143
batch 190 loss: 0.000557667890097946
batch 195 loss: 0.0005576788913458586
batch 200 loss: 0.000557595060672611
batch 205 loss: 0.0005576873198151588
batch 210 loss: 0.0005576593219302594
batch 215 loss: 0.0005576507421210409
batch 220 loss: 0.0005577374715358019
batch 225 loss: 0.00055761105613783
batch 230 loss: 0.0005576988216489554
batch 235 loss: 0.0005576885305345058
batch 240 loss: 0.000557596271391958
Training Loss: 0.0005576834162638988
Validation Loss: 0.000557693443261087
Epoch 54:
batch 5 loss: 0.0005575868184678256
batch 10 loss: 0.0005577550386078656
batch 15 loss: 0.0005576653755269944
batch 20 loss: 0.0005577677860856056
batch 25 loss: 0.0005577013944275677
batch 30 loss: 0.0005576614406891167
batch 35 loss: 0.0005576554802246391
batch 40 loss: 0.0005578029435127973
batch 45 loss: 0.0005576465395279228
batch 50 loss: 0.0005576645373366774
batch 55 loss: 0.000557724863756448
batch 60 loss: 0.0005576431402005255
batch 65 loss: 0.0005576255731284619
batch 70 loss: 0.000557632592972368
batch 75 loss: 0.0005577360279858112
batch 80 loss: 0.0005576427793130279
batch 85 loss: 0.0005575941177085042
batch 90 loss: 0.0005576475174166262
batch 95 loss: 0.0005576902651228011
batch 100 loss: 0.0005576871335506439
batch 105 loss: 0.0005577241536229849
batch 110 loss: 0.0005576860159635544
batch 115 loss: 0.0005576643627136946
batch 120 loss: 0.0005577450850978493
batch 125 loss: 0.0005576640483923257
batch 130 loss: 0.0005577575066126883
batch 135 loss: 0.0005576643394306302
batch 140 loss: 0.0005576203460805118
batch 145 loss: 0.000557800498791039
batch 150 loss: 0.0005576669587753713
batch 155 loss: 0.0005575414979830384
batch 160 loss: 0.0005577396834269166
batch 165 loss: 0.0005576749332249165
batch 170 loss: 0.0005576703115366399
batch 175 loss: 0.000557739520445466
batch 180 loss: 0.0005577244679443538
batch 185 loss: 0.0005576051771640778
batch 190 loss: 0.0005577991949394345
batch 195 loss: 0.0005576580879278481
batch 200 loss: 0.0005576700437813997
batch 205 loss: 0.0005576394847594202
batch 210 loss: 0.0005577023723162711
batch 215 loss: 0.0005577302305027843
batch 220 loss: 0.0005577387288212776
batch 225 loss: 0.0005576769355684519
batch 230 loss: 0.0005576776224188506
batch 235 loss: 0.0005575767252594232
batch 240 loss: 0.0005577141302637756
Training Loss: 0.0005576834131109839
Validation Loss: 0.0005576934810960666
Epoch 55:
batch 5 loss: 0.0005576569121330977
batch 10 loss: 0.0005576527677476406
batch 15 loss: 0.0005577679490670562
batch 20 loss: 0.0005577289382927119
batch 25 loss: 0.0005576300085522234
batch 30 loss: 0.0005577147821895778
batch 35 loss: 0.0005577006726525724
batch 40 loss: 0.000557701219804585
batch 45 loss: 0.0005577411269769072
batch 50 loss: 0.000557638006284833
batch 55 loss: 0.0005576186347752809
batch 60 loss: 0.0005577369127422571
batch 65 loss: 0.0005577371222898365
batch 70 loss: 0.0005577289382927119
batch 75 loss: 0.0005575644667260349
batch 80 loss: 0.0005576467840000987
batch 85 loss: 0.0005577103001996875
batch 90 loss: 0.0005576882162131369
batch 95 loss: 0.0005576997646130621
batch 100 loss: 0.0005577558418735862
batch 105 loss: 0.0005576931987889111
batch 110 loss: 0.0005577033618465066
batch 115 loss: 0.0005576953291893006
batch 120 loss: 0.0005577974603511393
batch 125 loss: 0.0005576878204010427
batch 130 loss: 0.0005576596246100962
batch 135 loss: 0.000557573267724365
batch 140 loss: 0.0005575861898250878
batch 145 loss: 0.0005577420582994818
batch 150 loss: 0.0005577468196861446
batch 155 loss: 0.00055760876275599
batch 160 loss: 0.0005575284245423973
batch 165 loss: 0.0005577491130679846
batch 170 loss: 0.0005576718132942915
batch 175 loss: 0.0005575999617576599
batch 180 loss: 0.0005576728028245271
batch 185 loss: 0.0005575984017923474
batch 190 loss: 0.0005576364812441171
batch 195 loss: 0.0005577184376306832
batch 200 loss: 0.0005576779716648161
batch 205 loss: 0.0005576915224082768
batch 210 loss: 0.0005577224073931575
batch 215 loss: 0.0005576379713602364
batch 220 loss: 0.0005578364827670157
batch 225 loss: 0.0005576680996455252
batch 230 loss: 0.0005576287861913442
batch 235 loss: 0.0005577699630521238
batch 240 loss: 0.0005576826049946248
Training Loss: 0.0005576834271778352
Validation Loss: 0.000557693473335045
Epoch 56:
batch 5 loss: 0.0005576079827733337
batch 10 loss: 0.0005576880183070898
batch 15 loss: 0.0005577298928983509
batch 20 loss: 0.0005576312425546349
batch 25 loss: 0.000557573651894927
batch 30 loss: 0.0005576727795414627
batch 35 loss: 0.0005576957832090556
batch 40 loss: 0.0005576544092036784
batch 45 loss: 0.0005576689727604389
batch 50 loss: 0.0005576536408625543
batch 55 loss: 0.0005575327784754335
batch 60 loss: 0.0005577563541010022
batch 65 loss: 0.0005576316267251969
batch 70 loss: 0.0005577301722951234
batch 75 loss: 0.0005576547933742404
batch 80 loss: 0.0005577277392148971
batch 85 loss: 0.0005576864583417773
batch 90 loss: 0.0005577066214755178
batch 95 loss: 0.0005576933268457651
batch 100 loss: 0.0005577430827543139
batch 105 loss: 0.0005577823729254305
batch 110 loss: 0.0005576830473728478
batch 115 loss: 0.0005575721501372754
batch 120 loss: 0.0005577882751822471
batch 125 loss: 0.0005577130010351539
batch 130 loss: 0.0005576580413617193
batch 135 loss: 0.0005577002419158816
batch 140 loss: 0.000557705108076334
batch 145 loss: 0.0005577021045610308
batch 150 loss: 0.0005577316274866462
batch 155 loss: 0.000557690835557878
batch 160 loss: 0.000557680893689394
batch 165 loss: 0.0005576134426519275
batch 170 loss: 0.0005576769704930485
batch 175 loss: 0.0005577229079790413
batch 180 loss: 0.0005577046540565789
batch 185 loss: 0.000557682744693011
batch 190 loss: 0.0005576555849984288
batch 195 loss: 0.0005576415103860199
batch 200 loss: 0.0005576169234700501
batch 205 loss: 0.000557655852753669
batch 210 loss: 0.00055759894894436
batch 215 loss: 0.0005577010335400701
batch 220 loss: 0.0005576579249463975
batch 225 loss: 0.0005577581352554262
batch 230 loss: 0.0005577555391937494
batch 235 loss: 0.0005577872740104795
batch 240 loss: 0.0005577274016104639
Training Loss: 0.0005576834140811115
Validation Loss: 0.000557693403485852
Epoch 57:
batch 5 loss: 0.0005576639203354716
batch 10 loss: 0.0005578164593316615
batch 15 loss: 0.0005576081108301878
batch 20 loss: 0.0005577225238084793
batch 25 loss: 0.0005577095202170312
batch 30 loss: 0.0005577547941356898
batch 35 loss: 0.0005576558294706046
batch 40 loss: 0.0005578108481131494
batch 45 loss: 0.0005576081923209131
batch 50 loss: 0.0005575688206590712
batch 55 loss: 0.0005576111725531518
batch 60 loss: 0.0005576047580689192
batch 65 loss: 0.0005576448398642242
batch 70 loss: 0.0005576201947405934
batch 75 loss: 0.0005577030009590089
batch 80 loss: 0.0005576438852585852
batch 85 loss: 0.000557763734832406
batch 90 loss: 0.0005577158066444099
batch 95 loss: 0.0005577420000918209
batch 100 loss: 0.0005576465395279228
batch 105 loss: 0.0005576925002969801
batch 110 loss: 0.00055764967110008
batch 115 loss: 0.0005577958538196981
batch 120 loss: 0.0005575582035817206
batch 125 loss: 0.0005576321505941451
batch 130 loss: 0.0005576824187301099
batch 135 loss: 0.0005577608826570213
batch 140 loss: 0.0005577728268690407
batch 145 loss: 0.000557646038942039
batch 150 loss: 0.000557709636632353
batch 155 loss: 0.0005576046649366617
batch 160 loss: 0.000557707145344466
batch 165 loss: 0.0005576013354584575
batch 170 loss: 0.0005577135016210377
batch 175 loss: 0.0005577377276495099
batch 180 loss: 0.0005577453295700252
batch 185 loss: 0.0005576240713708102
batch 190 loss: 0.000557677645701915
batch 195 loss: 0.0005575836636126042
batch 200 loss: 0.0005576630705036223
batch 205 loss: 0.0005576949799433351
batch 210 loss: 0.0005578651325777173
batch 215 loss: 0.0005576553870923817
batch 220 loss: 0.0005576162016950548
batch 225 loss: 0.0005576346535235644
batch 230 loss: 0.0005577100557275117
batch 235 loss: 0.0005576469004154206
batch 240 loss: 0.000557806738652289
Training Loss: 0.0005576834029246432
Validation Loss: 0.0005576934093066181
Epoch 58:
batch 5 loss: 0.0005576568772085011
batch 10 loss: 0.0005576929659582674
batch 15 loss: 0.0005577424424700439
batch 20 loss: 0.0005577235715463758
batch 25 loss: 0.0005576510564424097
batch 30 loss: 0.0005576898576691747
batch 35 loss: 0.0005576526164077222
batch 40 loss: 0.0005577306030318141
batch 45 loss: 0.0005577454925514757
batch 50 loss: 0.0005575945018790662
batch 55 loss: 0.0005576968076638877
batch 60 loss: 0.0005576678784564137
batch 65 loss: 0.0005577682750299573
batch 70 loss: 0.0005576864932663739
batch 75 loss: 0.0005576379713602364
batch 80 loss: 0.0005577605217695237
batch 85 loss: 0.0005576978903263808
batch 90 loss: 0.0005575695307925343
batch 95 loss: 0.0005576407071202994
batch 100 loss: 0.0005576358060352504
batch 105 loss: 0.0005576996132731438
batch 110 loss: 0.000557644315995276
batch 115 loss: 0.0005577166564762592
batch 120 loss: 0.0005576459458097816
batch 125 loss: 0.0005576232215389609
batch 130 loss: 0.0005576045601628721
batch 135 loss: 0.0005576822091825307
batch 140 loss: 0.0005577321979217231
batch 145 loss: 0.0005576926283538342
batch 150 loss: 0.0005577352596446872
batch 155 loss: 0.0005578163429163397
batch 160 loss: 0.0005576055613346398
batch 165 loss: 0.000557757040951401
batch 170 loss: 0.0005576597410254181
batch 175 loss: 0.000557741685770452
batch 180 loss: 0.0005576987052336336
batch 185 loss: 0.0005577738396823406
batch 190 loss: 0.0005576652358286083
batch 195 loss: 0.0005576826981268824
batch 200 loss: 0.000557656236924231
batch 205 loss: 0.00055766865843907
batch 210 loss: 0.0005575768649578094
batch 215 loss: 0.0005576549679972232
batch 220 loss: 0.0005577017553150653
batch 225 loss: 0.0005576061201281845
batch 230 loss: 0.0005577440722845494
batch 235 loss: 0.0005576565745286644
batch 240 loss: 0.0005577208590693772
Training Loss: 0.0005576834465803889
Validation Loss: 0.0005576938361627981
Epoch 59:
batch 5 loss: 0.0005577114061452448
batch 10 loss: 0.0005577190429903566
batch 15 loss: 0.0005575887160375714
batch 20 loss: 0.0005576270632445812
batch 25 loss: 0.0005578602897003293
batch 30 loss: 0.0005577352829277515
batch 35 loss: 0.0005576614756137132
batch 40 loss: 0.0005577315459959209
batch 45 loss: 0.0005576941301114857
batch 50 loss: 0.0005575938615947962
batch 55 loss: 0.0005576964700594545
batch 60 loss: 0.0005578035139478743
batch 65 loss: 0.0005577233619987965
batch 70 loss: 0.0005577604984864593
batch 75 loss: 0.0005577182164415717
batch 80 loss: 0.0005576259805820883
batch 85 loss: 0.0005577467498369515
batch 90 loss: 0.0005576622672379017
batch 95 loss: 0.0005576582974754274
batch 100 loss: 0.0005577472038567066
batch 105 loss: 0.0005576372612267732
batch 110 loss: 0.0005576764233410358
batch 115 loss: 0.0005577213945798576
batch 120 loss: 0.0005576071212999523
batch 125 loss: 0.0005576563184149563
batch 130 loss: 0.0005576833384111524
batch 135 loss: 0.0005576498806476593
batch 140 loss: 0.0005576665746048093
batch 145 loss: 0.0005575777729973197
batch 150 loss: 0.0005577136180363595
batch 155 loss: 0.0005576440831646323
batch 160 loss: 0.000557644385844469
batch 165 loss: 0.0005576693802140653
batch 170 loss: 0.0005576806608587504
batch 175 loss: 0.000557651009876281
batch 180 loss: 0.0005576099152676761
batch 185 loss: 0.0005576109513640403
batch 190 loss: 0.0005576386698521674
batch 195 loss: 0.0005578103824518621
batch 200 loss: 0.0005577333387918771
batch 205 loss: 0.0005577291245572269
batch 210 loss: 0.0005577188800089061
batch 215 loss: 0.0005575889139436185
batch 220 loss: 0.0005576212890446186
batch 225 loss: 0.0005576569936238229
batch 230 loss: 0.0005577345029450953
batch 235 loss: 0.0005576766678132116
batch 240 loss: 0.0005577306728810072
Training Loss: 0.0005576834354239206
Validation Loss: 0.0005576934219182779
Epoch 60:
batch 5 loss: 0.0005577118135988712
batch 10 loss: 0.0005577069008722901
batch 15 loss: 0.0005576420109719038
batch 20 loss: 0.000557620485778898
batch 25 loss: 0.0005577198578976094
batch 30 loss: 0.0005576722440309822
batch 35 loss: 0.0005576505674980581
batch 40 loss: 0.0005576022318564356
batch 45 loss: 0.0005576964700594545
batch 50 loss: 0.0005576652241870761
batch 55 loss: 0.0005577222560532391
batch 60 loss: 0.0005576774827204644
batch 65 loss: 0.0005576237686909735
batch 70 loss: 0.0005577291129156947
batch 75 loss: 0.0005576502997428178
batch 80 loss: 0.0005577408475801349
batch 85 loss: 0.0005576340132392943
batch 90 loss: 0.0005576536641456187
batch 95 loss: 0.0005576798808760941
batch 100 loss: 0.0005577318836003542
batch 105 loss: 0.0005577393807470798
batch 110 loss: 0.0005576756899245084
batch 115 loss: 0.0005575865623541176
batch 120 loss: 0.0005577329313382507
batch 125 loss: 0.0005576480645686388
batch 130 loss: 0.0005576121038757265
batch 135 loss: 0.0005576279014348984
batch 140 loss: 0.0005576533032581211
batch 145 loss: 0.000557683443184942
batch 150 loss: 0.0005577216041274368
batch 155 loss: 0.0005577612901106477
batch 160 loss: 0.0005575995077379048
batch 165 loss: 0.0005576203227974474
batch 170 loss: 0.0005576731287874282
batch 175 loss: 0.0005577393108978868
batch 180 loss: 0.0005576904630288481
batch 185 loss: 0.0005577776115387678
batch 190 loss: 0.0005578362615779042
batch 195 loss: 0.0005576987052336336
batch 200 loss: 0.0005576632102020085
batch 205 loss: 0.0005577280186116696
batch 210 loss: 0.0005576475989073515
batch 215 loss: 0.0005576125811785459
batch 220 loss: 0.0005577178206294775
batch 225 loss: 0.000557701347861439
batch 230 loss: 0.000557724165264517
batch 235 loss: 0.0005576794850639999
batch 240 loss: 0.0005577222560532391
Training Loss: 0.0005576834393044313
Validation Loss: 0.0005576934568428745
Epoch 61:
batch 5 loss: 0.0005576851195655763
batch 10 loss: 0.0005577128147706389
batch 15 loss: 0.0005576339666731655
batch 20 loss: 0.0005577326752245426
batch 25 loss: 0.000557622394990176
batch 30 loss: 0.0005577636417001486
batch 35 loss: 0.0005576492520049214
batch 40 loss: 0.0005576818133704364
batch 45 loss: 0.0005576849449425936
batch 50 loss: 0.0005576177034527063
batch 55 loss: 0.0005576774128712714
batch 60 loss: 0.0005576667026616633
batch 65 loss: 0.0005577506846748293
batch 70 loss: 0.0005577405681833625
batch 75 loss: 0.0005576521740294993
batch 80 loss: 0.0005576526978984475
batch 85 loss: 0.0005576093797571957
batch 90 loss: 0.0005576683208346367
batch 95 loss: 0.0005576763651333749
batch 100 loss: 0.0005576122784987092
batch 105 loss: 0.0005578083335421979
batch 110 loss: 0.0005576987401582301
batch 115 loss: 0.0005576250841841102
batch 120 loss: 0.0005576396943069994
batch 125 loss: 0.0005575652234256267
batch 130 loss: 0.0005577050382271409
batch 135 loss: 0.0005577530362643301
batch 140 loss: 0.000557711289729923
batch 145 loss: 0.0005577355739660561
batch 150 loss: 0.0005577012547291815
batch 155 loss: 0.0005576961324550211
batch 160 loss: 0.0005578409414738417
batch 165 loss: 0.0005577220232225955
batch 170 loss: 0.0005577346775680781
batch 175 loss: 0.0005576399038545787
batch 180 loss: 0.0005576381343416869
batch 185 loss: 0.0005576143856160342
batch 190 loss: 0.0005576118710450828
batch 195 loss: 0.0005576734780333936
batch 200 loss: 0.0005577079486101866
batch 205 loss: 0.0005577323259785772
batch 210 loss: 0.0005576827097684145
batch 215 loss: 0.0005576024646870792
batch 220 loss: 0.0005577297997660935
batch 225 loss: 0.0005576758761890232
batch 230 loss: 0.000557611626572907
batch 235 loss: 0.0005576813477091491
batch 240 loss: 0.0005577748292125761
Training Loss: 0.0005576834303307502
Validation Loss: 0.0005576934907973434
Epoch 62:
batch 5 loss: 0.0005577157950028777
batch 10 loss: 0.0005576124065555632
batch 15 loss: 0.0005576821509748697
batch 20 loss: 0.000557706959079951
batch 25 loss: 0.0005578203010372818
batch 30 loss: 0.0005576626630499959
batch 35 loss: 0.0005576051189564168
batch 40 loss: 0.0005577222909778357
batch 45 loss: 0.0005577108939178288
batch 50 loss: 0.0005577039439231158
batch 55 loss: 0.0005576913012191653
batch 60 loss: 0.0005576744675636292
batch 65 loss: 0.0005576285184361041
batch 70 loss: 0.0005577279138378799
batch 75 loss: 0.0005577550502493978
batch 80 loss: 0.0005577197531238198
batch 85 loss: 0.0005576480063609779
batch 90 loss: 0.0005576477735303343
batch 95 loss: 0.0005577309755608439
batch 100 loss: 0.0005576561787165701
batch 105 loss: 0.0005577006959356368
batch 110 loss: 0.0005576180876232684
batch 115 loss: 0.0005576952593401074
batch 120 loss: 0.0005576646304689348
batch 125 loss: 0.0005576467723585665
batch 130 loss: 0.0005576491821557283
batch 135 loss: 0.0005576350609771908
batch 140 loss: 0.0005577010801061988
batch 145 loss: 0.0005577502306550741
batch 150 loss: 0.000557617493905127
batch 155 loss: 0.0005577029543928802
batch 160 loss: 0.0005577545380219817
batch 165 loss: 0.0005576965515501798
batch 170 loss: 0.00055763921700418
batch 175 loss: 0.0005576488096266985
batch 180 loss: 0.0005576773779466748
batch 185 loss: 0.0005577093339525163
batch 190 loss: 0.0005577227449975908
batch 195 loss: 0.0005576853989623487
batch 200 loss: 0.000557667703833431
batch 205 loss: 0.0005576498573645949
batch 210 loss: 0.0005577239906415343
batch 215 loss: 0.0005576080759055913
batch 220 loss: 0.0005576642462983728
batch 225 loss: 0.0005576996481977403
batch 230 loss: 0.0005576651776209474
batch 235 loss: 0.0005577569245360792
batch 240 loss: 0.000557632721029222
Training Loss: 0.0005576834630725595
Validation Loss: 0.0005576934461714699
Epoch 63:
batch 5 loss: 0.0005577012547291815
batch 10 loss: 0.0005577295087277889
batch 15 loss: 0.0005578069831244648
batch 20 loss: 0.0005577463191002608
batch 25 loss: 0.0005576393567025661
batch 30 loss: 0.0005575971212238073
batch 35 loss: 0.0005576801137067378
batch 40 loss: 0.0005576319643296301
batch 45 loss: 0.0005576642695814371
batch 50 loss: 0.0005577239557169378
batch 55 loss: 0.0005576468538492918
batch 60 loss: 0.0005576080526225269
batch 65 loss: 0.0005577321397140622
batch 70 loss: 0.0005576872965320945
batch 75 loss: 0.0005577592179179192
batch 80 loss: 0.0005577522912062705
batch 85 loss: 0.0005576905678026378
batch 90 loss: 0.0005577173200435936
batch 95 loss: 0.0005576616153120994
batch 100 loss: 0.000557742640376091
batch 105 loss: 0.0005576768657192588
batch 110 loss: 0.0005576519877649843
batch 115 loss: 0.0005577720818109811
batch 120 loss: 0.0005577058997005224
batch 125 loss: 0.0005576289026066661
batch 130 loss: 0.0005577901960350573
batch 135 loss: 0.0005576715106144547
batch 140 loss: 0.000557710649445653
batch 145 loss: 0.0005576769588515162
batch 150 loss: 0.0005576211377047002
batch 155 loss: 0.0005576024414040148
batch 160 loss: 0.000557711604051292
batch 165 loss: 0.0005576711497269571
batch 170 loss: 0.0005575983435846865
batch 175 loss: 0.0005575988441705703
batch 180 loss: 0.0005577233619987965
batch 185 loss: 0.000557731359731406
batch 190 loss: 0.0005576619878411293
batch 195 loss: 0.0005576704861596227
batch 200 loss: 0.0005574482143856585
batch 205 loss: 0.0005577353062108159
batch 210 loss: 0.0005576563999056816
batch 215 loss: 0.0005576512659899891
batch 220 loss: 0.0005576764116995037
batch 225 loss: 0.0005577550386078656
batch 230 loss: 0.0005577374598942697
batch 235 loss: 0.0005577274831011891
batch 240 loss: 0.0005576221272349357
Training Loss: 0.0005576834232973245
Validation Loss: 0.0005576934801259388
Epoch 64:
batch 5 loss: 0.0005576928029768169
batch 10 loss: 0.0005577752250246704
batch 15 loss: 0.0005575661663897336
batch 20 loss: 0.0005576478200964629
batch 25 loss: 0.0005577801610343158
batch 30 loss: 0.0005576971103437245
batch 35 loss: 0.0005576402298174798
batch 40 loss: 0.0005576569237746298
batch 45 loss: 0.0005576553754508496
batch 50 loss: 0.0005577132920734585
batch 55 loss: 0.0005577760864980518
batch 60 loss: 0.0005575200193561614
batch 65 loss: 0.000557681720238179
batch 70 loss: 0.0005576342111453414
batch 75 loss: 0.0005577646661549807
batch 80 loss: 0.0005577121279202402
batch 85 loss: 0.0005576824303716421
batch 90 loss: 0.0005576419527642429
batch 95 loss: 0.000557726644910872
batch 100 loss: 0.0005577802774496376
batch 105 loss: 0.000557657890021801
batch 110 loss: 0.0005576532683335244
batch 115 loss: 0.0005576130002737046
batch 120 loss: 0.0005576289258897305
batch 125 loss: 0.0005576590774580836
batch 130 loss: 0.0005577049218118191
batch 135 loss: 0.0005577652133069933
batch 140 loss: 0.0005576356314122676
batch 145 loss: 0.0005578339565545321
batch 150 loss: 0.0005576622788794339
batch 155 loss: 0.0005576337571255863
batch 160 loss: 0.000557640555780381
batch 165 loss: 0.0005577002186328173
batch 170 loss: 0.0005576251307502389
batch 175 loss: 0.0005576688097789883
batch 180 loss: 0.0005577690317295492
batch 185 loss: 0.000557642092462629
batch 190 loss: 0.0005576582509092987
batch 195 loss: 0.0005576550145633518
batch 200 loss: 0.0005577528849244118
batch 205 loss: 0.0005577617441304028
batch 210 loss: 0.0005577414762228727
batch 215 loss: 0.000557643361389637
batch 220 loss: 0.0005576779833063484
batch 225 loss: 0.0005577466217800975
batch 230 loss: 0.0005575757240876555
batch 235 loss: 0.0005576135823503137
batch 240 loss: 0.0005577391711995006
Training Loss: 0.0005576834337261971
Validation Loss: 0.0005576934141572565
Epoch 65:
batch 5 loss: 0.0005576342111453414
batch 10 loss: 0.0005576991708949209
batch 15 loss: 0.0005576739204116166
batch 20 loss: 0.0005577689968049526
batch 25 loss: 0.0005577948526479304
batch 30 loss: 0.0005576444906182587
batch 35 loss: 0.0005577334901317954
batch 40 loss: 0.0005576835479587317
batch 45 loss: 0.0005576502066105604
batch 50 loss: 0.0005576513009145856
batch 55 loss: 0.0005575521150603891
batch 60 loss: 0.0005576140014454722
batch 65 loss: 0.0005576973082497716
batch 70 loss: 0.0005576528725214303
batch 75 loss: 0.0005576339084655046
batch 80 loss: 0.0005576819996349514
batch 85 loss: 0.0005576249328441918
batch 90 loss: 0.0005577702075242996
batch 95 loss: 0.0005575839313678443
batch 100 loss: 0.0005577355506829918
batch 105 loss: 0.0005576486000791192
batch 110 loss: 0.0005576320108957589
batch 115 loss: 0.0005577322212047875
batch 120 loss: 0.0005577594856731594
batch 125 loss: 0.0005577209405601025
batch 130 loss: 0.0005575791466981173
batch 135 loss: 0.0005577056086622179
batch 140 loss: 0.0005577096017077565
batch 145 loss: 0.000557584036141634
batch 150 loss: 0.0005577391129918396
batch 155 loss: 0.0005576575174927711
batch 160 loss: 0.0005577228846959769
batch 165 loss: 0.0005576596246100962
batch 170 loss: 0.0005577004747465252
batch 175 loss: 0.0005577498115599156
batch 180 loss: 0.0005576601251959801
batch 185 loss: 0.0005576492985710502
batch 190 loss: 0.0005577181349508464
batch 195 loss: 0.0005577780422754586
batch 200 loss: 0.0005576496245339513
batch 205 loss: 0.0005576416500844061
batch 210 loss: 0.00055784210562706
batch 215 loss: 0.0005577027797698975
batch 220 loss: 0.0005576143739745021
batch 225 loss: 0.0005576952942647039
batch 230 loss: 0.0005577214411459863
batch 235 loss: 0.000557709252461791
batch 240 loss: 0.0005576412193477153
Training Loss: 0.0005576834465803889
Validation Loss: 0.0005576934025157243
Epoch 66:
batch 5 loss: 0.0005576647468842566
batch 10 loss: 0.0005577600561082364
batch 15 loss: 0.0005576429073698818
batch 20 loss: 0.0005577082862146199
batch 25 loss: 0.0005576231516897679
batch 30 loss: 0.0005577081115916372
batch 35 loss: 0.0005576648749411106
batch 40 loss: 0.0005577678210102021
batch 45 loss: 0.0005576551426202059
batch 50 loss: 0.0005576592870056629
batch 55 loss: 0.0005577122094109655
batch 60 loss: 0.0005576621391810477
batch 65 loss: 0.0005576422554440796
batch 70 loss: 0.0005577349686063827
batch 75 loss: 0.0005576810915954411
batch 80 loss: 0.0005577474483288824
batch 85 loss: 0.0005578045733273029
batch 90 loss: 0.0005576878553256393
batch 95 loss: 0.0005576048977673053
batch 100 loss: 0.0005576406605541706
batch 105 loss: 0.0005577416974119842
batch 110 loss: 0.0005575936171226204
batch 115 loss: 0.0005575959105044604
batch 120 loss: 0.0005575677379965783
batch 125 loss: 0.0005577137460932135
batch 130 loss: 0.0005576089606620371
batch 135 loss: 0.0005576936411671341
batch 140 loss: 0.0005577246425673366
batch 145 loss: 0.0005577426869422198
batch 150 loss: 0.0005577050498686731
batch 155 loss: 0.0005577657138928771
batch 160 loss: 0.0005574882728978991
batch 165 loss: 0.000557662989012897
batch 170 loss: 0.0005575677845627069
batch 175 loss: 0.0005576210678555071
batch 180 loss: 0.0005578249343670905
batch 185 loss: 0.0005576759111136198
batch 190 loss: 0.0005576648865826428
batch 195 loss: 0.0005578058888204395
batch 200 loss: 0.0005577208125032484
batch 205 loss: 0.0005577633157372475
batch 210 loss: 0.0005577121977694332
batch 215 loss: 0.0005577238043770194
batch 220 loss: 0.000557604432106018
batch 225 loss: 0.0005577191244810819
batch 230 loss: 0.0005575970164500177
batch 235 loss: 0.0005576396826654673
batch 240 loss: 0.0005577864940278232
Training Loss: 0.0005576834271778352
Validation Loss: 0.0005576934422909592
Epoch 67:
batch 5 loss: 0.0005576769472099841
batch 10 loss: 0.0005576721392571926
batch 15 loss: 0.0005575786111876368
batch 20 loss: 0.0005577442701905966
batch 25 loss: 0.0005577080999501049
batch 30 loss: 0.0005575797520577907
batch 35 loss: 0.0005577362258918584
batch 40 loss: 0.0005577029311098159
batch 45 loss: 0.0005577337229624391
batch 50 loss: 0.0005578118492849171
batch 55 loss: 0.0005576216615736484
batch 60 loss: 0.0005577784380875528
batch 65 loss: 0.0005575714283622801
batch 70 loss: 0.0005576911615207791
batch 75 loss: 0.0005576598923653364
batch 80 loss: 0.0005576388793997467
batch 85 loss: 0.0005576123716309666
batch 90 loss: 0.0005576435360126197
batch 95 loss: 0.0005577180651016534
batch 100 loss: 0.0005576600669883192
batch 105 loss: 0.0005575705086812377
batch 110 loss: 0.0005576130584813655
batch 115 loss: 0.0005576986470259726
batch 120 loss: 0.0005576161318458616
batch 125 loss: 0.0005577014060690999
batch 130 loss: 0.0005576518829911947
batch 135 loss: 0.0005577387404628098
batch 140 loss: 0.0005576892057433724
batch 145 loss: 0.0005577311967499554
batch 150 loss: 0.0005577083094976843
batch 155 loss: 0.000557732058223337
batch 160 loss: 0.0005576035473495722
batch 165 loss: 0.0005577294388785959
batch 170 loss: 0.0005577741656452417
batch 175 loss: 0.0005577068426646292
batch 180 loss: 0.0005576803465373814
batch 185 loss: 0.0005577571457251907
batch 190 loss: 0.0005576910101808607
batch 195 loss: 0.0005576677154749632
batch 200 loss: 0.0005577099742367864
batch 205 loss: 0.0005576714407652617
batch 210 loss: 0.0005576873780228197
batch 215 loss: 0.000557673058938235
batch 220 loss: 0.0005577393225394189
batch 225 loss: 0.0005576872965320945
batch 230 loss: 0.000557750416919589
batch 235 loss: 0.0005575873423367739
batch 240 loss: 0.0005576979485340417
Training Loss: 0.0005576834497333039
Validation Loss: 0.0005576934393805762
Epoch 68:
batch 5 loss: 0.0005576421273872257
batch 10 loss: 0.0005576116382144392
batch 15 loss: 0.0005577043164521455
batch 20 loss: 0.0005576906609348953
batch 25 loss: 0.0005577890668064355
batch 30 loss: 0.0005576872499659657
batch 35 loss: 0.0005577030940912664
batch 40 loss: 0.0005575786926783621
batch 45 loss: 0.0005576771683990956
batch 50 loss: 0.0005576731753535568
batch 55 loss: 0.0005576929775997997
batch 60 loss: 0.0005577477044425905
batch 65 loss: 0.0005576084251515568
batch 70 loss: 0.000557734165340662
batch 75 loss: 0.0005577614880166948
batch 80 loss: 0.000557552941609174
batch 85 loss: 0.0005576463066972792
batch 90 loss: 0.0005577047355473042
batch 95 loss: 0.0005577066447585821
batch 100 loss: 0.0005576554918661714
batch 105 loss: 0.0005576946889050305
batch 110 loss: 0.0005577128147706389
batch 115 loss: 0.0005576689494773745
batch 120 loss: 0.0005577788804657757
batch 125 loss: 0.0005577105097472667
batch 130 loss: 0.0005577450152486563
batch 135 loss: 0.0005576590541750192
batch 140 loss: 0.0005577354109846056
batch 145 loss: 0.000557762966491282
batch 150 loss: 0.0005576674826443196
batch 155 loss: 0.0005576284718699753
batch 160 loss: 0.0005577520001679659
batch 165 loss: 0.0005576820112764835
batch 170 loss: 0.0005576191004365682
batch 175 loss: 0.0005575943388976157
batch 180 loss: 0.0005575577146373689
batch 185 loss: 0.0005577050731517374
batch 190 loss: 0.0005578491021879017
batch 195 loss: 0.0005576216848567128
batch 200 loss: 0.0005577020812779665
batch 205 loss: 0.0005577241769060493
batch 210 loss: 0.0005577243049629032
batch 215 loss: 0.0005577268777415157
batch 220 loss: 0.0005575809977017343
batch 225 loss: 0.0005576565745286644
batch 230 loss: 0.000557653175201267
batch 235 loss: 0.0005576560855843127
batch 240 loss: 0.0005576672498136759
Training Loss: 0.0005576834346963248
Validation Loss: 0.0005576934044559796
Epoch 69:
batch 5 loss: 0.0005577487172558904
batch 10 loss: 0.0005577066447585821
batch 15 loss: 0.0005576367839239538
batch 20 loss: 0.000557686819229275
batch 25 loss: 0.0005577649804763496
batch 30 loss: 0.0005577323492616415
batch 35 loss: 0.0005576199735514819
batch 40 loss: 0.0005575329647399485
batch 45 loss: 0.0005577120115049184
batch 50 loss: 0.0005576906143687666
batch 55 loss: 0.0005576283903792501
batch 60 loss: 0.000557779602240771
batch 65 loss: 0.000557736458722502
batch 70 loss: 0.0005576967261731625
batch 75 loss: 0.0005575183895416558
batch 80 loss: 0.0005577389965765178
batch 85 loss: 0.0005577767617069185
batch 90 loss: 0.0005576544092036784
batch 95 loss: 0.0005576346535235644
batch 100 loss: 0.0005577846197411418
batch 105 loss: 0.0005577760399319232
batch 110 loss: 0.0005577114527113736
batch 115 loss: 0.0005575789255090058
batch 120 loss: 0.0005576457013376057
batch 125 loss: 0.0005576630821451545
batch 130 loss: 0.0005576852825470268
batch 135 loss: 0.0005575602408498526
batch 140 loss: 0.0005577961564995348
batch 145 loss: 0.0005576922325417399
batch 150 loss: 0.000557634187862277
batch 155 loss: 0.0005576827912591398
batch 160 loss: 0.0005576823255978525
batch 165 loss: 0.0005576801835559308
batch 170 loss: 0.0005577598931267858
batch 175 loss: 0.0005577056901529432
batch 180 loss: 0.0005577537813223898
batch 185 loss: 0.0005576586700044572
batch 190 loss: 0.0005577874486334622
batch 195 loss: 0.0005575068644247949
batch 200 loss: 0.0005576348979957402
batch 205 loss: 0.0005577091942541301
batch 210 loss: 0.0005576783558353781
batch 215 loss: 0.0005577019997872412
batch 220 loss: 0.0005576850729994476
batch 225 loss: 0.0005576513125561178
batch 230 loss: 0.000557639286853373
batch 235 loss: 0.0005576018709689378
batch 240 loss: 0.000557759846560657
Training Loss: 0.0005576834094730051
Validation Loss: 0.0005576934131871288
Epoch 70:
batch 5 loss: 0.0005576646653935313
batch 10 loss: 0.000557656807359308
batch 15 loss: 0.0005576323950663209
batch 20 loss: 0.0005576542695052922
batch 25 loss: 0.000557717343326658
batch 30 loss: 0.000557808531448245
batch 35 loss: 0.0005576817085966468
batch 40 loss: 0.00055775340879336
batch 45 loss: 0.0005576640367507934
batch 50 loss: 0.0005576647585257888
batch 55 loss: 0.0005575914517976343
batch 60 loss: 0.0005577568430453539
batch 65 loss: 0.0005576593801379203
batch 70 loss: 0.0005576864001341164
batch 75 loss: 0.0005577173200435936
batch 80 loss: 0.0005577451433055103
batch 85 loss: 0.0005576787982136012
batch 90 loss: 0.0005576969007961452
batch 95 loss: 0.0005576704046688974
batch 100 loss: 0.0005577006726525724
batch 105 loss: 0.0005577343516051769
batch 110 loss: 0.0005577685544267297
batch 115 loss: 0.0005577256437391042
batch 120 loss: 0.0005576783209107816
batch 125 loss: 0.0005576573894359171
batch 130 loss: 0.0005576901021413505
batch 135 loss: 0.0005576780647970736
batch 140 loss: 0.0005577338160946965
batch 145 loss: 0.0005576899857260287
batch 150 loss: 0.0005576280876994133
batch 155 loss: 0.0005576947936788201
batch 160 loss: 0.0005576564813964069
batch 165 loss: 0.0005576755269430578
batch 170 loss: 0.0005577424773946405
batch 175 loss: 0.0005576580413617193
batch 180 loss: 0.0005577736883424222
batch 185 loss: 0.0005577388103120029
batch 190 loss: 0.0005576805211603642
batch 195 loss: 0.0005577232572250068
batch 200 loss: 0.0005575925577431917
batch 205 loss: 0.0005576395546086132
batch 210 loss: 0.0005576562602072954
batch 215 loss: 0.0005575925810262561
batch 220 loss: 0.000557582441251725
batch 225 loss: 0.0005575565504841506
batch 230 loss: 0.0005577657953836024
batch 235 loss: 0.0005576907657086849
batch 240 loss: 0.0005575982504524291
Training Loss: 0.0005576834148087074
Validation Loss: 0.0005576934170676395
Epoch 71:
batch 5 loss: 0.0005577018018811941
batch 10 loss: 0.0005576875410042703
batch 15 loss: 0.0005576414405368268
batch 20 loss: 0.0005576980416662991
batch 25 loss: 0.000557678029872477
batch 30 loss: 0.0005576576339080929
batch 35 loss: 0.0005576704628765583
batch 40 loss: 0.0005576651659794152
batch 45 loss: 0.0005577855277806521
batch 50 loss: 0.0005577445612289011
batch 55 loss: 0.0005575305898673832
batch 60 loss: 0.0005576616968028247
batch 65 loss: 0.0005577275296673179
batch 70 loss: 0.0005576983327046037
batch 75 loss: 0.0005578557029366493
batch 80 loss: 0.0005577365518547595
batch 85 loss: 0.0005576993338763714
batch 90 loss: 0.000557750987354666
batch 95 loss: 0.0005575834889896214
batch 100 loss: 0.0005577829666435719
batch 105 loss: 0.0005576486000791192
batch 110 loss: 0.0005577148403972387
batch 115 loss: 0.0005577439325861633
batch 120 loss: 0.0005576309631578624
batch 125 loss: 0.0005575872026383876
batch 130 loss: 0.000557748880237341
batch 135 loss: 0.0005577270057983696
batch 140 loss: 0.0005576921976171434
batch 145 loss: 0.0005576441995799542
batch 150 loss: 0.0005575936287641525
batch 155 loss: 0.0005577271920628845
batch 160 loss: 0.0005577943287789821
batch 165 loss: 0.0005577438394539058
batch 170 loss: 0.000557610287796706
batch 175 loss: 0.0005577224539592863
batch 180 loss: 0.0005576781230047345
batch 185 loss: 0.0005576949566602707
batch 190 loss: 0.0005576666444540024
batch 195 loss: 0.0005575277493335307
batch 200 loss: 0.0005575331626459957
batch 205 loss: 0.0005576816853135824
batch 210 loss: 0.0005576838040724397
batch 215 loss: 0.0005576738389208913
batch 220 loss: 0.0005575699848122895
batch 225 loss: 0.0005577051895670592
batch 230 loss: 0.000557733082678169
batch 235 loss: 0.0005576716619543731
batch 240 loss: 0.000557697843760252
Training Loss: 0.0005576834305732821
Validation Loss: 0.0005576934122170011
Epoch 72:
batch 5 loss: 0.0005576952826231718
batch 10 loss: 0.0005576151888817549
batch 15 loss: 0.0005577877745963633
batch 20 loss: 0.0005578064592555165
batch 25 loss: 0.0005576327326707542
batch 30 loss: 0.0005576667375862598
batch 35 loss: 0.0005575234536081553
batch 40 loss: 0.0005576862604357302
batch 45 loss: 0.0005577958887442947
batch 50 loss: 0.0005577386356890202
batch 55 loss: 0.0005577820120379329
batch 60 loss: 0.000557700649369508
batch 65 loss: 0.0005577126052230596
batch 70 loss: 0.0005575852934271097
batch 75 loss: 0.0005577812320552766
batch 80 loss: 0.0005576638039201498
batch 85 loss: 0.0005576290888711811
batch 90 loss: 0.0005576024763286114
batch 95 loss: 0.0005576228606514633
batch 100 loss: 0.0005578333628363907
batch 105 loss: 0.0005576143972575665
batch 110 loss: 0.0005576742347329855
batch 115 loss: 0.0005575929302722215
batch 120 loss: 0.0005576904863119125
batch 125 loss: 0.0005577274947427213
batch 130 loss: 0.0005577158299274743
batch 135 loss: 0.0005577294738031924
batch 140 loss: 0.0005577078787609935
batch 145 loss: 0.0005578160402365029
batch 150 loss: 0.0005576855386607349
batch 155 loss: 0.0005576859344728291
batch 160 loss: 0.0005576851312071085
batch 165 loss: 0.0005576960276812315
batch 170 loss: 0.0005576861556619405
batch 175 loss: 0.0005575701594352722
batch 180 loss: 0.0005576673778705299
batch 185 loss: 0.0005577706964686513
batch 190 loss: 0.0005576847586780786
batch 195 loss: 0.0005576640367507934
batch 200 loss: 0.0005576196708716452
batch 205 loss: 0.0005577441537752747
batch 210 loss: 0.0005576237919740379
batch 215 loss: 0.0005577332340180874
batch 220 loss: 0.0005576035007834434
batch 225 loss: 0.0005575994146056473
batch 230 loss: 0.0005576088209636509
batch 235 loss: 0.0005576307070441544
batch 240 loss: 0.0005577142466790975
Training Loss: 0.0005576834150512393
Validation Loss: 0.0005576934180377672
Epoch 73:
batch 5 loss: 0.000557731173466891
batch 10 loss: 0.0005576931522227824
batch 15 loss: 0.000557771255262196
batch 20 loss: 0.0005577013245783747
batch 25 loss: 0.0005575833027251064
batch 30 loss: 0.0005577417905442417
batch 35 loss: 0.000557586771901697
batch 40 loss: 0.0005576518829911947
batch 45 loss: 0.0005576023599132895
batch 50 loss: 0.0005575823597609997
batch 55 loss: 0.0005576313124038279
batch 60 loss: 0.0005578376934863627
batch 65 loss: 0.0005577185307629407
batch 70 loss: 0.000557683629449457
batch 75 loss: 0.0005576050840318203
batch 80 loss: 0.0005576994037255645
batch 85 loss: 0.000557689496781677
batch 90 loss: 0.0005576961324550211
batch 95 loss: 0.0005577294272370636
batch 100 loss: 0.0005577045609243214
batch 105 loss: 0.0005577616393566132
batch 110 loss: 0.0005576621973887086
batch 115 loss: 0.0005576582276262343
batch 120 loss: 0.0005576488212682307
batch 125 loss: 0.0005575800780206919
batch 130 loss: 0.0005577798001468182
batch 135 loss: 0.0005577398231253027
batch 140 loss: 0.0005576611612923444
batch 145 loss: 0.0005577728617936373
batch 150 loss: 0.0005577232572250068
batch 155 loss: 0.0005577835603617131
batch 160 loss: 0.0005577550153248012
batch 165 loss: 0.0005576776340603829
batch 170 loss: 0.0005576463765464724
batch 175 loss: 0.0005576303694397212
batch 180 loss: 0.0005575939547270536
batch 185 loss: 0.0005576841998845339
batch 190 loss: 0.0005577355157583952
batch 195 loss: 0.0005577201838605106
batch 200 loss: 0.0005576980533078313
batch 205 loss: 0.0005576661904342472
batch 210 loss: 0.0005577295552939177
batch 215 loss: 0.0005577430478297174
batch 220 loss: 0.0005575692979618907
batch 225 loss: 0.0005576060619205236
batch 230 loss: 0.0005576778086833656
batch 235 loss: 0.0005576304509304463
batch 240 loss: 0.0005576279247179628
Training Loss: 0.0005576834106856646
Validation Loss: 0.0005576935199011738
Epoch 74:
